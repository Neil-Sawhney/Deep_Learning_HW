%!PS-Adobe-3.0
%%Title: __init__.py, adam.py, augment_data.py, conv_2d.py, embed_to_vocab_file.py, embedder.py, group_norm.py, load_idx_data.py, load_pickle_data.py, positional_encoding.py
%%For: 
%%Creator: a2ps version 4.14
%%CreationDate: Mon Nov 27 13:03:14 2023
%%BoundingBox: 24 24 571 818
%%DocumentData: Clean7Bit
%%Orientation: Portrait
%%Pages: 79
%%PageOrder: Ascend
%%DocumentMedia: A4 595 842 0 () ()
%%DocumentNeededResources: font Courier
%%+ font Courier-Bold
%%+ font Courier-BoldOblique
%%+ font Courier-Oblique
%%+ font Helvetica
%%+ font Helvetica-Bold
%%+ font Symbol
%%+ font Times-Bold
%%+ font Times-Roman
%%DocumentProcessColors: Black 
%%DocumentSuppliedResources: procset a2ps-a2ps-hdr
%%+ procset a2ps-black+white-Prolog
%%+ encoding ISO-8859-1Encoding
%%EndComments
/a2psdict 200 dict def
a2psdict begin
%%BeginProlog
%%Copyright: (c) 1988, 89, 90, 91, 92, 93 Miguel Santana
%%Copyright: (c) 1995, 96, 97, 98 Akim Demaille, Miguel Santana
% Check PostScript language level.
/languagelevel where {
  pop /gs_languagelevel languagelevel def
} {
  /gs_languagelevel 1 def
} ifelse

% EPSF import as in the Red Book
/BeginInclude {
  /b4_Inc_state save def    		% Save state for cleanup
  /dict_count countdictstack def	% Count objects on dict stack
  /op_count count 1 sub def		% Count objects on operand stack 
  userdict begin
    0 setgray 0 setlinecap
    1 setlinewidth 0 setlinejoin
    10 setmiterlimit [ ] 0 setdash newpath
    gs_languagelevel 1 ne {
      false setstrokeadjust false setoverprint 
    } if
} bind def

/EndInclude {
  count op_count sub { pos } repeat	% Clean up stacks
  countdictstack dict_count sub { end } repeat
  b4_Inc_state restore
} bind def

/BeginEPSF {
  BeginInclude
  /showpage { } def
} bind def

/EndEPSF {
  EndInclude
} bind def

% Page prefeed
/page_prefeed {         % bool -> -
  statusdict /prefeed known {
    statusdict exch /prefeed exch put
  } {
    pop
  } ifelse
} bind def

/deffont {
  findfont exch scalefont def
} bind def

/reencode_font {
  findfont reencode 2 copy definefont pop def
} bind def

% Function c-show (str => -)
% centers text only according to x axis.
/c-show { 
  dup stringwidth pop
  2 div neg 0 rmoveto
  show
} bind def

% Function l-show (str => -)
% prints texts so that it ends at currentpoint
/l-show {
  dup stringwidth pop neg 
  0 
  rmoveto show
} bind def

% center-fit show (str w => -)
% show centered, and scale currentfont so that the width is less than w
/cfshow {
  exch dup stringwidth pop
  % If the title is too big, try to make it smaller
  3 2 roll 2 copy
  gt
  { % if, i.e. too big
    exch div
    currentfont exch scalefont setfont
  } { % ifelse
    pop pop 
  }
  ifelse
  c-show			% center title
} bind def

% Return the y size of the current font
% - => fontsize
/currentfontsize {
  currentfont /FontType get 0 eq {
    currentfont /FontMatrix get 3 get
  }{
    currentfont /FontMatrix get 3 get 1000 mul
  } ifelse
} bind def

% reencode the font
% <encoding-vector> <fontdict> -> <newfontdict>
/reencode { %def
  dup length 5 add dict begin
    { %forall
      % <vector> <key> <val>
      1 index /FID ne 
      { def }{ pop pop } ifelse
    } forall
    /Encoding exch def % -

    % Use the font's bounding box to determine the ascent, descent,
    % and overall height; don't forget that these values have to be
    % transformed using the font's matrix.
    % We use `load' because sometimes BBox is executable, sometimes not.
    % Since we need 4 numbers an not an array avoid BBox from being executed
    /FontBBox load aload pop
    FontMatrix transform /Ascent exch def pop
    FontMatrix transform /Descent exch def pop
    /FontHeight Ascent Descent sub def

    % Get the underline position and thickness if they're defined.
    % Use 1 if they are not defined.
    currentdict /FontInfo 2 copy known
    { get
      /UnderlinePosition 2 copy % <FontInfo> /UP <FontInfo> /UP
      2 copy known
      { get }{ pop pop 1 } ifelse
      0 exch FontMatrix transform exch pop
      def % <FontInfo>

      /UnderlineThickness 2 copy % <FontInfo> /UT <FontInfo> /UT
      2 copy known
      { get }{ pop pop 1 } ifelse
      0 exch FontMatrix transform exch pop
      def % <FontInfo>
      pop % -
    }{ pop pop
    } ifelse

    currentdict
  end 
} bind def

% composite fonts for ASCII-EUC mixed strings
% Version 1.2 1/31/1990
% Original Ken'ichi HANDA (handa@etl.go.jp)
% Modified Norio Katayama (katayama@rd.nacsis.ac.jp),1998
% Extend & Fix Koji Nakamaru (maru@on.cs.keio.ac.jp), 1999
% Anyone can freely copy, modify, distribute this program.

/copyfont {	% font-dic extra-entry-count  copyfont  font-dic
	1 index maxlength add dict begin
	{	1 index /FID ne 2 index /UniqueID ne and
		{def} {pop pop} ifelse
	} forall
	currentdict
	end
} bind def

/compositefont { % ASCIIFontName EUCFontName RomanScale RomanOffset Rot(T/F) compositefont font
    /RomanRotation exch def
    /RomanOffset exch def
    /RomanScale exch def
    userdict /fixeucfont_dict known not {
	userdict begin
	    /fixeucfont_dict 2 dict begin
		/UpperByteEncoding [
		    16#00 1 16#20 { pop 0 } for
		    16#21 1 16#28 { 16#20 sub } for
		    16#29 1 16#2F { pop 0 } for
		    16#30 1 16#74 { 16#27 sub } for
		    16#75 1 16#FF { pop 0 } for
		] def
	        /LowerByteEncoding [
		    16#00 1 16#A0 { pop /.notdef } for
		    16#A1 1 16#FE { 16#80 sub 16 2 string cvrs
				    (cXX) dup 1 4 -1 roll
				    putinterval cvn } for
		    /.notdef
		] def
		currentdict
	    end def
	end
    } if
    findfont dup /FontType get 0 eq {
	14 dict begin
	    %
	    % 7+8 bit EUC font
	    %
	    12 dict begin
		/EUCFont exch def
		/FontInfo (7+8 bit EUC font) readonly def
		/PaintType 0 def
		/FontType 0 def
		/FontMatrix matrix def
		% /FontName
		/Encoding fixeucfont_dict /UpperByteEncoding get def
		/FMapType 2 def
		EUCFont /WMode known
		{ EUCFont /WMode get /WMode exch def }
		{ /WMode 0 def } ifelse
		/FDepVector [
		    EUCFont /FDepVector get 0 get
		    [ 16#21 1 16#28 {} for 16#30 1 16#74 {} for ]
		    {
			13 dict begin
			    /EUCFont EUCFont def
			    /UpperByte exch 16#80 add def	
			    % /FontName
			    /FontInfo (EUC lower byte font) readonly def
			    /PaintType 0 def
			    /FontType 3 def
			    /FontMatrix matrix def
			    /FontBBox {0 0 0 0} def
			    /Encoding
				fixeucfont_dict /LowerByteEncoding get def
			    % /UniqueID
			    % /WMode
			    /BuildChar {
				gsave
				exch dup /EUCFont get setfont
				/UpperByte get
				2 string
				dup 0 4 -1 roll put
				dup 1 4 -1 roll put
				dup stringwidth setcharwidth
				0 0 moveto show
				grestore
			    } bind def
			    currentdict
			end
			/lowerbytefont exch definefont
		    } forall
		] def
		currentdict
	    end
	    /eucfont exch definefont
	    exch
	    findfont 1 copyfont dup begin
		RomanRotation {
			/FontMatrix FontMatrix
			[ 0 RomanScale neg RomanScale 0 RomanOffset neg 0 ]
			matrix concatmatrix def
		}{
			/FontMatrix FontMatrix
			[ RomanScale 0 0 RomanScale 0 RomanOffset ] matrix concatmatrix
			def
			/CDevProc
			    {pop pop pop pop 0 exch -1000 exch 2 div 880} def
		} ifelse
	    end
	    /asciifont exch definefont
	    exch
	    /FDepVector [ 4 2 roll ] def
	    /FontType 0 def
	    /WMode 0 def
	    /FMapType 4 def
	    /FontMatrix matrix def
	    /Encoding [0 1] def
	    /FontBBox {0 0 0 0} def
%	    /FontHeight 1.0 def % XXXX
	    /FontHeight RomanScale 1.0 ge { RomanScale }{ 1.0 } ifelse def
	    /Descent -0.3 def   % XXXX
	    currentdict
	end
	/tmpfont exch definefont
	pop
	/tmpfont findfont
    }{
	pop findfont 0 copyfont
    } ifelse
} def	

/slantfont {	% FontName slant-degree  slantfont  font'
    exch findfont 1 copyfont begin
    [ 1 0 4 -1 roll 1 0 0 ] FontMatrix exch matrix concatmatrix
    /FontMatrix exch def
    currentdict
    end
} def

% Function print line number (<string> # -)
/# {
  gsave
    sx cw mul neg 2 div 0 rmoveto
    f# setfont
    c-show
  grestore
} bind def

% -------- Some routines to enlight plain b/w printings ---------

% Underline
% width --
/dounderline {
  currentpoint
  gsave
    moveto
    0 currentfont /Descent get currentfontsize mul rmoveto
    0 rlineto
    stroke
  grestore
} bind def

% Underline a string
% string --
/dounderlinestring {
  stringwidth pop
  dounderline
} bind def

/UL {
  /ul exch store
} bind def

% Draw a box of WIDTH wrt current font
% width --
/dobox {
  currentpoint
  gsave
    newpath
    moveto
    0 currentfont /Descent get currentfontsize mul rmoveto
    dup 0 rlineto
    0 currentfont /FontHeight get currentfontsize mul rlineto
    neg 0 rlineto
    closepath
    stroke
  grestore
} bind def

/BX {
  /bx exch store
} bind def

% Box a string
% string --
/doboxstring {
  stringwidth pop
  dobox
} bind def

%
% ------------- Color routines ---------------
%
/FG /setrgbcolor load def

% Draw the background
% width --
/dobackground {
  currentpoint
  gsave
    newpath
    moveto
    0 currentfont /Descent get currentfontsize mul rmoveto
    dup 0 rlineto
    0 currentfont /FontHeight get currentfontsize mul rlineto
    neg 0 rlineto
    closepath
    bgcolor aload pop setrgbcolor
    fill
  grestore
} bind def

% Draw bg for a string
% string --
/dobackgroundstring {
  stringwidth pop
  dobackground
} bind def


/BG {
  dup /bg exch store
  { mark 4 1 roll ] /bgcolor exch store } if
} bind def


/Show {
  bg { dup dobackgroundstring } if
  ul { dup dounderlinestring } if
  bx { dup doboxstring } if
  show
} bind def

% Function T(ab), jumps to the n-th tabulation in the current line
/T {
  cw mul x0 add
  bg { dup currentpoint pop sub dobackground } if
  ul { dup currentpoint pop sub dounderline } if
  bx { dup currentpoint pop sub dobox } if
  y0 moveto
} bind def

% Function n: move to the next line
/n {
  /y0 y0 bfs sub store
  x0 y0 moveto
} bind def

% Function N: show and move to the next line
/N {
  Show
  /y0 y0 bfs sub store
  x0 y0 moveto
} bind def

/S {
  Show
} bind def

%%BeginResource: procset a2ps-a2ps-hdr 2.0 2
%%Copyright: (c) 1988, 89, 90, 91, 92, 93 Miguel Santana
%%Copyright: (c) 1995, 96, 97, 98 Akim Demaille, Miguel Santana
% Function title: prints page header.
% <ct> <rt> <lt> are passed as argument
/title { 
  % 1. Draw the background
  x v get y v get moveto
  gsave
    0 th 2 div neg rmoveto 
    th setlinewidth
    0.95 setgray
    pw 0 rlineto stroke
  grestore
  % 2. Border it
  gsave
    0.7 setlinewidth
    pw 0 rlineto
    0 th neg rlineto
    pw neg 0 rlineto
    closepath stroke
  grestore
  % stk: ct rt lt
  x v get y v get th sub 1 add moveto
%%IncludeResource: font Helvetica
  fHelvetica fnfs 0.8 mul scalefont setfont
  % 3. The left title
  gsave
    dup stringwidth pop fnfs 0.8 mul add exch % leave space took on stack
    fnfs 0.8 mul hm rmoveto
    show			% left title
  grestore
  exch
  % stk: ct ltw rt
  % 4. the right title
  gsave
    dup stringwidth pop fnfs 0.8 mul add exch % leave space took on stack
    dup
    pw exch stringwidth pop fnfs 0.8 mul add sub
    hm
    rmoveto
    show			% right title
  grestore
  % stk: ct ltw rtw
  % 5. the center title
  gsave
    pw 3 1 roll
    % stk: ct pw ltw rtw
    3 copy 
    % Move to the center of the left room
    sub add 2 div hm rmoveto
    % What is the available space in here?
    add sub fnfs 0.8 mul sub fnfs 0.8 mul sub
    % stk: ct space_left
%%IncludeResource: font Helvetica-Bold
  fHelvetica-Bold fnfs scalefont setfont
    cfshow
  grestore
} bind def

% Function border: prints virtual page border
/border { %def
  gsave				% print four sides
    0 setgray
    x v get y v get moveto
    0.7 setlinewidth		% of the square
    pw 0 rlineto
    0 ph neg rlineto
    pw neg 0 rlineto
    closepath stroke
  grestore
} bind def

% Function water: prints a water mark in background
/water { %def
  gsave
    scx scy moveto rotate
%%IncludeResource: font Times-Bold
  fTimes-Bold 100 scalefont setfont
    .97 setgray
    dup stringwidth pop 2 div neg -50 rmoveto
    show
  grestore
} bind def

% Function rhead: prints the right header
/rhead {  %def
  lx ly moveto
  fHelvetica fnfs 0.8 mul scalefont setfont
  l-show
} bind def

% Function footer (cf rf lf -> -)
/footer {
  fHelvetica fnfs 0.8 mul scalefont setfont
  dx dy moveto
  show

  snx sny moveto
  l-show
  
  fnx fny moveto
  c-show
} bind def
%%EndResource
%%BeginResource: procset a2ps-black+white-Prolog 2.0 1

% Function T(ab), jumps to the n-th tabulation in the current line
/T { 
  cw mul x0 add y0 moveto
} bind def

% Function n: move to the next line
/n { %def
  /y0 y0 bfs sub store
  x0 y0 moveto
} bind def

% Function N: show and move to the next line
/N {
  Show
  /y0 y0 bfs sub store
  x0 y0 moveto
}  bind def

/S {
  Show
} bind def

/p {
  false UL
  false BX
  fCourier bfs scalefont setfont
  Show
} bind def

/sy {
  false UL
  false BX
  fSymbol bfs scalefont setfont
  Show
} bind def

/k {
  false UL
  false BX
  fCourier-Oblique bfs scalefont setfont
  Show
} bind def

/K {
  false UL
  false BX
  fCourier-Bold bfs scalefont setfont
  Show
} bind def

/c {
  false UL
  false BX
  fCourier-Oblique bfs scalefont setfont
  Show
} bind def

/C {
  false UL
  false BX
  fCourier-BoldOblique bfs scalefont setfont
  Show 
} bind def

/l {
  false UL
  false BX
  fHelvetica bfs scalefont setfont
  Show
} bind def

/L {
  false UL
  false BX
  fHelvetica-Bold bfs scalefont setfont
  Show 
} bind def

/str{
  false UL
  false BX
  fTimes-Roman bfs scalefont setfont
  Show
} bind def

/e{
  false UL
  true BX
  fHelvetica-Bold bfs scalefont setfont
  Show
} bind def

%%EndResource
%%EndProlog
%%BeginSetup
%%IncludeResource: font Courier
%%IncludeResource: font Courier-Oblique
%%IncludeResource: font Courier-Bold
%%IncludeResource: font Times-Roman
%%IncludeResource: font Symbol
%%IncludeResource: font Courier-BoldOblique
%%BeginResource: encoding ISO-8859-1Encoding
/ISO-8859-1Encoding [
/.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef 
/.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef 
/.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef 
/.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef 
/space /exclam /quotedbl /numbersign /dollar /percent /ampersand /quoteright 
/parenleft /parenright /asterisk /plus /comma /minus /period /slash 
/zero /one /two /three /four /five /six /seven 
/eight /nine /colon /semicolon /less /equal /greater /question 
/at /A /B /C /D /E /F /G 
/H /I /J /K /L /M /N /O 
/P /Q /R /S /T /U /V /W 
/X /Y /Z /bracketleft /backslash /bracketright /asciicircum /underscore 
/quoteleft /a /b /c /d /e /f /g 
/h /i /j /k /l /m /n /o 
/p /q /r /s /t /u /v /w 
/x /y /z /braceleft /bar /braceright /asciitilde /.notdef 
/.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef 
/.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef 
/.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef 
/.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef 
/space /exclamdown /cent /sterling /currency /yen /brokenbar /section 
/dieresis /copyright /ordfeminine /guillemotleft /logicalnot /hyphen /registered /macron 
/degree /plusminus /twosuperior /threesuperior /acute /mu /paragraph /bullet 
/cedilla /onesuperior /ordmasculine /guillemotright /onequarter /onehalf /threequarters /questiondown 
/Agrave /Aacute /Acircumflex /Atilde /Adieresis /Aring /AE /Ccedilla 
/Egrave /Eacute /Ecircumflex /Edieresis /Igrave /Iacute /Icircumflex /Idieresis 
/Eth /Ntilde /Ograve /Oacute /Ocircumflex /Otilde /Odieresis /multiply 
/Oslash /Ugrave /Uacute /Ucircumflex /Udieresis /Yacute /Thorn /germandbls 
/agrave /aacute /acircumflex /atilde /adieresis /aring /ae /ccedilla 
/egrave /eacute /ecircumflex /edieresis /igrave /iacute /icircumflex /idieresis 
/eth /ntilde /ograve /oacute /ocircumflex /otilde /odieresis /divide 
/oslash /ugrave /uacute /ucircumflex /udieresis /yacute /thorn /ydieresis 
] def
%%EndResource
% Initialize page description variables.
/sh 842 def
/sw 595 def
/llx 24 def
/urx 571 def
/ury 818 def
/lly 24 def
/#copies 1 def
/th 20.000000 def
/fnfs 15 def
/bfs 11.199836 def
/cw 6.719901 def

% Dictionary for ISO-8859-1 support
/iso1dict 8 dict begin
  /fCourier ISO-8859-1Encoding /Courier reencode_font
  /fCourier-Bold ISO-8859-1Encoding /Courier-Bold reencode_font
  /fCourier-BoldOblique ISO-8859-1Encoding /Courier-BoldOblique reencode_font
  /fCourier-Oblique ISO-8859-1Encoding /Courier-Oblique reencode_font
  /fHelvetica ISO-8859-1Encoding /Helvetica reencode_font
  /fHelvetica-Bold ISO-8859-1Encoding /Helvetica-Bold reencode_font
  /fTimes-Bold ISO-8859-1Encoding /Times-Bold reencode_font
  /fTimes-Roman ISO-8859-1Encoding /Times-Roman reencode_font
currentdict end def
/bgcolor [ 0 0 0 ] def
/bg false def
/ul false def
/bx false def
% The font for line numbering
/f# /Helvetica findfont bfs .6 mul scalefont def
/fSymbol /Symbol findfont def
/hm fnfs 0.25 mul def
/pw
   cw 81.400000 mul
def
/ph
   747.029046 th add
def
/pmw 0 def
/pmh 0 def
/v 0 def
/x [
  0
] def
/y [
  pmh ph add 0 mul ph add
] def
/scx sw 2 div def
/scy sh 2 div def
/snx urx def
/sny lly 2 add def
/dx llx def
/dy sny def
/fnx scx def
/fny dy def
/lx snx def
/ly ury fnfs 0.8 mul sub def
/sx 0 def
/tab 8 def
/x0 0 def
/y0 0 def
%%EndSetup

%%Page: (1) 1
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(import) K
( tensorflow as tf) p n
() N
() N
(class) K
( Adam:) p n
(    ) S
(def) K
( __init__\(self,) p n
(                 learning_rate=1e-3,) N
(                 beta_1=0.9,) N
(                 beta_2=0.999,) N
(                 epsilon=1e-7,) N
(                 weight_decay=5e-3,\):) N
(        self.learning_rate = learning_rate) N
(        self.beta_1 = beta_1) N
(        self.beta_2 = beta_2) N
(        self.epsilon = epsilon) N
(        self.weight_decay = weight_decay) N
() N
(    ) S
(def) K
( apply_gradients\() p n
(        self,) N
(        grads_and_vars) N
(    \):) N
(        ) S
(for) K
( grad, var ) p
(in) K
( grads_and_vars:) p n
(            m = tf.Variable\(tf.zeros\(shape=var.shape\)\)) N
(            v = tf.Variable\(tf.zeros\(shape=var.shape\)\)) N
(            m.assign\(self.beta_1 * m + \(1 - self.beta_1\) * tf.convert_to_tensor\() N
(grad\)\)) N
(            v.assign\(self.beta_2 * v + \(1 - self.beta_2\) * tf.convert_to_tensor\() N
(grad\) ** 2\)) N
(            m_hat = m / \(1 - self.beta_1\)) N
(            v_hat = v / \(1 - self.beta_2\)) N
(            var.assign\(var - self.learning_rate * m_hat /) N
(                       \(tf.sqrt\(v_hat\) + self.epsilon\)\)) N
(            ) S
(if) K
( \(var.name.endswith\(') p
(kernel) str
('\) ) p
(or) K
( var.name.endswith\(') p
(w) str
('\)\):) p n
(                var.assign\(var - self.weight_decay * var * self.learning_rate\)) N
(adam.py) (Page 1/1) (Nov 04, 23 17:25) title
border
grestore
(Printed by ) rhead
() (1/79) (Monday November 27, 2023) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (1) 2
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(import) K
( tensorflow as tf) p n
() N
() N
(class) K
( AugmentData:) p n
(    ) S
(def) K
( __init__\(self, augmentation_multiplier: int\):) p n
(        """) S
(Initializes the AugmentData class) str n
() N
(        Args:) N
(            augmentation_multiplier \(int\): the percentage of the data to augment,) N
(            must be between 0 and 1) N
(        ) S
(""") p n
(        self.augmentation_multiplier = augmentation_multiplier) N
() N
(    ) S
(def) K
( __call__\() p n
(        self, labels: tf.Tensor, images: tf.Tensor) N
(    \) -> tuple[tf.Tensor, tf.Tensor]:) N
(        """) S
(Takes the data and augments it,) str n
(           by applying random zooms, rotations, brightness, contrast, hue, and) N
(           saturation) N
(        Args:) N
(            images \(tf.Tensor\): a tensor of RGB images of shape) N
(            [batch_size, height, width, 3]) N
(            labels \(tf.Tensor\): a tensor of labels of shape [batch_size]) N
(        Returns:) N
(            tuple[tf.Tensor, tf.Tensor]: a tuple of the augmented images and labels,) N
(            the images have shape [batch_size +) N
(            augmentation_multiplier*batch_size*6, height, width, 3] and the labels have) N
(            shape [batch_size + augmentation_multiplier*batch_size*6]) N
(        ) S
(""") p n
() N
(        zoom_indices = tf.random.uniform\() N
(            shape=[) N
(                tf.cast\() N
(                    tf.shape\(images\)[0].numpy\(\) * self.augmentation_multiplier, ) N
(tf.int32) N
(                \)) N
(            ],) N
(            maxval=tf.shape\(images\)[0],) N
(            dtype=tf.int32,) N
(        \)) N
(        flipped_indices = tf.random.uniform\() N
(            shape=[) N
(                tf.cast\() N
(                    tf.shape\(images\)[0].numpy\(\) * self.augmentation_multiplier, ) N
(tf.int32) N
(                \)) N
(            ],) N
(            maxval=tf.shape\(images\)[0],) N
(            dtype=tf.int32,) N
(        \)) N
(        brightness_indices = tf.random.uniform\() N
(            shape=[) N
(                tf.cast\() N
(                    tf.shape\(images\)[0].numpy\(\) * self.augmentation_multiplier, ) N
(tf.int32) N
(                \)) N
(            ],) N
(            maxval=tf.shape\(images\)[0],) N
(            dtype=tf.int32,) N
(        \)) N
(        contrast_indices = tf.random.uniform\() N
(            shape=[) N
(                tf.cast\() N
(                    tf.shape\(images\)[0].numpy\(\) * self.augmentation_multiplier, ) N
(tf.int32) N
(                \)) N
(augment_data.py) (Page 1/3) (Nov 04, 23 17:25) title
border
grestore
(Printed by ) rhead
() (Monday November 27, 2023) (2/79) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (2) 3
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(            ],) p n
(            maxval=tf.shape\(images\)[0],) N
(            dtype=tf.int32,) N
(        \)) N
(        hue_indices = tf.random.uniform\() N
(            shape=[) N
(                tf.cast\() N
(                    tf.shape\(images\)[0].numpy\(\) * self.augmentation_multiplier, ) N
(tf.int32) N
(                \)) N
(            ],) N
(            maxval=tf.shape\(images\)[0],) N
(            dtype=tf.int32,) N
(        \)) N
(        saturation_indices = tf.random.uniform\() N
(            shape=[) N
(                tf.cast\() N
(                    tf.shape\(images\)[0].numpy\(\) * self.augmentation_multiplier, ) N
(tf.int32) N
(                \)) N
(            ],) N
(            maxval=tf.shape\(images\)[0],) N
(            dtype=tf.int32,) N
(        \)) N
() N
(        ) S
(# apply augmentations to the images) c n
(        zoomed_images = tf.gather\(images, zoom_indices\)) p n
(        zoomed_images = tf.image.random_crop\() N
(            zoomed_images, [zoomed_images.shape[0], 24, 24, 3]) N
(        \)) N
(        zoomed_images = tf.image.resize\(zoomed_images, [32, 32]\)) N
() N
(        flipped_images = tf.gather\(images, flipped_indices\)) N
(        flipped_images = tf.image.random_flip_left_right\(flipped_images\)) N
() N
(        brightness_images = tf.gather\(images, brightness_indices\)) N
(        brightness_images = tf.image.random_brightness\(brightness_images, 0.2\)) N
() N
(        contrast_images = tf.gather\(images, contrast_indices\)) N
(        contrast_images = tf.image.random_contrast\(contrast_images, 0.2, 0.5\)) N
() N
(        hue_images = tf.gather\(images, hue_indices\)) N
(        hue_images = tf.image.random_hue\(hue_images, 0.2\)) N
() N
(        saturation_images = tf.gather\(images, saturation_indices\)) N
(        saturation_images = tf.image.random_saturation\(saturation_images, 0.2, 0) N
(.5\)) N
() N
(        ) S
(# combine the augmented images with the original images) c n
(        output_images = tf.concat\() p n
(            [) N
(                images,) N
(                zoomed_images,) N
(                flipped_images,) N
(                brightness_images,) N
(                contrast_images,) N
(                hue_images,) N
(                saturation_images,) N
(            ],) N
(            axis=0,) N
(        \)) N
() N
(        output_labels = tf.concat\() N
(            [) N
(                labels,) N
(                tf.gather\(labels, zoom_indices\),) N
(augment_data.py) (Page 2/3) (Nov 04, 23 17:25) title
border
grestore
(Printed by ) rhead
() (3/79) (Monday November 27, 2023) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (3) 4
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(                tf.gather\(labels, flipped_indices\),) p n
(                tf.gather\(labels, brightness_indices\),) N
(                tf.gather\(labels, contrast_indices\),) N
(                tf.gather\(labels, hue_indices\),) N
(                tf.gather\(labels, saturation_indices\),) N
(            ],) N
(            axis=0,) N
(        \)) N
() N
(        ) S
(return) K
( output_labels, output_images) p n
(augment_data.py) (Page 3/3) (Nov 04, 23 17:25) title
border
grestore
(Printed by ) rhead
() (Monday November 27, 2023) (4/79) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (1) 5
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(import) K
( tensorflow as tf) p n
() N
() N
(class) K
( Conv2D\(tf.Module\):) p n
(    ) S
(def) K
( __init__\() p n
(        self,) N
(        input_channels: int,) N
(        output_channels: int,) N
(        kernel_shape: tuple[int, int],) N
(        stride: int = 1,) N
(        bias_enabled: bool = False,) N
(    \):) N
(        """) S
(Initializes the Conv2D class) str n
() N
(        Args:) N
(            input_channels \(int\): How many channels the input has,) N
(                e.g. for the first layer this is 3 for RGB images,) N
(                1 for grayscale images) N
(            output_channels \(int\): How many filters the convolution should have) N
(            kernel_shape tuple[int, int]: Uses a filter of size) N
(                kernel_height x kernel_width) N
(            stride \(int, optional\): The stride of the convolution.) N
(            bias \(bool, optional\): Whether or not to use a bias.) N
(        ) S
(""") p n
(        self.stride = stride) N
(        self.bias_enabled = bias_enabled) N
() N
(        rng = tf.random.get_global_generator\(\)) N
() N
(        ) S
(# He initialization) c n
(        stddev = tf.sqrt\(2 / \(input_channels * kernel_shape[0] * kernel_shape[1]) p n
(\)\)) N
() N
(        self.kernel = tf.Variable\() N
(            rng.normal\() N
(                shape=[) N
(                    kernel_shape[0],) N
(                    kernel_shape[1],) N
(                    input_channels,) N
(                    output_channels,) N
(                ],) N
(                stddev=stddev,) N
(            \),) N
(            trainable=True,) N
(            name=") S
(Conv2D/kernel) str
(",) p n
(        \)) N
() N
(        ) S
(if) K
( self.bias_enabled:) p n
(            self.bias = tf.Variable\() N
(                tf.constant\(0.01, shape=[output_channels]\),) N
(                trainable=True,) N
(                name=") S
(Conv2D/bias) str
(",) p n
(            \)) N
() N
(    ) S
(def) K
( __call__\(self, x: tf.Tensor\):) p n
(        """) S
(Applies the convolution to the input) str n
() N
(        Args:) N
(            input_tensor \(tf.Tensor\): The input to apply the convolution to.) N
(            Shape should be [batch_size, height, width, input_channels]) N
() N
(        Returns:) N
(            tf.Tensor: The result of the convolution with the bias added) N
(                Shape should be [batch_size, height, width, output_channels]) N
(        ) S
(""") p n
(        result = tf.nn.conv2d\() N
(conv_2d.py) (Page 1/2) (Nov 04, 23 17:25) title
border
grestore
(Printed by ) rhead
() (5/79) (Monday November 27, 2023) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (2) 6
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(            x, self.kernel, [1, self.stride, self.stride, 1], ") p
(SAME) str
(") p n
(        \)) N
(        ) S
(if) K
( self.bias_enabled:) p n
(            result = result + self.bias) N
(        ) S
(return) K
( result) p n
(conv_2d.py) (Page 2/2) (Nov 04, 23 17:25) title
border
grestore
(Printed by ) rhead
() (Monday November 27, 2023) (6/79) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (1) 7
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(import) K
( tensorflow as tf) p n
() N
() N
(class) K
( EmbedToVocabFile\(tf.Module\):) p n
(    ) S
(def) K
( __init__\(self, vocab_file, embedding_depth\):) p n
(        rng = tf.random.get_global_generator\(\)) N
() N
(        self.vocab_file = vocab_file) N
(        vocab_initializer = tf.lookup.TextFileInitializer\() N
(            vocab_file.name,) N
(            key_dtype=tf.string,) N
(            key_index=tf.lookup.TextFileIndex.WHOLE_LINE,) N
(            value_dtype=tf.int64,) N
(            value_index=tf.lookup.TextFileIndex.LINE_NUMBER,) N
(        \)) N
() N
(        self.vocab_table = tf.lookup.StaticHashTable\() N
(            vocab_initializer, default_value=-1) N
(        \)) N
() N
(        self.embedding_depth = embedding_depth) N
(        stddev = tf.cast\() N
(            tf.sqrt\(2 / \(self.vocab_table.size\(\) * embedding_depth\)\), tf.float32) N
(        \)) N
(        self.embedding = tf.Variable\() N
(            rng.normal\() N
(                shape=[self.vocab_table.size\(\), embedding_depth],) N
(                stddev=stddev,) N
(            \),) N
(            trainable=True,) N
(            name=") S
(Embedder/embedding) str
(",) p n
(        \)) N
() N
(    ) S
(def) K
( tokens_to_ids\(self, tokens\):) p n
(        """) N
(        Convert the tokens into integers.) str n
() N
(        Args:) N
(            tokens \(tf.Tensor\): The tokenized text. Shape: [batch_size, num_tokenized_words]) N
() N
(        Returns:) N
(            tf.Tensor: The integer IDs of the tokens.) N
(        ) S
(""") p n
(        ) S
(return) K
( tf.cast\(self.vocab_table.lookup\(tokens\), tf.int32\)) p n
() N
(    ) S
(def) K
( decode\(self, logits\):) p n
(        """) N
(        Decode the logits into tokens.) str n
() N
(        Args:) N
(            logits \(tf.Tensor\): The logits. Shape: [batch_size, num_tokenized_words, vocab_size]) N
() N
(        Returns:) N
(            tf.Tensor: The tokens corresponding to the logits. Shape: [batch_size, num_tokenized_words]) N
(        ) S
(""") p n
(        reverse_vocab = []) N
(        with open\(self.vocab_file.name, ") S
(r) str
(", encoding=") p
(utf-8) str
("\) as f:) p n
(            ) S
(for) K
( line ) p
(in) K
( f:) p n
(                reverse_vocab.append\(line.strip\(\)\)) N
() N
(        ) S
(# Get the most likely token ID for each embedding) c n
(        probabilities = tf.nn.softmax\(logits, axis=-1\)) p n
() N
(        ) S
(# Get the most likely token ID for each embedding) c n
(        token_ids = tf.argmax\(probabilities, axis=-1, output_type=tf.int64\)) p n
() N
(embed_to_vocab_file.py) (Page 1/2) (Nov 12, 23 7:03) title
border
grestore
(Printed by ) rhead
() (7/79) (Monday November 27, 2023) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (2) 8
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(        ) p
(# Convert the token IDs into tokens) c n
(        tokens = tf.gather\(reverse_vocab, token_ids\)) p n
() N
(        ) S
(return) K
( tokens) p n
() N
(    ) S
(def) K
( get_vocab_size\(self\):) p n
(        """) N
(        Get the size of the vocabulary.) str n
() N
(        Returns:) N
(            int: The size of the vocabulary) N
(        ) S
(""") p n
(        ) S
(return) K
( tf.cast\(self.vocab_table.size\(\), tf.int32\)) p n
() N
(    ) S
(def) K
( __call__\(self, tokens\):) p n
(        """) N
(        Embed the tokenized text.) str n
() N
(        Args:) N
(            tokens \(tf.Tensor\): The tokenized text. Shape: [batch_size, num_tokenized_words]) N
() N
(        Returns:) N
(            tf.Tensor: The embeddings of the tokens.) N
(            Shape should be [batch_size, num_tokenized_words, embedding_depth]) N
(        ) S
(""") p n
(        token_ids = self.tokens_to_ids\(tokens\)) N
(        embeddings = tf.nn.embedding_lookup\(self.embedding, token_ids\)) N
(        ) S
(return) K
( embeddings) p n
(embed_to_vocab_file.py) (Page 2/2) (Nov 12, 23 7:03) title
border
grestore
(Printed by ) rhead
() (Monday November 27, 2023) (8/79) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (1) 9
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(import) K
( tensorflow as tf) p n
() N
() N
(class) K
( Embedder\(tf.Module\):) p n
(    ) S
(def) K
( __init__\(self, embedding_buckets, embedding_depth\):) p n
(        rng = tf.random.get_global_generator\(\)) N
() N
(        self.embedding_buckets = embedding_buckets) N
(        self.embedding_depth = embedding_depth) N
(        stddev = tf.sqrt\(2 / \(embedding_buckets * embedding_depth\)\)) N
(        self.embedding = tf.Variable\() N
(            rng.normal\() N
(                shape=[) N
(                    embedding_buckets,) N
(                    embedding_depth,) N
(                ],) N
(                stddev=stddev,) N
(            \),) N
(            trainable=True,) N
(            name=") S
(Embedder/embedding) str
(",) p n
(        \)) N
() N
(    ) S
(def) K
( __call__\(self, tokens\):) p n
(        """) N
(        Embed the tokenized text.) str n
() N
(        Args:) N
(            tokens \(tf.Tensor\): The tokenized text. Shape: [batch_size, num_tokenized_words]) N
() N
(        Returns:) N
(            tf.Tensor: The embeddings of the tokens.) N
(            Shape should be [batch_size, num_tokenized_words, embedding_depth]) N
(        ) S
(""") p n
(        hashed_tokens = tf.strings.to_hash_bucket_fast\(tokens, self.embedding_bu) N
(ckets\)) N
() N
(        embeddings = tf.nn.embedding_lookup\(self.embedding, hashed_tokens\)) N
() N
(        ) S
(return) K
( embeddings) p n
(embedder.py) (Page 1/1) (Nov 11, 23 23:33) title
border
grestore
(Printed by ) rhead
() (9/79) (Monday November 27, 2023) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (1) 10
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(import) K
( tensorflow as tf) p n
() N
() N
(class) K
( GroupNorm\(tf.Module\):) p n
(    ) S
(def) K
( __init__\() p n
(        self,) N
(        num_groups: int,) N
(        input_depth: int,) N
(        input_channels: int = 2,) N
(        epsilon: float = 1e-5,) N
(    \):) N
(        """) S
(Initializes the GroupNorm class) str n
() N
(        Args:) N
(            num_groups \(int\): the number of groups to split the channels into) N
(            input_depth \(int\): the depth of the input tensor) N
(            input_channels \(int\): the number of channels in the input tensor) N
(            epsilon \(float, optional\): small value for numerical stability.) N
(                Defaults to 1e-5.) N
(        ) S
(""") p n
(        self.num_groups = int\(num_groups\)) N
(        self.epsilon = epsilon) N
(        self.input_depth = input_depth) N
(        self.input_channels = input_channels) N
() N
(        ) S
(if) K
( input_channels == 1:) p n
(            self.gamma = tf.Variable\() N
(                tf.ones\(shape=[1, 1, input_depth]\),) N
(                trainable=True,) N
(                name=") S
(GroupNorm/gamma) str
(",) p n
(            \)) N
() N
(            self.beta = tf.Variable\() N
(                tf.zeros\(shape=[1, 1, input_depth]\),) N
(                trainable=True,) N
(                name=") S
(GroupNorm/beta) str
(",) p n
(            \)) N
() N
(        ) S
(elif) K
( input_channels == 2:) p n
(            self.gamma = tf.Variable\() N
(                tf.ones\(shape=[1, 1, 1, input_depth]\),) N
(                trainable=True,) N
(                name=") S
(GroupNorm/gamma) str
(",) p n
(            \)) N
() N
(            self.beta = tf.Variable\() N
(                tf.zeros\(shape=[1, 1, 1, input_depth]\),) N
(                trainable=True,) N
(                name=") S
(GroupNorm/beta) str
(",) p n
(            \)) N
() N
(    ) S
(def) K
( __call__\(self, x: tf.Tensor\) -> tf.Tensor:) p n
(        """) S
(Applies group normalization to the input tensor) str n
() N
(        Args:) N
(            x \(tf.Tensor\): the input tensor) N
() N
(        Returns:) N
(            tf.Tensor: the normalized tensor) N
(        ) S
(""") p n
(        ) S
(if) K
( self.input_channels == 1:) p n
(            \() N
(                batch_size,) N
(                context_length,) N
(                model_dim,) N
(            \) = x.shape) N
(group_norm.py) (Page 1/2) (Nov 09, 23 19:09) title
border
grestore
(Printed by ) rhead
() (Monday November 27, 2023) (10/79) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (2) 11
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(            x = tf.reshape\() p n
(                x,) N
(                [) N
(                    batch_size,) N
(                    context_length,) N
(                    self.num_groups,) N
(                    model_dim // self.num_groups,) N
(                ],) N
(            \)) N
() N
(            mean, variance = tf.nn.moments\(x, axes=[1, 3], keepdims=True\)) N
(            x = \(x - mean\) / tf.sqrt\(variance + self.epsilon\)) N
() N
(            x = tf.reshape\(x, [batch_size, context_length, model_dim]\)) N
() N
(        ) S
(elif) K
( self.input_channels == 2:) p n
(            \() N
(                batch_size,) N
(                input_height,) N
(                input_width,) N
(                input_depth,) N
(            \) = x.shape) N
(            x = tf.reshape\() N
(                x,) N
(                [) N
(                    batch_size,) N
(                    input_height,) N
(                    input_width,) N
(                    self.num_groups,) N
(                    input_depth // self.num_groups,) N
(                ],) N
(            \)) N
() N
(            mean, variance = tf.nn.moments\(x, axes=[1, 2, 4], keepdims=True\)) N
(            x = \(x - mean\) / tf.sqrt\(variance + self.epsilon\)) N
() N
(            x = tf.reshape\(x, [batch_size, input_height, input_width, input_dept) N
(h]\)) N
() N
(        ) S
(return) K
( x * self.gamma + self.beta) p n
(group_norm.py) (Page 2/2) (Nov 09, 23 19:09) title
border
grestore
(Printed by ) rhead
() (11/79) (Monday November 27, 2023) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (1) 12
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(import) K
( idx2numpy) p n
(import) K
( tensorflow as tf) p n
() N
() N
(def) K
( load_idx_data\() p n
(    filename: str,) N
(\):) N
(    """) S
(Uses idx2numpy to load an idx file into a tensor) str n
() N
(    Args:) N
(        filename \(str\): The path to the idx file) N
() N
(    Returns:) N
(        tf.tensor: The tensor containing the data from the idx file) N
(    ) S
(""") p n
(    idx2numpy.convert_from_file\(filename\)) N
(    numpy_data = idx2numpy.convert_from_file\(filename\)) N
(    ) S
(return) K
( tf.convert_to_tensor\(numpy_data\)[..., tf.newaxis]) p n
(load_idx_data.py) (Page 1/1) (Nov 07, 23 1:22) title
border
grestore
(Printed by ) rhead
() (Monday November 27, 2023) (12/79) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (1) 13
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(import) K
( pickle) p n
(from) K
( pathlib ) p
(import) K
( Path) p n
(import) K
( tensorflow as tf) p n
() N
() N
(def) K
( load_pickle_data\(filename: Path, label_id: str = ") p
(labels) str
(", data_id: str = ") p
(data) str
() p n
("\):) N
(    """) S
(Load data from a pickle file. Convert into a tensorflow dataset.) str n
(    Return the labels and images as a tuple.) N
() N
(    Args:) N
(        filename \(Path\): Path to the pickle file.) N
() N
(    Returns:) N
(        tuple: Tuple of labels and images.) N
(    ) S
(""") p n
(    with open\(filename, ') S
(rb) str
('\) as fo:) p n
(        data = pickle.load\(fo, encoding=') S
(bytes) str
('\)) p n
() N
(    label_id = tf.cast\(data[label_id.encode\(') S
(utf-8) str
('\)], tf.int32\)) p n
(    data = tf.cast\(data[data_id.encode\(') S
(utf-8) str
('\)], tf.float32\)) p n
() N
(    ) S
(# data -- a 10000x3072 numpy array of uint8s. Each row of the array stores) c n
(    ) p
(# a 32x32 colour image. The first 1024 entries contain the red channel) c n
(    ) p
(# values, the next 1024 the green, and the final 1024 the blue. The image) c n
(    ) p
(# is stored in row-major order, so that the first 32 entries of the array) c n
(    ) p
(# are the red channel values of the first row of the image.) c n
() p n
(    data = tf.reshape\(data, [-1, 3, 32, 32]\)) N
(    ) S
(# convert from \(batch_size, depth, height, width\) to) c n
(    ) p
(# \(batch_size, height, width, depth\)) c n
(    data = tf.transpose\(data, [0, 2, 3, 1]\)) p n
() N
(    data = tf.cast\(data, tf.float32\)/255.0) N
(    ) S
(return) K
( label_id, data) p n
(load_pickle_data.py) (Page 1/1) (Nov 04, 23 17:25) title
border
grestore
(Printed by ) rhead
() (13/79) (Monday November 27, 2023) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (1) 14
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(import) K
( numpy as np) p n
(import) K
( tensorflow as tf) p n
() N
() N
(class) K
( PositionalEncoding\(tf.Module\):) p n
(    """) S
(PositionalEncoding layer.) str n
() N
(    This is an implementation of positional encoding as described in the) N
(    paper ) S
("Attention ) p
(is) K
( all you Need") p
( \(Vaswani et al., 2017\).) str n
() N
(    This layer first calculates a positional encoding matrix, then adds it to) N
(    the inputs.) N
() N
(    Args:) N
(        max_position: Maximum position to encode.) N
(        model_dim: Size of each attention head for value, query, and queue.) N
() N
(    Call arguments:) N
(        inputs: Input `Tensor` of shape `\(B, seq_len, model_dim\)`.) N
() N
(    Returns:) N
(        output: The result of the computation, of shape `\(B, seq_len, model_dim\)`,) N
(    ) S
(""") p n
() N
(    ) S
(# FIXME: this whole thing is a mess) c n
(    ) p
(def) K
( __init__\(self, max_position, model_dim\):) p n
(        super\(PositionalEncoding, self\).__init__\(\)) N
(        self.positional_encoding = self._calculate_positional_encoding\() N
(            max_position, model_dim) N
(        \)) N
() N
(    ) S
(def) K
( _calculate_positional_encoding\(self, max_position, model_dim\):) p n
(        positions = np.arange\(max_position\)[:, np.newaxis]) N
(        div_term = np.exp\(-np.arange\(0, model_dim, 2\) * \(np.log\(10000.0\) / model) N
(_dim\)\)) N
(        positional_encoding = np.zeros\(\(max_position, model_dim\)\)) N
(        positional_encoding[:, 0::2] = np.sin\(positions * div_term\)) N
(        positional_encoding[:, 1::2] = np.cos\(positions * div_term\)) N
(        ) S
(return) K
( tf.convert_to_tensor\() p n
(            positional_encoding[np.newaxis, ...], dtype=tf.float32) N
(        \)) N
() N
(    ) S
(def) K
( __call__\(self, inputs\):) p n
(        ) S
(return) K
( inputs + self.positional_encoding[:, : inputs.shape[1], :]) p n
(positional_encoding.py) (Page 1/1) (Nov 08, 23 11:37) title
border
grestore
(Printed by ) rhead
() (Monday November 27, 2023) (14/79) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (1) 15
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(import) K
( einops) p n
(import) K
( tensorflow as tf) p n
() N
() N
(class) K
( Tokenizer\(tf.Module\):) p n
(    ) S
(def) K
( __init__\(self, num_word_to_tokenize, pre_batched=True\):) p n
(        self.num_word_to_tokenize = num_word_to_tokenize) N
(        self.pre_batched = pre_batched) N
() N
(    ) S
(def) K
( __call__\(self, text: tf.Tensor\):) p n
(        """) N
(        Tokenize the input text.) str n
() N
(        Args:) N
(            text \(tf.Tensor\): The text to tokenize. Shape: [batch_size, text_length]) N
() N
(        Returns:) N
(            tokens \(tf.Tensor\): The tokenized text. Shape: [batch_size, num_word_to_tokenize]) N
(        ) S
(""") p n
(        tokens = tf.strings.split\(text, sep=") S
( ) str
("\)) p n
(        ) S
(if) K
( self.pre_batched:) p n
(            tokens = tokens[:, : self.num_word_to_tokenize]) N
(            tokens = tokens.to_tensor\(default_value=b") S
(<PAD>) str
("\)) p n
(            ) S
(if) K
( tokens.shape[1] < self.num_word_to_tokenize:) p n
(                tokens = tf.pad\() N
(                    tokens,) N
(                    [) N
(                        [0, 0],) N
(                        [0, self.num_word_to_tokenize - tokens.shape[1]],) N
(                    ],) N
(                    constant_values=b") S
(<PAD>) str
(",) p n
(                \)) N
(        ) S
(else) K
(:) p n
(            ) S
(# Pad the sequence with <PAD> tokens to make it a multiple of contex) c n
(t_length) N
(            num_tokens = tokens.shape[0]) p n
(            remainder = num_tokens % \(self.num_word_to_tokenize\)) N
() N
(            ) S
(if) K
( remainder != 0:) p n
(                tokens = tf.pad\() N
(                    tokens,) N
(                    [[0, \(self.num_word_to_tokenize\) - remainder]],) N
(                    constant_values=b") S
(<PAD>) str
(",) p n
(                \)) N
() N
(            tokens = einops.rearrange\() N
(                tokens,) N
(                ") S
(\(batch context_length\) -> batch context_length) str
(",) p n
(                context_length=self.num_word_to_tokenize,) N
(            \)) N
() N
(        ) S
(return) K
( tokens) p n
(tokenizer.py) (Page 1/1) (Nov 12, 23 5:30) title
border
grestore
(Printed by ) rhead
() (15/79) (Monday November 27, 2023) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (1) 16
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(import) K
( tensorflow as tf) p n
() N
() N
(class) K
( BasisExpansion\(tf.Module\):) p n
(    ) S
(def) K
( __init__\(self, num_bases, num_inputs, num_outputs\):) p n
(        rng = tf.random.get_global_generator\(\)) N
() N
(        stddev = tf.math.sqrt\(2 / \(num_inputs + num_outputs\)\)) N
() N
(        self.mu = tf.Variable\() N
(            rng.normal\(shape=[num_inputs, num_bases], stddev=stddev\),) N
(            trainable=True,) N
(            name=") S
(BasisExpansion/mu) str
(",) p n
(        \)) N
() N
(        self.sigma = tf.Variable\() N
(            rng.normal\(shape=[num_inputs, num_bases], stddev=stddev\),) N
(            trainable=True,) N
(            name=") S
(BasisExpansion/sigma) str
(",) p n
(        \)) N
() N
(    ) S
(def) K
( __call__\(self, x\):) p n
(        z = tf.exp\(-\(x - self.mu\)**2 / \(self.sigma**2\)\)) N
() N
(        ) S
(return) K
( z) p n
(basis_expansion.py) (Page 1/1) (Nov 04, 23 17:25) title
border
grestore
(Printed by ) rhead
() (Monday November 27, 2023) (16/79) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (1) 17
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(import) K
( tensorflow as tf) p n
() N
(from) K
( modules.mlp ) p
(import) K
( MLP) p n
(from) K
( modules.residual_block ) p
(import) K
( ResidualBlock) p n
() N
() N
(class) K
( Classifier\(tf.Module\):) p n
(    ) S
(def) K
( __init__\() p n
(        self,) N
(        input_depth: int,) N
(        layer_depths: list[int],) N
(        layer_kernel_sizes: list[tuple[int, int]],) N
(        num_classes: int,) N
(        input_size: int,) N
(        resblock_size: int = 2,) N
(        pool_size: int = 2,) N
(        dropout_prob: float = 0.5,) N
(        group_norm_num_groups: int = 32,) N
(        num_hidden_layers: int = 1,) N
(        hidden_layer_width: int = 128,) N
(    \):) N
(        """) S
(Initializes the Classifier class) str n
() N
(        Args:) N
(            input_depth \(int\): number of input channels,) N
(                e.g. this is 3 for RGB images, 1 for grayscale images) N
(            layer_depths \(list[int]\): A list of how many filters each layer) N
(                should have the length of this list determines how many layers) N
(                the network has) N
(            layer_kernel_sizes \(list[tuple[int, int]]\): A list of the kernel) N
(                sizes for each layer, the length of this list should be the) N
(                same as the length of layer_depths) N
(            num_classes \(int\): How many classes the network should classify) N
(                affects the output size of the call) N
(            input_size \(int\): The size of the input image, the image should be) N
(                square, e.g. 28 for MNIST) N
(            num_hidden_layers \(int\): The number of hidden layers in the MLP) N
(            hidden_layer_width \(int\): The width of the hidden layers in the MLP) N
(            pool_every_n_layers \(int, optional\): Adds a max pooling layer) N
(                every n layers. Defaults to 0. Aka, no) N
(                pooling layers.) N
(            pool_size \(int, optional\): The size of the kernel for the max) N
(                pooling layer. Defaults to 2.) N
(            dropout_prob \(float, optional\): The probability of dropping a node) N
(            group_norm_num_groups \(int, optional\): The number of groups to) N
(            split the channels into for group normalization. Defaults to 32.) N
(        ) S
(""") p n
(        self.layer_kernel_sizes = layer_kernel_sizes) N
(        self.input_size = input_size) N
(        self.pool_size = pool_size) N
(        self.dropout_prob = dropout_prob) N
() N
(        self.flatten_size = layer_depths[-1]) N
() N
(        self.residual_blocks = []) N
(        ) S
(for) K
( layer_depth, layer_kernel_size, group_norm_num ) p
(in) K
( zip\() p n
(            layer_depths, self.layer_kernel_sizes, group_norm_num_groups) N
(        \):) N
(            self.residual_blocks.append\() N
(                ResidualBlock\() N
(                    input_depth,) N
(                    layer_depth,) N
(                    layer_kernel_size,) N
(                    group_norm_num,) N
(                    resblock_size,) N
(                \)) N
(classifier.py) (Page 1/2) (Nov 04, 23 17:25) title
border
grestore
(Printed by ) rhead
() (17/79) (Monday November 27, 2023) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (2) 18
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(            \)) p n
(            input_depth = layer_depth) N
() N
(        self.fully_connected = MLP\() N
(            self.flatten_size,) N
(            num_classes,) N
(            num_hidden_layers,) N
(            hidden_layer_width,) N
(            hidden_activation=tf.nn.relu,) N
(            zero_init=True,) N
(        \)) N
() N
(    ) S
(def) K
( __call__\(self, x: tf.Tensor\):) p n
(        """) S
(Applies the classifier to the input,) str n
() N
(        Args:) N
(            x \(tf.Tensor\): The Image to classify, should have shape) N
(                [batch_size, input_size, input_size, input_depth]) N
() N
(        Returns:) N
(            tf.Tensor: The logits of the classification, should have shape) N
(                [batch_size, num_classes]) N
(        ) S
(""") p n
() N
(        ) S
(for) K
( residual_block ) p
(in) K
( self.residual_blocks:) p n
(            x = residual_block\(x\)) N
() N
(        x = tf.nn.max_pool2d\(x, self.pool_size, strides=2, padding=") S
(VALID) str
("\)) p n
() N
(        x = tf.nn.dropout\(x, rate=self.dropout_prob\)) N
() N
(        ) S
(if) K
( self.flatten_size != \(x.shape[3]\):) p n
(            ) S
(raise) K
( ValueError\(") p
(Flatten size does not match output tensor shape) str
("\)) p n
() N
(        x = tf.nn.avg_pool2d\(x, [x.shape[1], x.shape[2]], strides=1, padding=") S
(V) str n
(ALID) S
("\)) p n
() N
(        x = tf.reshape\(x, [-1, self.flatten_size]\)) N
() N
(        x = self.fully_connected\(x\)) N
() N
(        ) S
(return) K
( x) p n
(classifier.py) (Page 2/2) (Nov 04, 23 17:25) title
border
grestore
(Printed by ) rhead
() (Monday November 27, 2023) (18/79) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (1) 19
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(import) K
( tensorflow as tf) p n
() N
(from) K
( helpers.embedder ) p
(import) K
( Embedder) p n
(from) K
( helpers.tokenizer ) p
(import) K
( Tokenizer) p n
(from) K
( modules.mlp ) p
(import) K
( MLP) p n
() N
() N
(class) K
( EmbedClassifier\(tf.Module\):) p n
(    ) S
(def) K
( __init__\() p n
(        self,) N
(        num_embedding,) N
(        embedding_depth,) N
(        num_word_to_tokenize,) N
(        dropout_prob,) N
(        num_hidden_layers,) N
(        hidden_layer_width,) N
(        num_classes,) N
(    \):) N
(        self.num_word_to_tokenize = num_word_to_tokenize) N
(        self.embedding_depth = embedding_depth) N
(        self.tokenizer = Tokenizer\(num_word_to_tokenize\)) N
(        self.embedder = Embedder\(num_embedding, embedding_depth\)) N
() N
(        self.mlp = MLP\() N
(            num_word_to_tokenize * embedding_depth,) N
(            num_classes,) N
(            num_hidden_layers,) N
(            hidden_layer_width,) N
(            tf.nn.relu,) N
(            tf.nn.softmax,) N
(            dropout_prob,) N
(        \)) N
() N
(    ) S
(def) K
( __call__\(self, text: tf.Tensor\):) p n
(        """) S
(Applies the embedding and MLP to the text.) str n
() N
(        Args:) N
(            text \(tf.Tensor\): The text to tokenize.) N
(            Shape should be [batch_size]) N
() N
(        Returns:) N
(            tf.Tensor: The logits of the classes.) N
(            Shape should be [batch_size, num_classes]) N
(        ) S
(""") p n
() N
(        tokens = self.tokenizer\(text\)) N
(        embeddings = self.embedder\(tokens\)) N
() N
(        embeddings = tf.reshape\() N
(            embeddings, [-1, self.num_word_to_tokenize * self.embedding_depth]) N
(        \)) N
() N
(        ) S
(return) K
( self.mlp\(embeddings\)) p n
(embed_classifier.py) (Page 1/1) (Nov 09, 23 17:49) title
border
grestore
(Printed by ) rhead
() (19/79) (Monday November 27, 2023) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (1) 20
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(import) K
( tensorflow as tf) p n
() N
() N
(class) K
( Linear\(tf.Module\):) p n
(    ) S
(def) K
( __init__\() p n
(        self,) N
(        num_inputs,) N
(        num_outputs,) N
(        bias=True,) N
(        zero_init=False,) N
(    \):) N
(        rng = tf.random.get_global_generator\(\)) N
() N
(        stddev = tf.cast\(tf.math.sqrt\(2 / \(num_inputs + num_outputs\)\), tf.float3) N
(2\)) N
() N
(        self.bias = bias) N
() N
(        ) S
(if) K
( zero_init:) p n
(            self.w = tf.Variable\() N
(                tf.zeros\(shape=[num_inputs, num_outputs]\),) N
(                trainable=True,) N
(                name=") S
(Linear/w) str
(",) p n
(            \)) N
(        ) S
(else) K
(:) p n
(            self.w = tf.Variable\() N
(                rng.normal\(shape=[num_inputs, num_outputs], stddev=stddev\),) N
(                trainable=True,) N
(                name=") S
(Linear/w) str
(",) p n
(            \)) N
() N
(        ) S
(if) K
( self.bias:) p n
(            self.b = tf.Variable\() N
(                tf.zeros\() N
(                    shape=[1, num_outputs],) N
(                \),) N
(                trainable=True,) N
(                name=") S
(Linear/b) str
(",) p n
(            \)) N
() N
(    ) S
(# create the logits by multiplying the inputs by the weights + the) c n
(    ) p
(# optional bias) c n
(    ) p
(def) K
( __call__\(self, x\):) p n
(        z = x @ self.w) N
() N
(        ) S
(if) K
( self.bias:) p n
(            z += self.b) N
() N
(        ) S
(return) K
( z) p n
(linear.py) (Page 1/1) (Nov 12, 23 5:30) title
border
grestore
(Printed by ) rhead
() (Monday November 27, 2023) (20/79) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (1) 21
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(import) K
( tensorflow as tf) p n
() N
(from) K
( modules.linear ) p
(import) K
( Linear) p n
() N
() N
(class) K
( MLP\(tf.Module\):) p n
(    ) S
(def) K
( __init__\() p n
(        self,) N
(        num_inputs,) N
(        num_outputs,) N
(        num_hidden_layers=0,) N
(        hidden_layer_width=0,) N
(        hidden_activation=tf.identity,) N
(        output_activation=tf.identity,) N
(        dropout_prob=0,) N
(        zero_init=False,) N
(    \):) N
(        self.num_inputs = num_inputs) N
(        self.num_outputs = num_outputs) N
(        self.num_hidden_layers = num_hidden_layers) N
(        self.hidden_layer_width = hidden_layer_width) N
(        self.hidden_activation = hidden_activation) N
(        self.output_activation = output_activation) N
(        self.hidden_linear = \() N
(            Linear\(self.hidden_layer_width, self.hidden_layer_width\)) N
(            ) S
(if) K
( self.num_hidden_layers > 0) p n
(            ) S
(else) K
( None) p n
(        \)) N
(        self.first_linear = Linear\(num_inputs, hidden_layer_width\)) N
(        self.final_linear = Linear\() N
(            self.hidden_layer_width, self.num_outputs, zero_init=zero_init) N
(        \)) N
(        self.dropout_prob = dropout_prob) N
() N
(    ) S
(def) K
( __call__\(self, x\):) p n
(        """) S
(Applies the MLP to the input) str n
() N
(        Args:) N
(            x \(tf.tensor\): input tensor of shape [batch_size, num_inputs]) N
() N
(        Returns:) N
(            tf.tensor: output tensor of shape [batch_size, num_outputs]) N
(        ) S
(""") p n
(        x = self.hidden_activation\(self.first_linear\(x\)\)) N
() N
(        ) S
(for) K
( _ ) p
(in) K
( range\(self.num_hidden_layers\):) p n
(            x = self.hidden_activation\(self.hidden_linear\(x\)\)) N
() N
(        ) S
(if) K
( self.dropout_prob > 0:) p n
(            x = tf.nn.dropout\(x, self.dropout_prob\)) N
() N
(        ) S
(return) K
( self.output_activation\(self.final_linear\(x\)\)) p n
(mlp.py) (Page 1/1) (Nov 07, 23 12:36) title
border
grestore
(Printed by ) rhead
() (21/79) (Monday November 27, 2023) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (1) 22
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(import) K
( einops) p n
(import) K
( tensorflow as tf) p n
() N
(from) K
( modules.linear ) p
(import) K
( Linear) p n
() N
() N
(class) K
( MultiHeadAttention\(tf.Module\):) p n
(    """) S
(MultiHeadAttention layer.) str n
() N
(    This is an implementation of multi-headed attention as described in the) N
(    paper ) S
("Attention ) p
(is) K
( all you Need") p
( \(Vaswani et al., 2017\).) str n
() N
(    This layer first projects `query`, `key` and `value`. These are) N
(    \(effectively\) a list of tensors of length `num_heads`, where the) N
(    corresponding shapes are `\(batch_size, seq_len, model_dim\)`) N
() N
(    Then, the query and key tensors are dot-producted and scaled. These are) N
(    softmaxed to obtain attention probabilities. The value tensors are then) N
(    interpolated by these probabilities, then concatenated back to a single) N
(    tensor.) N
() N
(    Finally, the result tensor with the last dimension as model_dim can take an) N
(    linear projection and return.) N
() N
(    Args:) N
(        num_heads: Number of attention heads.) N
(        model_dim: Size of each attention head for value, query, and queue.) N
(        dropout: Dropout probability.) N
() N
(    Call arguments:) N
(        query: Query `Tensor` of shape `\(B, seq_len, model_dim\)`.) N
(        value: Value `Tensor` of shape `\(B, seq_len, model_dim\)`.) N
(        key: Optional key `Tensor` of shape `\(B, seq_len, model_dim\)`. If not given, will use `value` for both `key` and `v) N
(alue`, which is the most common case.) N
(        mask: Optional mask tensor of shape `\(B, seq_len, seq_len\)`.) N
() N
(    Returns:) N
(        output: The result of the computation, of shape `\(B, seq_len, model_dim\)`,) N
(    ) S
(""") p n
() N
(    ) S
(def) K
( __init__\(self, num_heads, model_dim, dropout_prob=0.1\):) p n
(        self.num_heads = num_heads) N
(        self.model_dim = model_dim) N
(        self.dropout_prob = dropout_prob) N
() N
(        assert model_dim % num_heads == 0) N
() N
(        self.depth = model_dim // num_heads) N
() N
(        self.wq = Linear\(model_dim, model_dim\)) N
(        self.wk = Linear\(model_dim, model_dim\)) N
(        self.wv = Linear\(model_dim, model_dim\)) N
(        self.wo = Linear\(model_dim, model_dim\)) N
() N
(    ) S
(def) K
( _split_heads\(self, inputs\):) p n
(        """) S
(Split the last dimension into \(num_heads, depth\). Transpose and organize the result) str n
() N
(        Args:) N
(            inputs: input tensor of shape `\(batch_size, seq_len, model_dim\)`) N
(            batch_size: batch size) N
() N
(        Returns:) N
(            A tensor with shape `\(batch_size, num_heads, seq_len, depth\)`) N
(        ) S
(""") p n
(        output = einops.rearrange\() N
(            inputs,) N
(multi_head_attention.py) (Page 1/2) (Nov 12, 23 19:58) title
border
grestore
(Printed by ) rhead
() (Monday November 27, 2023) (22/79) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (2) 23
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(            ") p
(batch seq \(heads depth\) -> batch heads seq depth) str
(",) p n
(            heads=self.num_heads,) N
(        \)) N
() N
(        ) S
(return) K
( output) p n
() N
(    ) S
(def) K
( _scaled_dot_product_attention\(self, q, k, v, mask=None\):) p n
(        """) S
(Scaled dot product attention) str n
() N
(        Args:) N
(            q: query tensor of shape `\(batch_size, num_heads, seq_len, depth\)`) N
(            k: key tensor of shape `\(batch_size, num_heads, seq_len, depth\)`) N
(            v: value tensor of shape `\(batch_size, num_heads, seq_len, depth\)`) N
(            mask: optional mask tensor of shape `\(batch_size, seq_len, seq_len\)`) N
() N
(        Returns:) N
(            output: output tensor of shape `\(batch_size, num_heads, seq_len, depth\)`) N
(        ) S
(""") p n
(        ) S
(# matmul q and k while transposing k: \(batch_size, num_heads, seq_len, s) c n
(eq_len\)) N
(        ) p
(# Transpose the last two dimensions of k) c n
(        k_transposed = tf.transpose\(k, [0, 1, 3, 2]\)) p n
(        matmul_qk = tf.einsum\(") S
(bnqd,bndk->bnqk) str
(", q, k_transposed\)) p n
() N
(        scaled_attention_logits = matmul_qk / tf.math.sqrt\() N
(            tf.cast\(self.depth, tf.float32\)) N
(        \)) N
() N
() N
(        ) S
(if) K
( mask ) p
(is) K
( ) p
(not) K
( None:) p n
(            ) S
(# stack the mask so it can be applied to each head) c n
(            mask = tf.stack\([mask ) p
(for) K
( _ ) p
(in) K
( range\(self.num_heads\)], axis=1\)) p n
() N
(            ) S
(# we want -inf where mask is 1 because of the softmax) c n
(            scaled_attention_logits += mask * -1e9) p n
() N
(        ) S
(# Apply softmax to turn the attention scores into probabilities) c n
(        attention_weights = tf.nn.softmax\(scaled_attention_logits, axis=-1\)) p n
() N
(        output = tf.matmul\(attention_weights, v\)) N
() N
(        ) S
(return) K
( output) p n
() N
(    ) S
(def) K
( __call__\(self, query, value, key=None, mask=None\):) p n
(        key = value ) S
(if) K
( key ) p
(is) K
( None ) p
(else) K
( key) p n
() N
(        query = self.wq\(query\)) N
(        key = self.wk\(key\)) N
(        value = self.wv\(value\)) N
() N
(        query = self._split_heads\(query\)) N
(        key = self._split_heads\(key\)) N
(        value = self._split_heads\(value\)) N
() N
(        scaled_attention = self._scaled_dot_product_attention\(query, key, value,) N
( mask\)) N
() N
(        scaled_attention = einops.rearrange\() N
(            scaled_attention, ") S
(batch heads seq depth -> batch seq \(heads depth\)) str
(") p n
(        \)) N
() N
(        output = self.wo\(scaled_attention\)) N
() N
(        ) S
(return) K
( output) p n
(multi_head_attention.py) (Page 2/2) (Nov 12, 23 19:58) title
border
grestore
(Printed by ) rhead
() (23/79) (Monday November 27, 2023) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (1) 24
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(import) K
( tensorflow as tf) p n
() N
(from) K
( helpers.conv_2d ) p
(import) K
( Conv2D) p n
(from) K
( helpers.group_norm ) p
(import) K
( GroupNorm) p n
() N
() N
(class) K
( ResidualBlock\(tf.Module\):) p n
(    ) S
(def) K
( __init__\() p n
(        self,) N
(        input_depth,) N
(        output_depth,) N
(        kernel_size,) N
(        group_norm_num_groups,) N
(        resblock_size=2,) N
(    \):) N
(        """) S
(Initializes the ResidualBlock class) str n
() N
(        Args:) N
(            input_depth \(int\): the number of input channels) N
(            output_depth \(int\): the number of output channels) N
(            kernel_size \(list\): the kernel size) N
(            group_norm_num_groups \(int\): the number of groups to split the channels into) N
(            resblock_size \(int, optional\): the number of residual blocks to stack) N
(            inbetween skip connections. Defaults to 2.) N
(        ) S
(""") p n
(        self.resblock_size = resblock_size) N
() N
(        self.shortcut_conv = Conv2D\(input_depth, output_depth, [1, 1]\)) N
() N
(        self.conv_layers = []) N
(        ) S
(for) K
( _ ) p
(in) K
( range\(self.resblock_size\):) p n
(            self.conv_layers.append\() N
(                Conv2D\(input_depth, output_depth, kernel_size\)) N
(            \)) N
(            input_depth = output_depth) N
() N
(        self.group_norm = GroupNorm\(group_norm_num_groups, output_depth\)) N
() N
(    ) S
(def) K
( __call__\(self, x: tf.Tensor\) -> tf.Tensor:) p n
(        shortcut = self.shortcut_conv\(x\)) N
(        ) S
(for) K
( conv_layer ) p
(in) K
( self.conv_layers:) p n
(            x = conv_layer\(x\)) N
(            x = self.group_norm\(x\)) N
(            x = tf.nn.relu\(x\)) N
(        ) S
(return) K
( x + shortcut) p n
(residual_block.py) (Page 1/1) (Nov 04, 23 18:43) title
border
grestore
(Printed by ) rhead
() (Monday November 27, 2023) (24/79) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (1) 25
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(import) K
( tempfile) p n
() N
(import) K
( tensorflow as tf) p n
() N
(from) K
( helpers.embed_to_vocab_file ) p
(import) K
( EmbedToVocabFile) p n
(from) K
( helpers.positional_encoding ) p
(import) K
( PositionalEncoding) p n
(from) K
( helpers.tokenizer ) p
(import) K
( Tokenizer) p n
(from) K
( modules.linear ) p
(import) K
( Linear) p n
(from) K
( modules.transformer_decoder_block ) p
(import) K
( TransformerDecoderBlock) p n
() N
() N
(class) K
( TransformerDecoder\(tf.Module\):) p n
(    """) S
(Transformer Decoder.) str n
() N
(    This is an implementation of a transformer decoder as described) N
(    in the paper ) S
("Attention ) p
(is) K
( all you Need") p
( \(Vaswani et al., 2017\).) str n
() N
(    Args:) N
(        num_embedding: Number of embeddings to use.) N
(        embedding_depth: Depth of each embedding.) N
(        num_word_to_tokenize: Number of words to tokenize.) N
(        num_heads: Number of attention heads.) N
(        model_dim: Size of each attention head for value, query, and queue.) N
(        ffn_dim: Size of the hidden layer in the feed-forward network.) N
(        num_blocks: Number of transformer decoder blocks.) N
(        input_text: Text to use for training. If None, training will not be possible.) N
(        vocab_file: Path to the vocab file. If None, a temporary file will be created.) N
(        dropout: Dropout probability.) N
() N
(    Call arguments:) N
(        input: Input `Tensor` of shape `\(B, seq_len\)` during training and untokenized `\(B, 1\)` during inference.) N
() N
(    Returns:) N
(        Output `Tensor` of shape `\(B, seq_len, vocab_size\)` during training and untokenized `\(B, 1\)` during inference.) N
(    ) S
(""") p n
() N
(    ) S
(def) K
( __init__\() p n
(        self,) N
(        context_length,) N
(        num_heads,) N
(        model_dim,) N
(        ffn_dim,) N
(        num_blocks,) N
(        input_text=None,) N
(        vocab_file=None,) N
(        dropout_prob=0.1,) N
(    \):) N
(        self.tokenizer = Tokenizer\(context_length, False\)) N
() N
(        self.input_text = input_text) N
(        self.context_length = context_length) N
(        ) S
(if) K
( vocab_file ) p
(is) K
( None:) p n
(            self.vocab_file = self._create_vocab_file\(input_text\)) N
(        ) S
(else) K
(:) p n
(            self.vocab_file = tf.io.gfile.GFile\(vocab_file, ") S
(r) str
("\)) p n
() N
(        self.embedder = EmbedToVocabFile\(self.vocab_file, model_dim\)) N
(        self.positional_encoding = PositionalEncoding\(context_length, model_dim\)) N
() N
(        self.layers = [) N
(            TransformerDecoderBlock\(num_heads, model_dim, ffn_dim, dropout_prob\)) N
(            ) S
(for) K
( _ ) p
(in) K
( range\(num_blocks\)) p n
(        ]) N
() N
(        self.vocab_size = self.embedder.get_vocab_size\(\)) N
(        self.linear = Linear\(model_dim, self.vocab_size\)) N
(transformer_decoder.py) (Page 1/3) (Nov 12, 23 23:40) title
border
grestore
(Printed by ) rhead
() (25/79) (Monday November 27, 2023) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (2) 26
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
() p n
(    ) S
(def) K
( get_vocab_file\(self\):) p n
(        ) S
(return) K
( self.vocab_file) p n
() N
(    ) S
(def) K
( get_tokens_and_targets\(self\):) p n
(        tokenized_text = self.tokenizer\(self.input_text\)) N
() N
(        tokenized_targets = tokenized_text[:, 1:]) N
(        tokenized_text = tokenized_text[:, :-1]) N
() N
(        targets = self.embedder.tokens_to_ids\(tokenized_targets\)) N
() N
(        ) S
(return) K
( tokenized_text, targets) p n
() N
(    ) S
(def) K
( decode\(self, logits\):) p n
(        ) S
(return) K
( self.embedder.decode\(logits\)) p n
() N
(    ) S
(def) K
( predict\(self, input_text\):) p n
(        len_input = len\(input_text.split\(\)\)) N
() N
(        output_index = len_input) N
(        output = "") N
(        ) S
(for) K
( _ ) p
(in) K
( range\(self.context_length - len_input\):) p n
(            tokenized_text = self.tokenizer\(input_text\)) N
() N
(            logits = self.__call__\(tokenized_text, training=False\)) N
() N
(            decoded_logits = self.decode\(logits\)) N
() N
(            next_word = decoded_logits[:, output_index - 1 : output_index]) N
() N
(            next_word_decoded = next_word[-1][0].numpy\(\).decode\(") S
(utf-8) str
("\)) p n
() N
(            output_index += 1) N
() N
(            ) S
(if) K
( next_word_decoded == ") p
(<EOS>) str
(" ) p
(or) K
( next_word_decoded == ") p
(<PAD>) str
(":) p n
(                ) S
(break) K n
() p n
(            output += ") S
( ) str
(" + next_word_decoded) p n
(            input_text += ") S
( ) str
(" + next_word_decoded) p n
() N
(        ) S
(return) K
( output) p n
() N
(    ) S
(def) K
( _create_vocab_file\(self, input_text\):) p n
(        ) S
(# Tokenize the contents of the file) c n
(        tokenized_text = self.tokenizer\(input_text\)) p n
() N
(        ) S
(# Flatten the tokenized_text tensor to 1D) c n
(        flattened_text = tf.reshape\(tokenized_text, [-1]\)) p n
() N
(        ) S
(# Create a tensor of unique tokens) c n
(        unique_tokens, _ = tf.unique\(flattened_text\)) p n
() N
(        ) S
(# Write these unique tokens to a new vocab file) c n
(        vocab_file = tempfile.NamedTemporaryFile\(delete=False\)) p n
(        with open\(vocab_file.name, ") S
(w) str
(", encoding=") p
(utf-8) str
("\) as vocab_file:) p n
(            ) S
(for) K
( token ) p
(in) K
( unique_tokens.numpy\(\):) p n
(                vocab_file.write\(f") S
({token.decode\('utf-8'\)}) str
("\)) p n
(                ) S
(if) K
( token != unique_tokens[-1]:) p n
(                    vocab_file.write\(") S
(\\n) str
("\)) p n
() N
(        ) S
(return) K
( vocab_file) p n
() N
(    ) S
(def) K
( __call__\(self, input_tokens, training=True\):) p n
(        causal_mask = tf.linalg.band_part\() N
(            tf.ones\(\(input_tokens.shape[1], input_tokens.shape[1]\)\), 0, -1) N
(transformer_decoder.py) (Page 2/3) (Nov 12, 23 23:40) title
border
grestore
(Printed by ) rhead
() (Monday November 27, 2023) (26/79) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (3) 27
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(        \)) p n
(        ) S
(# make the main diagonal 0) c n
(        causal_mask = causal_mask - tf.eye\(input_tokens.shape[1]\)) p n
() N
(        ) S
(# stack causal mask for each batch resulting in shape \(B, seq_len, seq_l) c n
(en\)) N
(        causal_mask = tf.stack\([causal_mask ) p
(for) K
( _ ) p
(in) K
( range\(input_tokens.shape[0]) p n
(\)]\)) N
() N
(        pad_mask_vector = tf.cast\(tf.equal\(input_tokens, b") S
(<PAD>) str
("\), tf.float32\)) p n
() N
(        ) S
(# stack seq_len copies of the pad mask vector for each batch resulting i) c n
(n shape \(B, seq_len, seq_len\)) N
(        pad_mask1 = tf.stack\() p n
(            [pad_mask_vector ) S
(for) K
( _ ) p
(in) K
( range\(input_tokens.shape[1]\)], axis=1) p n
(        \)) N
() N
(        ) S
(# transpose the pad mask vector to get shape \(B, seq_len, seq_len\)) c n
(        pad_mask2 = tf.transpose\(pad_mask1, [0, 2, 1]\)) p n
() N
(        ) S
(# logical or of the two pad masks, switch 2's to 1's) c n
(        pad_mask = tf.cast\(pad_mask1 + pad_mask2, tf.bool\)) p n
(        pad_mask = tf.cast\(pad_mask, tf.float32\)) N
(        pad_mask = pad_mask1) N
() N
(        mask = tf.cast\(causal_mask + pad_mask, tf.bool\)) N
(        mask = tf.cast\(mask, tf.float32\)) N
() N
(        embeddings = self.embedder\(input_tokens\)) N
() N
(        ) S
(for) K
( layer ) p
(in) K
( self.layers:) p n
(            embeddings = layer\(embeddings, mask, training\)) N
() N
(        output = self.linear\(embeddings\)) N
() N
(        ) S
(return) K
( output) p n
(transformer_decoder.py) (Page 3/3) (Nov 12, 23 23:40) title
border
grestore
(Printed by ) rhead
() (27/79) (Monday November 27, 2023) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (1) 28
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(import) K
( tensorflow as tf) p n
() N
(from) K
( helpers.group_norm ) p
(import) K
( GroupNorm) p n
(from) K
( modules.mlp ) p
(import) K
( MLP) p n
(from) K
( modules.multi_head_attention ) p
(import) K
( MultiHeadAttention) p n
() N
() N
(class) K
( TransformerDecoderBlock\(tf.Module\):) p n
(    """) S
(Transformer Decoder Block.) str n
() N
(    This is an implementation of a single transformer decoder block as described) N
(    in the paper ) S
("Attention ) p
(is) K
( all you Need") p
( \(Vaswani et al., 2017\).) str n
() N
(    This layer first applies masked multi-headed attention to the inputs, then applies a feed-forward network to the resul) N
(t.) N
() N
(    Args:) N
(        num_heads: Number of attention heads.) N
(        model_dim: Size of each attention head for value, query, and queue.) N
(        ffn_dim: Size of the hidden layer in the feed-forward network.) N
(        dropout: Dropout probability.) N
() N
(    Call arguments:) N
(        inputs: Input `Tensor` of shape `\(B, seq_len, model_dim\)`.) N
(        mask: Optional mask tensor of shape `\(B, seq_len, seq_len\)`.) N
() N
(    Returns:) N
(        Output `Tensor` of shape `\(B, seq_len, model_dim\)`.) N
(    ) S
(""") p n
() N
(    ) S
(def) K
( __init__\(self, num_heads, model_dim, ffn_dim, dropout_prob=0.1\):) p n
(        self.dropout_prob = dropout_prob) N
() N
(        self.mha = MultiHeadAttention\(num_heads, model_dim\)) N
(        self.ff = MLP\() N
(            model_dim,) N
(            model_dim,) N
(            hidden_layer_width=ffn_dim,) N
(            hidden_activation=tf.nn.relu,) N
(        \)) N
(        ) S
(# Split the model dimension into 5 groups for group normalization) c n
(        self.groupnorm1 = GroupNorm\(model_dim // 4, model_dim, 1\)) p n
(        self.groupnorm2 = GroupNorm\(model_dim // 4, model_dim, 1\)) N
() N
(    ) S
(def) K
( __call__\(self, inputs, mask=None, training=False\):) p n
(        attn = self.mha\() N
(            self.groupnorm1\(inputs\),) N
(            self.groupnorm1\(inputs\),) N
(            self.groupnorm1\(inputs\),) N
(            mask,) N
(        \)) N
(        ) S
(if) K
( training:) p n
(            attn = tf.nn.dropout\(attn, rate=self.dropout_prob\)) N
(        out1 = attn + inputs) N
() N
(        ffn_output = self.ff\(self.groupnorm2\(out1\)\)) N
(        ) S
(if) K
( training:) p n
(            ffn_output = tf.nn.dropout\(ffn_output, rate=self.dropout_prob\)) N
(        out2 = out1 + ffn_output) N
() N
(        ) S
(return) K
( out2) p n
(transformer_decoder_block.py) (Page 1/1) (Nov 13, 23 14:51) title
border
grestore
(Printed by ) rhead
() (Monday November 27, 2023) (28/79) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (1) 29
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(from) K
( pathlib ) p
(import) K
( Path) p n
() N
(import) K
( matplotlib.pyplot as plt) p n
(import) K
( numpy as np) p n
(import) K
( tensorflow as tf) p n
(import) K
( tqdm) p n
(import) K
( yaml) p n
(from) K
( datasets ) p
(import) K
( load_dataset) p n
() N
(from) K
( helpers.adam ) p
(import) K
( Adam) p n
(from) K
( modules.embed_classifier ) p
(import) K
( EmbedClassifier) p n
() N
() N
(def) K
( train_batch_accuracy\(classifier, train_text_batch, train_labels_batch\):) p n
(    ) S
(return) K
( tf.reduce_mean\() p n
(        tf.cast\() N
(            tf.equal\() N
(                classifier\(train_text_batch\).numpy\(\).argmax\(axis=1\),) N
(                train_labels_batch.numpy\(\).reshape\(-1\),) N
(            \),) N
(            tf.float32,) N
(        \)) N
(    \)) N
() N
() N
(def) K
( val_accuracy\(classifier, val_text, val_labels\):) p n
(    val_accuracy = 0) N
(    val_text = tf.convert_to_tensor\(val_text\)) N
(    ) S
(for) K
( i ) p
(in) K
( range\(0, val_text.shape[0], val_text.shape[0] // 100\):) p n
(        batch_indices = tf.range\(i, i + val_text.shape[0] // 100\)) N
(        val_batch_text = tf.gather\(val_text, batch_indices\)) N
(        val_batch_labels = tf.gather\(val_labels, batch_indices\)) N
(        ) S
(if) K
( i == 0:) p n
(            val_accuracy = tf.reduce_mean\() N
(                tf.cast\() N
(                    tf.equal\() N
(                        classifier\(val_batch_text\).numpy\(\).argmax\(axis=1\),) N
(                        val_batch_labels.numpy\(\).reshape\(-1\),) N
(                    \),) N
(                    tf.float32,) N
(                \)) N
(            \) / \(val_text.shape[0] // 100\)) N
(        ) S
(else) K
(:) p n
(            val_accuracy += tf.reduce_mean\() N
(                tf.cast\() N
(                    tf.equal\() N
(                        classifier\(val_batch_text\).numpy\(\).argmax\(axis=1\),) N
(                        val_batch_labels.numpy\(\).reshape\(-1\),) N
(                    \),) N
(                    tf.float32,) N
(                \)) N
(            \) / \(val_text.shape[0] // 100\)) N
(    ) S
(return) K
( val_accuracy.numpy\(\)) p n
() N
() N
(def) K
( val_loss\() p n
(    classifier,) N
(    val_text,) N
(    val_labels,) N
(    checkpoint_manager,) N
(    minimum_val_loss,) N
(    minimum_val_step,) N
(    current_step,) N
(\):) N
(    val_text = tf.convert_to_tensor\(val_text\)) N
(    validation_loss = 0) N
(classify_agnews.py) (Page 1/8) (Nov 12, 23 5:30) title
border
grestore
(Printed by ) rhead
() (29/79) (Monday November 27, 2023) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (2) 30
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
() p n
(    ) S
(for) K
( i ) p
(in) K
( range\(0, val_text.shape[0], val_text.shape[0] // 100\):) p n
(        batch_indices = tf.range\(i, i + val_text.shape[0] // 100\)) N
(        val_batch_text = tf.gather\(val_text, batch_indices\)) N
(        val_batch_labels = tf.gather\(val_labels, batch_indices\)) N
(        validation_loss = tf.reduce_mean\() N
(            tf.nn.sparse_softmax_cross_entropy_with_logits\() N
(                labels=tf.squeeze\(val_batch_labels\), logits=classifier\(val_batch) N
(_text\)) N
(            \)) N
(        \)) N
() N
(        ) S
(# average the validation loss over the batches) c n
(        ) p
(if) K
( i == 0:) p n
(            validation_loss = validation_loss / \(val_text.shape[0] // 100\)) N
(        ) S
(else) K
(:) p n
(            validation_loss += validation_loss / \(val_text.shape[0] // 100\)) N
() N
(    ) S
(if) K
( validation_loss < minimum_val_loss:) p n
(        minimum_val_loss = validation_loss) N
(        minimum_val_step = current_step) N
(        checkpoint_manager.save\(\)) N
() N
(    ) S
(return) K
( validation_loss, minimum_val_loss, minimum_val_step) p n
() N
() N
(def) K
( val_check\() p n
(    classifier,) N
(    val_text,) N
(    val_labels,) N
(    checkpoint_manager,) N
(    minimum_val_loss,) N
(    minimum_val_step_num,) N
(    current_step,) N
(    val_check_rate,) N
(    y_val_loss,) N
(    y_val_accuracy,) N
(    used_patience,) N
(    current_val_loss,) N
(    current_validation_accuracy,) N
(    x_val_iterations,) N
(\):) N
(    ) S
(if) K
( current_step % val_check_rate == \(val_check_rate - 1\):) p n
(        \() N
(            current_val_loss,) N
(            minimum_val_loss,) N
(            minimum_val_step_num,) N
(        \) = val_loss\() N
(            classifier,) N
(            val_text,) N
(            val_labels,) N
(            checkpoint_manager,) N
(            minimum_val_loss,) N
(            minimum_val_step_num,) N
(            current_step,) N
(        \)) N
(        x_val_iterations = np.append\(x_val_iterations, current_step\)) N
() N
(        y_val_loss = np.append\(y_val_loss, current_val_loss\)) N
() N
(        current_validation_accuracy = val_accuracy\(classifier, val_text, val_lab) N
(els\)) N
() N
(        y_val_accuracy = np.append\(y_val_accuracy, current_validation_accuracy\)) N
(        used_patience = current_step - minimum_val_step_num) N
() N
(classify_agnews.py) (Page 2/8) (Nov 12, 23 5:30) title
border
grestore
(Printed by ) rhead
() (Monday November 27, 2023) (30/79) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (3) 31
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(    ) p
(return) K
( \() p n
(        used_patience,) N
(        minimum_val_loss,) N
(        minimum_val_step_num,) N
(        current_validation_accuracy,) N
(        current_val_loss,) N
(        y_val_loss,) N
(        y_val_accuracy,) N
(        x_val_iterations,) N
(    \)) N
() N
() N
(def) K
( test_accuracy\(classifier, test_images, test_labels\):) p n
(    test_accuracy = 0) N
(    test_images = tf.convert_to_tensor\(test_images\)) N
(    ) S
(for) K
( i ) p
(in) K
( range\(0, test_images.shape[0], test_images.shape[0] // 100\):) p n
(        batch_indices = tf.range\(i, i + test_images.shape[0] // 100\)) N
(        test_batch_images = tf.gather\(test_images, batch_indices\)) N
(        test_batch_labels = tf.gather\(test_labels, batch_indices\)) N
(        ) S
(if) K
( i == 0:) p n
(            test_accuracy = \() N
(                tf.reduce_mean\() N
(                    tf.cast\() N
(                        tf.equal\() N
(                            classifier\(test_batch_images\).numpy\(\).argmax\(axis=1\)) N
(,) N
(                            test_batch_labels.numpy\(\).reshape\(-1\),) N
(                        \),) N
(                        tf.float32,) N
(                    \)) N
(                \)) N
(                / 100) N
(            \)) N
(        ) S
(else) K
(:) p n
(            test_accuracy += \() N
(                tf.reduce_mean\() N
(                    tf.cast\() N
(                        tf.equal\() N
(                            classifier\(test_batch_images\).numpy\(\).argmax\(axis=1\)) N
(,) N
(                            test_batch_labels.numpy\(\).reshape\(-1\),) N
(                        \),) N
(                        tf.float32,) N
(                    \)) N
(                \)) N
(                / 100) N
(            \)) N
(    ) S
(return) K
( test_accuracy.numpy\(\)) p n
() N
() N
(def) K
( train\(config_path: Path, use_last_checkpoint: bool\):) p n
(    ) S
(if) K
( config_path ) p
(is) K
( None:) p n
(        config_path = Path\(") S
(configs/classify_agnews_config.yaml) str
("\)) p n
() N
(    config = yaml.safe_load\(config_path.read_text\(\)\)) N
(    num_iters = config[") S
(learning) str
("][") p
(num_iters) str
("]) p n
(    weight_decay = config[") S
(learning) str
("][") p
(weight_decay) str
("]) p n
(    dropout_prob = config[") S
(learning) str
("][") p
(dropout_prob) str
("]) p n
(    batch_size = config[") S
(learning) str
("][") p
(batch_size) str
("]) p n
(    learning_patience = config[") S
(learning) str
("][") p
(learning_patience) str
("]) p n
(    learning_rates = config[") S
(learning) str
("][") p
(learning_rates) str
("]) p n
(    num_embeddings = config[") S
(learning) str
("][") p
(num_embeddings) str
("]) p n
(    embedding_depth = config[") S
(learning) str
("][") p
(embedding_depth) str
("]) p n
(    val_check_rate = config[") S
(learning) str
("][") p
(val_check_rate) str
("]) p n
() N
(    refresh_rate = config[") S
(display) str
("][") p
(refresh_rate) str
("]) p n
(classify_agnews.py) (Page 3/8) (Nov 12, 23 5:30) title
border
grestore
(Printed by ) rhead
() (31/79) (Monday November 27, 2023) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (4) 32
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
() p n
(    num_hidden_layers = config[") S
(mlp) str
("][") p
(num_hidden_layers) str
("]) p n
(    hidden_layer_width = config[") S
(mlp) str
("][") p
(hidden_layer_width) str
("]) p n
() N
(    num_word_to_tokenize = config[") S
(data) str
("][") p
(num_words_to_tokenize) str
("]) p n
() N
(    rng = tf.random.get_global_generator\(\)) N
(    rng.reset_from_seed\(0x43966E87BD57227011B5B03B58785EC1\)) N
(    tf.random.set_seed\(0x43966E87BD57227011B5B03B58785EC1\)) N
() N
(    dataset = load_dataset\(") S
(ag_news) str
("\)) p n
(    train_and_val_labels = dataset[") S
(train) str
("][") p
(label) str
("]) p n
(    train_and_val_text = dataset[") S
(train) str
("][") p
(text) str
("]) p n
() N
(    ) S
(# use 10,000 training samples for validation) c n
(    train_labels = train_and_val_labels[:-10000]) p n
(    train_text = tf.convert_to_tensor\(train_and_val_text[:-10000]\)) N
(    val_labels = train_and_val_labels[-10000:]) N
(    val_text = train_and_val_text[-10000:]) N
() N
(    minimum_val_step_num = 0) N
(    current_val_loss = 0) N
(    used_patience = 0) N
(    current_val_loss = -1) N
(    current_validation_accuracy = -1) N
() N
(    num_classes = 4) N
(    embed_classifier = EmbedClassifier\() N
(        num_embeddings,) N
(        embedding_depth,) N
(        num_word_to_tokenize,) N
(        dropout_prob,) N
(        num_hidden_layers,) N
(        hidden_layer_width,) N
(        num_classes,) N
(    \)) N
() N
(    ) S
(# Used For Plotting) c n
(    y_train_batch_accuracy = np.array\([]\)) p n
(    y_train_batch_loss = np.array\([]\)) N
(    y_val_accuracy = np.array\([]\)) N
(    y_val_loss = np.array\([]\)) N
(    x_train_loss_iterations = np.array\([]\)) N
(    x_train_accuracy_iterations = np.array\([]\)) N
(    x_val_iterations = np.array\([]\)) N
() N
(    learning_rate_change_steps = np.array\([]\)) N
() N
(    ) S
(# Index of the current learning rate, used to change the learning rate) c n
(    ) p
(# when the validation loss stops improving) c n
(    learning_rate_index = 0) p n
(    adam = Adam\() N
(        learning_rates[learning_rate_index],) N
(        weight_decay=weight_decay,) N
(    \)) N
() N
(    checkpoint = tf.train.Checkpoint\(embed_classifier\)) N
(    checkpoint_manager = tf.train.CheckpointManager\() N
(        checkpoint, ") S
(temp/checkpoints/classify_agnews) str
(", max_to_keep=1) p n
(    \)) N
(    ) S
(if) K
( use_last_checkpoint:) p n
(        ) S
(print) K
(\(") p
(\\n\\nRestoring from last checkpoint) str
("\)) p n
(        checkpoint_manager.restore_or_initialize\(\)) N
() N
(    overall_log = tqdm.tqdm\(total=0, position=1, bar_format=") S
({desc}) str
("\)) p n
(    train_log = tqdm.tqdm\(total=0, position=2, bar_format=") S
({desc}) str
("\)) p n
(classify_agnews.py) (Page 4/8) (Nov 12, 23 5:30) title
border
grestore
(Printed by ) rhead
() (Monday November 27, 2023) (32/79) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (5) 33
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(    val_log = tqdm.tqdm\(total=0, position=3, bar_format=") p
({desc}) str
("\)) p n
(    bar = tqdm.trange\(num_iters, position=4\)) N
() N
(    num_of_parameters = tf.math.add_n\() N
(        [tf.math.reduce_prod\(var.shape\) ) S
(for) K
( var ) p
(in) K
( embed_classifier.trainable_va) p n
(riables]) N
(    \)) N
(    ) S
(print) K
(\(f") p
(\\nNumber of Parameters => {num_of_parameters}) str
("\)) p n
() N
(    ) S
(for) K
( i ) p
(in) K
( bar:) p n
(        batch_indices = rng.uniform\() N
(            shape=[batch_size], maxval=train_text.shape[0], dtype=tf.int32) N
(        \)) N
(        with tf.GradientTape\(\) as tape:) N
(            train_text_batch = tf.gather\(train_text, batch_indices\)) N
(            train_labels_batch = tf.gather\(train_labels, batch_indices\)) N
() N
(            current_train_batch_loss = tf.reduce_mean\() N
(                tf.nn.sparse_softmax_cross_entropy_with_logits\() N
(                    labels=tf.squeeze\(train_labels_batch\),) N
(                    logits=embed_classifier\(train_text_batch\),) N
(                \)) N
(            \)) N
() N
(        ) S
(# Print initial train batch loss) c n
(        ) p
(if) K
( i == 0:) p n
(            ) S
(print) K
(\(") p
(\\n\\n\\n\\n) str
("\)) p n
(            ) S
(print) K
(\(f") p
(Initial Training Loss => {current_train_batch_loss:0.4f}) str
("\)) p n
(            _, minimum_val_loss, minimum_val_step_num = val_loss\() N
(                embed_classifier,) N
(                val_text,) N
(                val_labels,) N
(                checkpoint_manager,) N
(                np.inf,) N
(                i,) N
(                i,) N
(            \)) N
(            current_validation_accuracy = val_accuracy\() N
(                embed_classifier, val_text, val_labels) N
(            \)) N
(            current_val_loss = minimum_val_loss) N
() N
(        grads = tape.gradient\() N
(            current_train_batch_loss, embed_classifier.trainable_variables) N
(        \)) N
() N
(        adam.apply_gradients\(zip\(grads, embed_classifier.trainable_variables\)\)) N
() N
(        \() N
(            used_patience,) N
(            minimum_val_loss,) N
(            minimum_val_step_num,) N
(            current_validation_accuracy,) N
(            current_val_loss,) N
(            y_val_loss,) N
(            y_val_accuracy,) N
(            x_val_iterations,) N
(        \) = val_check\() N
(            embed_classifier,) N
(            val_text,) N
(            val_labels,) N
(            checkpoint_manager,) N
(            minimum_val_loss,) N
(            minimum_val_step_num,) N
(            i,) N
(            val_check_rate,) N
(classify_agnews.py) (Page 5/8) (Nov 12, 23 5:30) title
border
grestore
(Printed by ) rhead
() (33/79) (Monday November 27, 2023) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (6) 34
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(            y_val_loss,) p n
(            y_val_accuracy,) N
(            used_patience,) N
(            current_val_loss,) N
(            current_validation_accuracy,) N
(            x_val_iterations,) N
(        \)) N
() N
(        current_train_batch_loss = current_train_batch_loss.numpy\(\)) N
(        y_train_batch_loss = np.append\(y_train_batch_loss, current_train_batch_l) N
(oss\)) N
(        x_train_loss_iterations = np.append\(x_train_loss_iterations, i\)) N
() N
(        ) S
(if) K
( i % refresh_rate == \(refresh_rate - 1\):) p n
(            current_batch_accuracy = train_batch_accuracy\() N
(                embed_classifier, train_text_batch, train_labels_batch) N
(            \)) N
(            x_train_accuracy_iterations = np.append\(x_train_accuracy_iterations,) N
( i\)) N
(            y_train_batch_accuracy = np.append\() N
(                y_train_batch_accuracy, current_batch_accuracy) N
(            \)) N
() N
(            learning_rates_left = len\(learning_rates\) - learning_rate_index) N
(            patience_left = learning_patience - used_patience) N
(            overall_description = \() N
(                f") S
(Minimum Val Loss => {minimum_val_loss:0.4f}    ) str
(") p n
(                + f") S
(Learning Rates Left => {learning_rates_left}    ) str
(") p n
(                + f") S
(Patience Left => {patience_left}    ) str
(") p n
(            \)) N
(            overall_log.set_description_str\(overall_description\)) N
(            overall_log.refresh\(\)) N
() N
(            train_description = \() N
(                f") S
(Train Batch Loss => {current_train_batch_loss:0.4f}    ) str
(") p n
(                + f") S
(Train Accuracy => {current_batch_accuracy:0.4f}    ) str
(") p n
(            \)) N
(            train_log.set_description_str\(train_description\)) N
(            train_log.update\(refresh_rate\)) N
() N
(            val_description = \() N
(                f") S
(Val Loss => {current_val_loss:0.4f}    ) str
(") p n
(                + f") S
(Val Accuracy => {current_validation_accuracy:0.4f}    ) str
(") p n
(            \)) N
(            val_log.set_description_str\(val_description\)) N
(            val_log.update\(refresh_rate\)) N
() N
(            bar_description = f") S
(Step => {i}) str
(") p n
(            bar.set_description\(bar_description\)) N
(            bar.refresh\(\)) N
() N
(            ) S
(# if the validation loss has not improved for learning_patience) c n
(            ) p
(if) K
( \() p n
(                current_val_loss > minimum_val_loss) N
(                ) S
(and) K
( i - minimum_val_step_num > learning_patience) p n
(            \):) N
(                ) S
(if) K
( learning_rate_index == \(len\(learning_rates\) - 1\):) p n
(                    ) S
(break) K n
(                learning_rate_index += 1) p n
(                adam.learning_rate = learning_rates[learning_rate_index]) N
(                learning_rate_change_steps = np.append\(learning_rate_change_step) N
(s, i\)) N
(                minimum_val_step_num = i) N
(                checkpoint_manager.restore_or_initialize\(\)) N
() N
(    checkpoint_manager.restore_or_initialize\(\)) N
(classify_agnews.py) (Page 6/8) (Nov 12, 23 5:30) title
border
grestore
(Printed by ) rhead
() (Monday November 27, 2023) (34/79) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (7) 35
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(    current_validation_accuracy = val_accuracy\(embed_classifier, val_text, val_l) p n
(abels\)) N
() N
(    fig, ax = plt.subplots\(2, 1\)) N
() N
(    ax[0].plot\() N
(        x_train_accuracy_iterations, y_train_batch_accuracy, label=") S
(Train Accuracy) str
(") p n
(    \)) N
(    ax[0].plot\(x_val_iterations, y_val_accuracy, label=") S
(Val Accuracy) str
("\)) p n
(    ) S
(# plot vertical line on learning rate change) c n
(    ) p
(for) K
( learning_rate_change_step ) p
(in) K
( learning_rate_change_steps:) p n
(        ax[0].axvline\(x=learning_rate_change_step, color=") S
(black) str
(", linestyle=") p
(dashe) str n
(d) S
("\)) p n
(    ax[0].set_xlabel\(") S
(Iterations) str
("\)) p n
(    ax[0].set_ylabel\(") S
(Accuracy) str
("\)) p n
(    ax[0].legend\(\)) N
() N
(    ax[1].semilogy\() N
(        x_train_loss_iterations, y_train_batch_loss, label=") S
(Train Batch Loss) str
(") p n
(    \)) N
(    ax[1].semilogy\(x_val_iterations, y_val_loss, label=") S
(Val Loss) str
("\)) p n
(    ) S
(for) K
( learning_rate_change_step ) p
(in) K
( learning_rate_change_steps:) p n
(        ax[1].axvline\(x=learning_rate_change_step, color=") S
(black) str
(", linestyle=") p
(dashe) str n
(d) S
("\)) p n
(    ax[1].set_xlabel\(") S
(Iterations) str
("\)) p n
(    ax[1].set_ylabel\(") S
(Loss) str
("\)) p n
(    ax[1].legend\(\)) N
() N
(    ) S
(print) K
(\(") p
(\\n\\n\\n\\n) str
("\)) p n
(    ) S
(print) K
(\(f") p
(Final Training Loss => {current_train_batch_loss:0.4f}) str
("\)) p n
(    ) S
(print) K
(\(f") p
(Stop Iteration => {i}) str
("\)) p n
() N
(    fig.suptitle\() N
(        ") S
(Classify AGNews: Final Val Accuracy = ) str
(" + f") p
({current_validation_accuracy:0.4f}) str
(") p n
(    \)) N
() N
(    ) S
(# if the file already exists add a number to the end of the file name) c n
(    ) p
(# to avoid overwriting) c n
(    file_index = 0) p n
(    ) S
(while) K
( Path\(f") p
(artifacts/agnews/classify_agnews_img_{file_index}.png) str
("\).exists\(\):) p n
(        file_index += 1) N
(    fig.savefig\(f") S
(artifacts/agnews/classify_agnews_img_{file_index}.png) str
("\)) p n
() N
(    ) S
(# Save the config file as a yaml under the same name as the image) c n
(    config_path = Path\(f") p
(artifacts/agnews/classify_agnews_img_{file_index}.yaml) str
("\)) p n
(    config_path.write_text\(yaml.dump\(config\)\)) N
() N
(    ) S
(# save the model) c n
(    checkpoint_manager.save\(\)) p n
(    config_path = Path\(f") S
(artifacts/agnews/model.yaml) str
("\)) p n
(    config_path.write_text\(yaml.dump\(config\)\)) N
() N
() N
(def) K
( test\(checkpoint_path: Path\):) p n
(    ) S
(if) K
( checkpoint_path ) p
(is) K
( None:) p n
(        checkpoint_path = Path\(") S
(temp/checkpoints/classify_agnews) str
("\)) p n
() N
(    ) S
(if) K
( ) p
(not) K
( checkpoint_path.exists\(\):) p n
(        ) S
(print) K
(\(") p
(Checkpoint does not exist, run the train script first) str
("\)) p n
(        ) S
(return) K n
() p n
(    config_path = Path\(") S
(artifacts/agnews/model.yaml) str
("\)) p n
() N
(    config = yaml.safe_load\(config_path.read_text\(\)\)) N
(    dropout_prob = config[") S
(learning) str
("][") p
(dropout_prob) str
("]) p n
(    num_embeddings = config[") S
(learning) str
("][") p
(num_embeddings) str
("]) p n
(classify_agnews.py) (Page 7/8) (Nov 12, 23 5:30) title
border
grestore
(Printed by ) rhead
() (35/79) (Monday November 27, 2023) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (8) 36
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(    embedding_depth = config[") p
(learning) str
("][") p
(embedding_depth) str
("]) p n
() N
(    num_hidden_layers = config[") S
(mlp) str
("][") p
(num_hidden_layers) str
("]) p n
(    hidden_layer_width = config[") S
(mlp) str
("][") p
(hidden_layer_width) str
("]) p n
() N
(    num_word_to_tokenize = config[") S
(data) str
("][") p
(num_words_to_tokenize) str
("]) p n
() N
(    num_classes = 4) N
(    embed_classifier = EmbedClassifier\() N
(        num_embeddings,) N
(        embedding_depth,) N
(        num_word_to_tokenize,) N
(        dropout_prob,) N
(        num_hidden_layers,) N
(        hidden_layer_width,) N
(        num_classes,) N
(    \)) N
() N
(    checkpoint = tf.train.Checkpoint\(embed_classifier\)) N
(    checkpoint.restore\(tf.train.latest_checkpoint\(checkpoint_path\)\)) N
() N
(    dataset = load_dataset\(") S
(ag_news) str
("\)) p n
(    test_labels = dataset[") S
(test) str
("][") p
(label) str
("]) p n
(    test_text = dataset[") S
(test) str
("][") p
(text) str
("]) p n
() N
(    test_text = tf.convert_to_tensor\(test_text\)) N
(    test_labels = tf.convert_to_tensor\(test_labels\)) N
() N
(    test_accuracy_value = test_accuracy\(embed_classifier, test_text, test_labels) N
(\)) N
() N
(    ) S
(print) K
(\(f") p
(Test Accuracy => {test_accuracy_value:0.4f}) str
("\)) p n
(classify_agnews.py) (Page 8/8) (Nov 12, 23 5:30) title
border
grestore
(Printed by ) rhead
() (Monday November 27, 2023) (36/79) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (1) 37
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(from) K
( pathlib ) p
(import) K
( Path) p n
() N
(import) K
( matplotlib.pyplot as plt) p n
(import) K
( numpy as np) p n
(import) K
( tensorflow as tf) p n
(import) K
( tqdm) p n
(import) K
( yaml) p n
() N
(from) K
( helpers.adam ) p
(import) K
( Adam) p n
(from) K
( helpers.augment_data ) p
(import) K
( AugmentData) p n
(from) K
( helpers.load_pickle_data ) p
(import) K
( load_pickle_data) p n
(from) K
( modules.classifier ) p
(import) K
( Classifier) p n
() N
(from) K
( sklearn.metrics ) p
(import) K
( top_k_accuracy_score) p n
() N
() N
(def) K
( train_batch_accuracy\(classifier, train_images_batch, train_labels_batch\):) p n
(    ) S
(return) K
( tf.reduce_mean\() p n
(        tf.cast\() N
(            tf.equal\() N
(                classifier\(train_images_batch\).numpy\(\).argmax\(axis=1\),) N
(                train_labels_batch.numpy\(\).reshape\(-1\),) N
(            \),) N
(            tf.float32,) N
(        \)) N
(    \)) N
() N
() N
(def) K
( val_accuracy\(classifier, val_images, val_labels\):) p n
(    val_accuracy = 0) N
(    ) S
(for) K
( i ) p
(in) K
( range\(0, val_images.shape[0], val_images.shape[0] // 100\):) p n
(        batch_indices = tf.range\(i, i + val_images.shape[0] // 100\)) N
(        val_batch_images = tf.gather\(val_images, batch_indices\)) N
(        val_batch_labels = tf.gather\(val_labels, batch_indices\)) N
(        ) S
(if) K
( i == 0:) p n
(            val_accuracy = tf.reduce_mean\() N
(                tf.cast\() N
(                    tf.equal\() N
(                        classifier\(val_batch_images\).numpy\(\).argmax\(axis=1\),) N
(                        val_batch_labels.numpy\(\).reshape\(-1\),) N
(                    \),) N
(                    tf.float32,) N
(                \)) N
(            \) / \(val_images.shape[0] // 100\)) N
(        ) S
(else) K
(:) p n
(            val_accuracy += \() N
(                tf.reduce_mean\() N
(                    tf.cast\() N
(                        tf.equal\() N
(                            classifier\(val_batch_images\).numpy\(\).argmax\(axis=1\),) N
(                            val_batch_labels.numpy\(\).reshape\(-1\),) N
(                        \),) N
(                        tf.float32,) N
(                    \)) N
(                \)) N
(                / \(val_images.shape[0] // 100\)) N
(            \)) N
(    ) S
(return) K
( val_accuracy.numpy\(\)) p n
() N
() N
(def) K
( test_accuracy\(classifier, test_images, test_labels\):) p n
(    ) S
(return) K
( tf.reduce_mean\() p n
(        tf.cast\() N
(            tf.equal\() N
(                classifier\(test_images\).numpy\(\).argmax\(axis=1\),) N
(                test_labels.numpy\(\).reshape\(-1\),) N
(classify_cifar10.py) (Page 1/6) (Nov 04, 23 17:25) title
border
grestore
(Printed by ) rhead
() (37/79) (Monday November 27, 2023) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (2) 38
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(            \),) p n
(            tf.float32,) N
(        \)) N
(    \).numpy\(\)) N
() N
() N
(def) K
( top_5_test_accuracy\(classifier, test_images, test_labels\):) p n
(    ) S
(return) K
( top_k_accuracy_score\() p n
(        test_labels.numpy\(\).reshape\(-1\), classifier\(test_images\).numpy\(\), k=5) N
(    \)) N
() N
() N
(def) K
( val_loss\() p n
(    classifier,) N
(    val_images,) N
(    val_labels,) N
(    checkpoint_manager,) N
(    minimum_val_loss,) N
(    minimum_val_step,) N
(    current_step,) N
(\):) N
(    validation_loss = 0) N
() N
(    ) S
(for) K
( i ) p
(in) K
( range\(0, val_images.shape[0], val_images.shape[0] // 100\):) p n
(        batch_indices = tf.range\(i, i + val_images.shape[0] // 100\)) N
(        val_batch_images = tf.gather\(val_images, batch_indices\)) N
(        val_batch_labels = tf.gather\(val_labels, batch_indices\)) N
(        validation_loss = tf.reduce_mean\() N
(            tf.nn.sparse_softmax_cross_entropy_with_logits\() N
(                labels=tf.squeeze\(val_batch_labels\), logits=classifier\(val_batch) N
(_images\)) N
(            \)) N
(        \)) N
() N
(        ) S
(# average the validation loss over the batches) c n
(        ) p
(if) K
( i == 0:) p n
(            validation_loss = validation_loss / \(val_images.shape[0] // 100\)) N
(        ) S
(else) K
(:) p n
(            validation_loss += validation_loss / \(val_images.shape[0] // 100\)) N
() N
(    ) S
(if) K
( validation_loss < minimum_val_loss:) p n
(        minimum_val_loss = validation_loss) N
(        minimum_val_step = current_step) N
(        checkpoint_manager.save\(\)) N
() N
(    ) S
(return) K
( validation_loss, minimum_val_loss, minimum_val_step) p n
() N
() N
(def) K
( train\(config_path: Path, use_last_checkpoint: bool\):) p n
(    ) S
(if) K
( config_path ) p
(is) K
( None:) p n
(        config_path = Path\(") S
(configs/classify_cifar_config.yaml) str
("\)) p n
() N
(    config = yaml.safe_load\(config_path.read_text\(\)\)) N
(    resblock_size = config[") S
(cnn) str
("][") p
(resblock_size) str
("]) p n
(    pool_size = config[") S
(cnn) str
("][") p
(pool_size) str
("]) p n
(    augmentation_multiplier = config[") S
(cnn) str
("][") p
(augmentation_multiplier) str
("]) p n
(    layers = config[") S
(cnn) str
("][") p
(layers) str
("]) p n
(    num_iters = config[") S
(learning) str
("][") p
(num_iters) str
("]) p n
(    weight_decay = config[") S
(learning) str
("][") p
(weight_decay) str
("]) p n
(    dropout_prob = config[") S
(learning) str
("][") p
(dropout_prob) str
("]) p n
(    batch_size = config[") S
(learning) str
("][") p
(batch_size) str
("]) p n
(    learning_patience = config[") S
(learning) str
("][") p
(learning_patience) str
("]) p n
(    learning_rates = config[") S
(learning) str
("][") p
(learning_rates) str
("]) p n
(    refresh_rate = config[") S
(display) str
("][") p
(refresh_rate) str
("]) p n
(    num_hidden_layers = config[") S
(mlp) str
("][") p
(num_hidden_layers) str
("]) p n
(    hidden_layer_width = config[") S
(mlp) str
("][") p
(hidden_layer_width) str
("]) p n
(classify_cifar10.py) (Page 2/6) (Nov 04, 23 17:25) title
border
grestore
(Printed by ) rhead
() (Monday November 27, 2023) (38/79) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (3) 39
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
() p n
(    layer_depths = [layer[") S
(depth) str
("] ) p
(for) K
( layer ) p
(in) K
( layers]) p n
(    kernel_sizes = [layer[") S
(kernel_size) str
("] ) p
(for) K
( layer ) p
(in) K
( layers]) p n
(    group_norm_num_groups = [layer[") S
(group_norm_num_groups) str
("] ) p
(for) K
( layer ) p
(in) K
( layers]) p n
() N
(    rng = tf.random.get_global_generator\(\)) N
(    rng.reset_from_seed\(0x43966E87BD57227011B5B03B58785EC1\)) N
() N
(    train_and_val_labels, train_and_val_images = load_pickle_data\() N
(        ") S
(data/cifar-10-batches-py/data_batch_1) str
(") p n
(    \)) N
(    ) S
(for) K
( i ) p
(in) K
( range\(2, 6\):) p n
(        labels, images = load_pickle_data\(f") S
(data/cifar-10-batches-py/data_batch_{i}) str
("\)) p n
(        train_and_val_labels = tf.concat\([train_and_val_labels, labels], axis=0\)) N
(        train_and_val_images = tf.concat\([train_and_val_images, images], axis=0\)) N
() N
(    num_classes = 10) N
(    train_labels = train_and_val_labels[:-10000]) N
(    train_images = train_and_val_images[:-10000]) N
(    val_labels = train_and_val_labels[-10000:]) N
(    val_images = train_and_val_images[-10000:]) N
() N
(    test_labels, test_images = load_pickle_data\(") S
(data/cifar-10-batches-py/test_batch) str
("\)) p n
() N
(    num_samples = train_images.shape[0]) N
(    input_depth = train_images.shape[-1]) N
(    classifier = Classifier\() N
(        input_depth,) N
(        layer_depths,) N
(        kernel_sizes,) N
(        num_classes,) N
(        train_images.shape[1],) N
(        resblock_size,) N
(        pool_size,) N
(        dropout_prob,) N
(        group_norm_num_groups,) N
(        num_hidden_layers,) N
(        hidden_layer_width,) N
(    \)) N
() N
(    minimum_val_step_num = 0) N
(    current_val_loss = 0) N
() N
(    ) S
(# Used For Plotting) c n
(    y_train_batch_accuracy = np.array\([]\)) p n
(    y_train_batch_loss = np.array\([]\)) N
(    y_val_accuracy = np.array\([]\)) N
(    y_val_loss = np.array\([]\)) N
(    x_loss_iterations = np.array\([]\)) N
(    x_accuracy_iterations = np.array\([]\)) N
() N
(    learning_rate_change_steps = np.array\([]\)) N
() N
(    ) S
(# Index of the current learning rate, used to change the learning rate) c n
(    ) p
(# when the validation loss stops improving) c n
(    learning_rate_index = 0) p n
(    adam = Adam\() N
(        learning_rates[learning_rate_index],) N
(        weight_decay=weight_decay,) N
(    \)) N
() N
(    checkpoint = tf.train.Checkpoint\(classifier\)) N
(    checkpoint_manager = tf.train.CheckpointManager\() N
(        checkpoint, ") S
(temp/checkpoints/classify_numbers) str
(", max_to_keep=1) p n
(    \)) N
(    ) S
(if) K
( use_last_checkpoint:) p n
(classify_cifar10.py) (Page 3/6) (Nov 04, 23 17:25) title
border
grestore
(Printed by ) rhead
() (39/79) (Monday November 27, 2023) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (4) 40
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(        ) p
(print) K
(\(") p
(\\n\\nRestoring from last checkpoint) str
("\)) p n
(        checkpoint_manager.restore_or_initialize\(\)) N
() N
(    overall_log = tqdm.tqdm\(total=0, position=1, bar_format=") S
({desc}) str
("\)) p n
(    train_log = tqdm.tqdm\(total=0, position=2, bar_format=") S
({desc}) str
("\)) p n
(    val_log = tqdm.tqdm\(total=0, position=3, bar_format=") S
({desc}) str
("\)) p n
(    bar = tqdm.trange\(num_iters, position=4\)) N
() N
(    num_of_parameters = tf.math.add_n\() N
(        [tf.math.reduce_prod\(var.shape\) ) S
(for) K
( var ) p
(in) K
( classifier.trainable_variable) p n
(s]) N
(    \)) N
(    ) S
(print) K
(\(f") p
(\\nNumber of Parameters => {num_of_parameters}) str
("\)) p n
() N
(    augment_data = AugmentData\(augmentation_multiplier\)) N
(    ) S
(for) K
( i ) p
(in) K
( bar:) p n
(        batch_indices = rng.uniform\() N
(            shape=[batch_size], maxval=num_samples, dtype=tf.int32) N
(        \)) N
(        with tf.GradientTape\(\) as tape:) N
(            train_images_batch = tf.gather\(train_images, batch_indices\)) N
(            train_labels_batch = tf.gather\(train_labels, batch_indices\)) N
() N
(            train_labels_batch, train_images_batch = augment_data\() N
(                train_labels_batch, train_images_batch) N
(            \)) N
(            current_train_batch_loss = tf.reduce_mean\() N
(                tf.nn.sparse_softmax_cross_entropy_with_logits\() N
(                    labels=tf.squeeze\(train_labels_batch\),) N
(                    logits=classifier\(train_images_batch\),) N
(                \)) N
(            \)) N
() N
(        ) S
(# Print initial train batch loss) c n
(        ) p
(if) K
( i == 0:) p n
(            ) S
(print) K
(\(") p
(\\n\\n\\n\\n) str
("\)) p n
(            ) S
(print) K
(\(f") p
(Initial Training Loss => {current_train_batch_loss:0.4f}) str
("\)) p n
(            minimum_val_loss = current_train_batch_loss) N
() N
(        grads = tape.gradient\(current_train_batch_loss, classifier.trainable_var) N
(iables\)) N
() N
(        adam.apply_gradients\(zip\(grads, classifier.trainable_variables\)\)) N
() N
(        ) S
(if) K
( i % refresh_rate == \(refresh_rate - 1\):) p n
(            \() N
(                current_val_loss,) N
(                minimum_val_loss,) N
(                minimum_val_step_num,) N
(            \) = val_loss\() N
(                classifier,) N
(                val_images,) N
(                val_labels,) N
(                checkpoint_manager,) N
(                minimum_val_loss,) N
(                minimum_val_step_num,) N
(                i,) N
(            \)) N
() N
(            y_val_loss = np.append\(y_val_loss, current_val_loss\)) N
(            current_train_batch_loss = current_train_batch_loss.numpy\(\)) N
(            y_train_batch_loss = np.append\(y_train_batch_loss, current_train_bat) N
(ch_loss\)) N
(            x_loss_iterations = np.append\(x_loss_iterations, i\)) N
() N
(            current_batch_accuracy = train_batch_accuracy\() N
(classify_cifar10.py) (Page 4/6) (Nov 04, 23 17:25) title
border
grestore
(Printed by ) rhead
() (Monday November 27, 2023) (40/79) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (5) 41
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(                classifier, train_images_batch, train_labels_batch) p n
(            \)) N
(            current_validation_accuracy = val_accuracy\() N
(                classifier, val_images, val_labels) N
(            \)) N
() N
(            x_accuracy_iterations = np.append\(x_accuracy_iterations, i\)) N
(            y_train_batch_accuracy = np.append\() N
(                y_train_batch_accuracy, current_batch_accuracy) N
(            \)) N
(            y_val_accuracy = np.append\(y_val_accuracy, current_validation_accura) N
(cy\)) N
() N
(            learning_rates_left = len\(learning_rates\) - learning_rate_index) N
(            used_patience = i - minimum_val_step_num) N
(            patience_left = learning_patience - used_patience) N
(            overall_description = \() N
(                f") S
(Minimum Val Loss => {minimum_val_loss:0.4f}    ) str
(") p n
(                + f") S
(Learning Rates Left => {learning_rates_left}    ) str
(") p n
(                + f") S
(Patience Left => {patience_left}    ) str
(") p n
(            \)) N
(            overall_log.set_description_str\(overall_description\)) N
(            overall_log.refresh\(\)) N
() N
(            train_description = \() N
(                f") S
(Train Batch Loss => {current_train_batch_loss:0.4f}    ) str
(") p n
(                + f") S
(Train Accuracy => {current_batch_accuracy:0.4f}    ) str
(") p n
(            \)) N
(            train_log.set_description_str\(train_description\)) N
(            train_log.update\(refresh_rate\)) N
() N
(            val_description = \() N
(                f") S
(Val Loss => {current_val_loss:0.4f}    ) str
(") p n
(                + f") S
(Val Accuracy => {current_validation_accuracy:0.4f}    ) str
(") p n
(            \)) N
(            val_log.set_description_str\(val_description\)) N
(            val_log.update\(refresh_rate\)) N
() N
(            bar_description = f") S
(Step => {i}) str
(") p n
(            bar.set_description\(bar_description\)) N
(            bar.refresh\(\)) N
() N
(            ) S
(# if the validation loss has not improved for learning_patience) c n
(            ) p
(if) K
( \() p n
(                current_val_loss > minimum_val_loss) N
(                ) S
(and) K
( i - minimum_val_step_num > learning_patience) p n
(            \):) N
(                ) S
(if) K
( learning_rate_index == \(len\(learning_rates\) - 1\):) p n
(                    ) S
(break) K n
(                learning_rate_index += 1) p n
(                adam.learning_rate = learning_rates[learning_rate_index]) N
(                learning_rate_change_steps = np.append\(learning_rate_change_step) N
(s, i\)) N
(                minimum_val_step_num = i) N
(                checkpoint_manager.restore_or_initialize\(\)) N
() N
(    checkpoint_manager.restore_or_initialize\(\)) N
() N
(    fig, ax = plt.subplots\(2, 1\)) N
() N
(    ax[0].plot\(x_accuracy_iterations, y_train_batch_accuracy, label=") S
(Train Accuracy) str
() p n
("\)) N
(    ax[0].plot\(x_accuracy_iterations, y_val_accuracy, label=") S
(Val Accuracy) str
("\)) p n
(    ) S
(# plot vertical line on learning rate change) c n
(    ) p
(for) K
( learning_rate_change_step ) p
(in) K
( learning_rate_change_steps:) p n
(        ax[0].axvline\(x=learning_rate_change_step, color=") S
(black) str
(", linestyle=") p
(dashe) str n
(classify_cifar10.py) (Page 5/6) (Nov 04, 23 17:25) title
border
grestore
(Printed by ) rhead
() (41/79) (Monday November 27, 2023) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (6) 42
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(d) str
("\)) p n
(    ax[0].set_xlabel\(") S
(Iterations) str
("\)) p n
(    ax[0].set_ylabel\(") S
(Accuracy) str
("\)) p n
(    ax[0].legend\(\)) N
() N
(    ax[1].semilogy\(x_loss_iterations, y_train_batch_loss, label=") S
(Train Batch Loss) str
("\)) p n
(    ax[1].semilogy\(x_loss_iterations, y_val_loss, label=") S
(Val Loss) str
("\)) p n
(    ) S
(for) K
( learning_rate_change_step ) p
(in) K
( learning_rate_change_steps:) p n
(        ax[1].axvline\(x=learning_rate_change_step, color=") S
(black) str
(", linestyle=") p
(dashe) str n
(d) S
("\)) p n
(    ax[1].set_xlabel\(") S
(Iterations) str
("\)) p n
(    ax[1].set_ylabel\(") S
(Loss) str
("\)) p n
(    ax[1].legend\(\)) N
() N
(    ) S
(print) K
(\(") p
(\\n\\n\\n\\n) str
("\)) p n
(    ) S
(print) K
(\(f") p
(Final Training Loss => {current_train_batch_loss:0.4f}) str
("\)) p n
(    ) S
(print) K
(\(f") p
(Stop Iteration => {i}) str
("\)) p n
() N
(    final_test_accuracy = test_accuracy\(classifier, test_images, test_labels\)) N
(    final_top_5_test_accuracy = top_5_test_accuracy\() N
(        classifier, test_images, test_labels) N
(    \)) N
(    ) S
(print) K
(\(f") p
(Test Accuracy => {final_test_accuracy:0.4f}) str
("\)) p n
(    ) S
(print) K
(\(f") p
(Top 5 Test Accuracy => {final_top_5_test_accuracy:0.4f}) str
("\)) p n
(    fig.suptitle\() N
(        ") S
(Classify Cifar10: Test Accuracy = ) str
(") p n
(        + str\(final_test_accuracy\)) N
(        + ") S
(\\nTop 5 Test Accuracy = ) str
(") p n
(        + str\(final_top_5_test_accuracy\)) N
(    \)) N
() N
(    ) S
(# if the file already exists add a number to the end of the file name) c n
(    ) p
(# to avoid overwriting) c n
(    file_index = 0) p n
(    ) S
(while) K
( Path\(f") p
(artifacts/classify_cifar10_img_{file_index}.png) str
("\).exists\(\):) p n
(        file_index += 1) N
(    fig.savefig\(f") S
(artifacts/classify_cifar10_img_{file_index}.png) str
("\)) p n
() N
(    ) S
(# Save the config file as a yaml under the same name as the image) c n
(    config_path = Path\(f") p
(artifacts/classify_cifar10_img_{file_index}.yaml) str
("\)) p n
(    config_path.write_text\(yaml.dump\(config\)\)) N
(classify_cifar10.py) (Page 6/6) (Nov 04, 23 17:25) title
border
grestore
(Printed by ) rhead
() (Monday November 27, 2023) (42/79) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (1) 43
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(from) K
( pathlib ) p
(import) K
( Path) p n
() N
(import) K
( matplotlib.pyplot as plt) p n
(import) K
( numpy as np) p n
(import) K
( tensorflow as tf) p n
(import) K
( tqdm) p n
(import) K
( yaml) p n
() N
(from) K
( helpers.adam ) p
(import) K
( Adam) p n
(from) K
( helpers.augment_data ) p
(import) K
( AugmentData) p n
(from) K
( helpers.load_pickle_data ) p
(import) K
( load_pickle_data) p n
(from) K
( modules.classifier ) p
(import) K
( Classifier) p n
() N
(from) K
( sklearn.metrics ) p
(import) K
( top_k_accuracy_score) p n
() N
() N
(def) K
( train_batch_accuracy\(classifier, train_images_batch, train_labels_batch\):) p n
(    ) S
(return) K
( tf.reduce_mean\() p n
(        tf.cast\() N
(            tf.equal\() N
(                classifier\(train_images_batch\).numpy\(\).argmax\(axis=1\),) N
(                train_labels_batch.numpy\(\).reshape\(-1\),) N
(            \),) N
(            tf.float32,) N
(        \)) N
(    \)) N
() N
() N
(def) K
( val_accuracy\(classifier, val_images, val_labels\):) p n
(    ) S
(return) K
( tf.reduce_mean\() p n
(        tf.cast\() N
(            tf.equal\() N
(                classifier\(val_images\).numpy\(\).argmax\(axis=1\),) N
(                val_labels.numpy\(\).reshape\(-1\),) N
(            \),) N
(            tf.float32,) N
(        \)) N
(    \)) N
() N
() N
(def) K
( test_accuracy\(classifier, test_images, test_labels\):) p n
(    ) S
(return) K
( tf.reduce_mean\() p n
(        tf.cast\() N
(            tf.equal\() N
(                classifier\(test_images\).numpy\(\).argmax\(axis=1\),) N
(                test_labels.numpy\(\).reshape\(-1\),) N
(            \),) N
(            tf.float32,) N
(        \)) N
(    \).numpy\(\)) N
() N
() N
(def) K
( top_5_test_accuracy\(classifier, test_images, test_labels\):) p n
(    ) S
(return) K
( top_k_accuracy_score\() p n
(        test_labels.numpy\(\).reshape\(-1\), classifier\(test_images\).numpy\(\), k=5) N
(    \)) N
() N
() N
(def) K
( val_loss\() p n
(    classifier,) N
(    val_images,) N
(    val_labels,) N
(    checkpoint_manager,) N
(    minimum_val_loss,) N
(    minimum_val_step,) N
(    current_step,) N
(classify_cifar100.py) (Page 1/6) (Nov 04, 23 17:25) title
border
grestore
(Printed by ) rhead
() (43/79) (Monday November 27, 2023) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (2) 44
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(\):) p n
(    validation_loss = tf.reduce_mean\() N
(        tf.nn.sparse_softmax_cross_entropy_with_logits\() N
(            labels=tf.squeeze\(val_labels\), logits=classifier\(val_images\)) N
(        \)) N
(    \)) N
() N
(    ) S
(if) K
( validation_loss < minimum_val_loss:) p n
(        minimum_val_loss = validation_loss) N
(        minimum_val_step = current_step) N
(        checkpoint_manager.save\(\)) N
() N
(    ) S
(return) K
( validation_loss, minimum_val_loss, minimum_val_step) p n
() N
() N
(def) K
( train\(config_path: Path, use_last_checkpoint: bool\):) p n
(    ) S
(if) K
( config_path ) p
(is) K
( None:) p n
(        config_path = Path\(") S
(configs/classify_cifar_config.yaml) str
("\)) p n
() N
(    config = yaml.safe_load\(config_path.read_text\(\)\)) N
(    resblock_size = config[") S
(cnn) str
("][") p
(resblock_size) str
("]) p n
(    pool_size = config[") S
(cnn) str
("][") p
(pool_size) str
("]) p n
(    augmentation_multiplier = config[") S
(cnn) str
("][") p
(augmentation_multiplier) str
("]) p n
(    layers = config[") S
(cnn) str
("][") p
(layers) str
("]) p n
(    num_iters = config[") S
(learning) str
("][") p
(num_iters) str
("]) p n
(    weight_decay = config[") S
(learning) str
("][") p
(weight_decay) str
("]) p n
(    dropout_prob = config[") S
(learning) str
("][") p
(dropout_prob) str
("]) p n
(    batch_size = config[") S
(learning) str
("][") p
(batch_size) str
("]) p n
(    learning_patience = config[") S
(learning) str
("][") p
(learning_patience) str
("]) p n
(    learning_rates = config[") S
(learning) str
("][") p
(learning_rates) str
("]) p n
(    refresh_rate = config[") S
(display) str
("][") p
(refresh_rate) str
("]) p n
(    num_hidden_layers = config[") S
(mlp) str
("][") p
(num_hidden_layers) str
("]) p n
(    hidden_layer_width = config[") S
(mlp) str
("][") p
(hidden_layer_width) str
("]) p n
() N
(    layer_depths = [layer[") S
(depth) str
("] ) p
(for) K
( layer ) p
(in) K
( layers]) p n
(    kernel_sizes = [layer[") S
(kernel_size) str
("] ) p
(for) K
( layer ) p
(in) K
( layers]) p n
(    group_norm_num_groups = [layer[") S
(group_norm_num_groups) str
("] ) p
(for) K
( layer ) p
(in) K
( layers]) p n
() N
(    rng = tf.random.get_global_generator\(\)) N
(    rng.reset_from_seed\(0x43966E87BD57227011B5B03B58785EC1\)) N
() N
(    train_and_val_labels, train_and_val_images = load_pickle_data\() N
(        ") S
(data/cifar-100-python/train) str
(", ") p
(fine_labels) str
(") p n
(    \)) N
() N
(    num_classes = 100) N
(    train_labels = train_and_val_labels[:-10000]) N
(    train_images = train_and_val_images[:-10000]) N
(    val_labels = train_and_val_labels[-10000:]) N
(    val_images = train_and_val_images[-10000:]) N
() N
(    test_labels, test_images = load_pickle_data\() N
(        ") S
(data/cifar-100-python/test) str
(", ") p
(fine_labels) str
(") p n
(    \)) N
() N
(    num_samples = train_images.shape[0]) N
(    input_depth = train_images.shape[-1]) N
(    classifier = Classifier\() N
(        input_depth,) N
(        layer_depths,) N
(        kernel_sizes,) N
(        num_classes,) N
(        train_images.shape[1],) N
(        resblock_size,) N
(        pool_size,) N
(        dropout_prob,) N
(classify_cifar100.py) (Page 2/6) (Nov 04, 23 17:25) title
border
grestore
(Printed by ) rhead
() (Monday November 27, 2023) (44/79) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (3) 45
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(        group_norm_num_groups,) p n
(        num_hidden_layers,) N
(        hidden_layer_width,) N
(    \)) N
() N
(    minimum_val_step_num = 0) N
(    current_val_loss = 0) N
() N
(    ) S
(# Used For Plotting) c n
(    y_train_batch_accuracy = np.array\([]\)) p n
(    y_train_batch_loss = np.array\([]\)) N
(    y_val_accuracy = np.array\([]\)) N
(    y_val_loss = np.array\([]\)) N
(    x_loss_iterations = np.array\([]\)) N
(    x_accuracy_iterations = np.array\([]\)) N
() N
(    learning_rate_change_steps = np.array\([]\)) N
() N
(    ) S
(# Index of the current learning rate, used to change the learning rate) c n
(    ) p
(# when the validation loss stops improving) c n
(    learning_rate_index = 0) p n
(    adam = Adam\() N
(        learning_rates[learning_rate_index],) N
(        weight_decay=weight_decay,) N
(    \)) N
() N
(    checkpoint = tf.train.Checkpoint\(classifier\)) N
(    checkpoint_manager = tf.train.CheckpointManager\() N
(        checkpoint, ") S
(temp/checkpoints/classify_numbers) str
(", max_to_keep=1) p n
(    \)) N
(    ) S
(if) K
( use_last_checkpoint:) p n
(        ) S
(print) K
(\(") p
(\\n\\nRestoring from last checkpoint) str
("\)) p n
(        checkpoint_manager.restore_or_initialize\(\)) N
() N
(    overall_log = tqdm.tqdm\(total=0, position=1, bar_format=") S
({desc}) str
("\)) p n
(    train_log = tqdm.tqdm\(total=0, position=2, bar_format=") S
({desc}) str
("\)) p n
(    val_log = tqdm.tqdm\(total=0, position=3, bar_format=") S
({desc}) str
("\)) p n
(    bar = tqdm.trange\(num_iters, position=4\)) N
() N
(    num_of_parameters = tf.math.add_n\() N
(        [tf.math.reduce_prod\(var.shape\) ) S
(for) K
( var ) p
(in) K
( classifier.trainable_variable) p n
(s]) N
(    \)) N
(    ) S
(print) K
(\(f") p
(\\nNumber of Parameters => {num_of_parameters}) str
("\)) p n
() N
(    augment_data = AugmentData\(augmentation_multiplier\)) N
(    ) S
(for) K
( i ) p
(in) K
( bar:) p n
(        batch_indices = rng.uniform\() N
(            shape=[batch_size], maxval=num_samples, dtype=tf.int32) N
(        \)) N
(        with tf.GradientTape\(\) as tape:) N
(            train_images_batch = tf.gather\(train_images, batch_indices\)) N
(            train_labels_batch = tf.gather\(train_labels, batch_indices\)) N
() N
(            train_labels_batch, train_images_batch = augment_data\() N
(                train_labels_batch, train_images_batch) N
(            \)) N
(            current_train_batch_loss = tf.reduce_mean\() N
(                tf.nn.sparse_softmax_cross_entropy_with_logits\() N
(                    labels=tf.squeeze\(train_labels_batch\),) N
(                    logits=classifier\(train_images_batch\),) N
(                \)) N
(            \)) N
() N
(        ) S
(# Print initial train batch loss) c n
(        ) p
(if) K
( i == 0:) p n
(classify_cifar100.py) (Page 3/6) (Nov 04, 23 17:25) title
border
grestore
(Printed by ) rhead
() (45/79) (Monday November 27, 2023) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (4) 46
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(            ) p
(print) K
(\(") p
(\\n\\n\\n\\n) str
("\)) p n
(            ) S
(print) K
(\(f") p
(Initial Training Loss => {current_train_batch_loss:0.4f}) str
("\)) p n
(            minimum_val_loss = current_train_batch_loss) N
() N
(        grads = tape.gradient\(current_train_batch_loss, classifier.trainable_var) N
(iables\)) N
() N
(        adam.apply_gradients\(zip\(grads, classifier.trainable_variables\)\)) N
() N
(        \() N
(            current_val_loss,) N
(            minimum_val_loss,) N
(            minimum_val_step_num,) N
(        \) = val_loss\() N
(            classifier,) N
(            val_images,) N
(            val_labels,) N
(            checkpoint_manager,) N
(            minimum_val_loss,) N
(            minimum_val_step_num,) N
(            i,) N
(        \)) N
() N
(        y_val_loss = np.append\(y_val_loss, current_val_loss\)) N
(        current_train_batch_loss = current_train_batch_loss.numpy\(\)) N
(        y_train_batch_loss = np.append\(y_train_batch_loss, current_train_batch_l) N
(oss\)) N
(        x_loss_iterations = np.append\(x_loss_iterations, i\)) N
() N
(        ) S
(if) K
( i % refresh_rate == \(refresh_rate - 1\):) p n
(            current_batch_accuracy = train_batch_accuracy\() N
(                classifier, train_images_batch, train_labels_batch) N
(            \)) N
(            current_validation_accuracy = val_accuracy\() N
(                classifier, val_images, val_labels) N
(            \)) N
() N
(            x_accuracy_iterations = np.append\(x_accuracy_iterations, i\)) N
(            y_train_batch_accuracy = np.append\() N
(                y_train_batch_accuracy, current_batch_accuracy) N
(            \)) N
(            y_val_accuracy = np.append\(y_val_accuracy, current_validation_accura) N
(cy\)) N
() N
(            learning_rates_left = len\(learning_rates\) - learning_rate_index) N
(            used_patience = i - minimum_val_step_num) N
(            patience_left = learning_patience - used_patience) N
(            overall_description = \() N
(                f") S
(Minimum Val Loss => {minimum_val_loss:0.4f}    ) str
(") p n
(                + f") S
(Learning Rates Left => {learning_rates_left}    ) str
(") p n
(                + f") S
(Patience Left => {patience_left}    ) str
(") p n
(            \)) N
(            overall_log.set_description_str\(overall_description\)) N
(            overall_log.refresh\(\)) N
() N
(            train_description = \() N
(                f") S
(Train Batch Loss => {current_train_batch_loss:0.4f}    ) str
(") p n
(                + f") S
(Train Accuracy => {current_batch_accuracy:0.4f}    ) str
(") p n
(            \)) N
(            train_log.set_description_str\(train_description\)) N
(            train_log.update\(refresh_rate\)) N
() N
(            val_description = \() N
(                f") S
(Val Loss => {current_val_loss:0.4f}    ) str
(") p n
(                + f") S
(Val Accuracy => {current_validation_accuracy:0.4f}    ) str
(") p n
(            \)) N
(classify_cifar100.py) (Page 4/6) (Nov 04, 23 17:25) title
border
grestore
(Printed by ) rhead
() (Monday November 27, 2023) (46/79) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (5) 47
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(            val_log.set_description_str\(val_description\)) p n
(            val_log.update\(refresh_rate\)) N
() N
(            bar_description = f") S
(Step => {i}) str
(") p n
(            bar.set_description\(bar_description\)) N
(            bar.refresh\(\)) N
() N
(            ) S
(# if the validation loss has not improved for learning_patience) c n
(            ) p
(if) K
( \() p n
(                current_val_loss > minimum_val_loss) N
(                ) S
(and) K
( i - minimum_val_step_num > learning_patience) p n
(            \):) N
(                ) S
(if) K
( learning_rate_index == \(len\(learning_rates\) - 1\):) p n
(                    ) S
(break) K n
(                learning_rate_index += 1) p n
(                adam.learning_rate = learning_rates[learning_rate_index]) N
(                learning_rate_change_steps = np.append\(learning_rate_change_step) N
(s, i\)) N
(                minimum_val_step_num = i) N
(                checkpoint_manager.restore_or_initialize\(\)) N
() N
(    checkpoint_manager.restore_or_initialize\(\)) N
() N
(    fig, ax = plt.subplots\(2, 1\)) N
() N
(    ax[0].plot\(x_accuracy_iterations, y_train_batch_accuracy, label=") S
(Train Accuracy) str
() p n
("\)) N
(    ax[0].plot\(x_accuracy_iterations, y_val_accuracy, label=") S
(Val Accuracy) str
("\)) p n
(    ) S
(# plot vertical line on learning rate change) c n
(    ) p
(for) K
( learning_rate_change_step ) p
(in) K
( learning_rate_change_steps:) p n
(        ax[0].axvline\(x=learning_rate_change_step, color=") S
(black) str
(", linestyle=") p
(dashe) str n
(d) S
("\)) p n
(    ax[0].set_xlabel\(") S
(Iterations) str
("\)) p n
(    ax[0].set_ylabel\(") S
(Accuracy) str
("\)) p n
(    ax[0].legend\(\)) N
() N
(    ax[1].semilogy\(x_loss_iterations, y_train_batch_loss, label=") S
(Train Batch Loss) str
("\)) p n
(    ax[1].semilogy\(x_loss_iterations, y_val_loss, label=") S
(Val Loss) str
("\)) p n
(    ) S
(for) K
( learning_rate_change_step ) p
(in) K
( learning_rate_change_steps:) p n
(        ax[1].axvline\(x=learning_rate_change_step, color=") S
(black) str
(", linestyle=") p
(dashe) str n
(d) S
("\)) p n
(    ax[1].set_xlabel\(") S
(Iterations) str
("\)) p n
(    ax[1].set_ylabel\(") S
(Loss) str
("\)) p n
(    ax[1].legend\(\)) N
() N
(    ) S
(print) K
(\(") p
(\\n\\n\\n\\n) str
("\)) p n
(    ) S
(print) K
(\(f") p
(Final Training Loss => {current_train_batch_loss:0.4f}) str
("\)) p n
(    ) S
(print) K
(\(f") p
(Stop Iteration => {i}) str
("\)) p n
() N
(    final_test_accuracy = test_accuracy\(classifier, test_images, test_labels\)) N
(    final_top_5_test_accuracy = top_5_test_accuracy\() N
(        classifier, test_images, test_labels) N
(    \)) N
(    ) S
(print) K
(\(f") p
(Test Accuracy => {final_test_accuracy:0.4f}) str
("\)) p n
(    ) S
(print) K
(\(f") p
(Top 5 Test Accuracy => {final_top_5_test_accuracy:0.4f}) str
("\)) p n
(    fig.suptitle\() N
(        ") S
(Classify Cifar100: Test Accuracy = ) str
(") p n
(        + str\(final_test_accuracy\)) N
(        + ") S
(\\nTop 5 Test Accuracy = ) str
(") p n
(        + str\(final_top_5_test_accuracy\)) N
(    \)) N
() N
(    ) S
(# if the file already exists add a number to the end of the file name) c n
(    ) p
(# to avoid overwriting) c n
(    file_index = 0) p n
(    ) S
(while) K
( Path\(f") p
(artifacts/classify_cifar100_img_{file_index}.png) str
("\).exists\(\):) p n
(classify_cifar100.py) (Page 5/6) (Nov 04, 23 17:25) title
border
grestore
(Printed by ) rhead
() (47/79) (Monday November 27, 2023) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (6) 48
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(        file_index += 1) p n
(    fig.savefig\(f") S
(artifacts/classify_cifar100_img_{file_index}.png) str
("\)) p n
() N
(    ) S
(# Save the config file as a yaml under the same name as the image) c n
(    config_path = Path\(f") p
(artifacts/classify_cifar100_img_{file_index}.yaml) str
("\)) p n
(    config_path.write_text\(yaml.dump\(config\)\)) N
(classify_cifar100.py) (Page 6/6) (Nov 04, 23 17:25) title
border
grestore
(Printed by ) rhead
() (Monday November 27, 2023) (48/79) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (1) 49
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(import) K
( tempfile) p n
(from) K
( pathlib ) p
(import) K
( Path) p n
() N
(import) K
( matplotlib.pyplot as plt) p n
(import) K
( numpy as np) p n
(import) K
( tensorflow as tf) p n
(import) K
( tqdm) p n
(import) K
( yaml) p n
() N
(from) K
( helpers.adam ) p
(import) K
( Adam) p n
(from) K
( modules.transformer_decoder ) p
(import) K
( TransformerDecoder) p n
() N
() N
(def) K
( train_batch_accuracy\(logits, labels\):) p n
(    ) S
(return) K
( tf.reduce_mean\() p n
(        tf.cast\() N
(            tf.equal\() N
(                logits.numpy\(\).argmax\(axis=2\).reshape\(-1\),) N
(                labels.numpy\(\).reshape\(-1\),) N
(            \),) N
(            tf.float32,) N
(        \)) N
(    \)) N
() N
() N
(def) K
( train\(config_path: Path, use_last_checkpoint: bool\):) p n
(    ) S
(if) K
( config_path ) p
(is) K
( None:) p n
(        config_path = Path\(") S
(configs/predict_who_bites_who.yaml) str
("\)) p n
() N
(    ) S
(# HYPERPARAMETERS) c n
(    config = yaml.safe_load\(config_path.read_text\(\)\)) p n
(    refresh_rate = config[") S
(display) str
("][") p
(refresh_rate) str
("]) p n
(    batch_size = config[") S
(learning) str
("][") p
(batch_size) str
("]) p n
(    learning_patience = config[") S
(learning) str
("][") p
(learning_patience) str
("]) p n
(    learning_rates = config[") S
(learning) str
("][") p
(learning_rates) str
("]) p n
(    num_iters = config[") S
(learning) str
("][") p
(num_iters) str
("]) p n
(    weight_decay = config[") S
(learning) str
("][") p
(weight_decay) str
("]) p n
(    context_length = config[") S
(data) str
("][") p
(context_length) str
("]) p n
(    num_heads = config[") S
(transformer) str
("][") p
(num_heads) str
("]) p n
(    model_dim = config[") S
(transformer) str
("][") p
(model_dim) str
("]) p n
(    ffn_dim = config[") S
(transformer) str
("][") p
(ffn_dim) str
("]) p n
(    num_blocks = config[") S
(transformer) str
("][") p
(num_blocks) str
("]) p n
() N
(    rng = tf.random.get_global_generator\(\)) N
(    rng.reset_from_seed\(0x43966E87BD57227011B5B03B58785EC1\)) N
(    tf.random.set_seed\(0x43966E87BD57227011B5B03B58785EC1\)) N
() N
(    with open\(") S
(data/who_bites_who.txt) str
(", ") p
(r) str
(", encoding=") p
(utf-8) str
("\) as file:) p n
(        input_text = file.read\(\)) N
() N
(    transformer_decoder = TransformerDecoder\() N
(        context_length,) N
(        num_heads,) N
(        model_dim,) N
(        ffn_dim,) N
(        num_blocks,) N
(        input_text,) N
(    \)) N
() N
(    text, targets = transformer_decoder.get_tokens_and_targets\(\)) N
() N
(    used_patience = 0) N
(    minimum_train_loss = np.inf) N
(    minimum_loss_step_num = 0) N
() N
(    ) S
(# Used For Plotting) c n
(predict_who_bites_who.py) (Page 1/6) (Nov 12, 23 23:48) title
border
grestore
(Printed by ) rhead
() (49/79) (Monday November 27, 2023) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (2) 50
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(    y_train_accuracy = np.array\([]\)) p n
(    y_train_batch_loss = np.array\([]\)) N
(    x_train_loss_iterations = np.array\([]\)) N
(    x_train_accuracy_iterations = np.array\([]\)) N
() N
(    learning_rate_change_steps = np.array\([]\)) N
() N
(    ) S
(# Index of the current learning rate, used to change the learning rate) c n
(    ) p
(# when the training loss stops improving) c n
(    learning_rate_index = 0) p n
(    adam = Adam\() N
(        learning_rates[learning_rate_index],) N
(        weight_decay=weight_decay,) N
(    \)) N
() N
(    ) S
(# find the temp_dir with the prefix "who_bites_who_" if it exists) c n
(    ) p
(# otherwise create a new one) c n
(    temp_dir = None) p n
(    ) S
(for) K
( temp_dir ) p
(in) K
( Path\(tempfile.gettempdir\(\)\).iterdir\(\):) p n
(        ) S
(if) K
( temp_dir.is_dir\(\) ) p
(and) K
( temp_dir.name.startswith\(") p
(who_bites_who_) str
("\):) p n
(            ) S
(break) K n
() p n
(    ) S
(if) K
( ) p
(not) K
( temp_dir.name.startswith\(") p
(who_bites_who_) str
("\):) p n
(        temp_dir = tempfile.mkdtemp\(prefix=") S
(who_bites_who_) str
("\)) p n
() N
(    checkpoint = tf.train.Checkpoint\(transformer_decoder\)) N
(    checkpoint_manager = tf.train.CheckpointManager\() N
(        checkpoint,) N
(        temp_dir,) N
(        max_to_keep=1,) N
(    \)) N
(    ) S
(if) K
( use_last_checkpoint:) p n
(        ) S
(print) K
(\(") p
(\\n\\nRestoring from last checkpoint) str
("\)) p n
(        checkpoint_manager.restore_or_initialize\(\)) N
() N
(    overall_log = tqdm.tqdm\(total=0, position=1, bar_format=") S
({desc}) str
("\)) p n
(    train_log = tqdm.tqdm\(total=0, position=2, bar_format=") S
({desc}) str
("\)) p n
(    bar = tqdm.trange\(num_iters, position=3\)) N
() N
(    num_of_parameters = tf.math.add_n\() N
(        [) N
(            tf.math.reduce_prod\(var.shape\)) N
(            ) S
(for) K
( var ) p
(in) K
( transformer_decoder.trainable_variables) p n
(        ]) N
(    \)) N
(    ) S
(print) K
(\(f") p
(\\nNumber of Parameters => {num_of_parameters}) str
("\)) p n
() N
(    ) S
(for) K
( i ) p
(in) K
( bar:) p n
(        batch_indices = rng.uniform\() N
(            shape=[batch_size], maxval=text.shape[0], dtype=tf.int32) N
(        \)) N
() N
(        with tf.GradientTape\(\) as tape:) N
(            input_tokens_batch = tf.gather\(text, batch_indices\)) N
(            targets_batch = tf.gather\(targets, batch_indices\)) N
() N
(            labels = targets_batch) N
(            logits = transformer_decoder\(input_tokens_batch\)) N
(            current_train_loss = tf.reduce_mean\() N
(                tf.nn.sparse_softmax_cross_entropy_with_logits\() N
(                    labels=labels,) N
(                    logits=logits,) N
(                \)) N
(            \)) N
() N
(        ) S
(# Print initial train batch loss) c n
(predict_who_bites_who.py) (Page 2/6) (Nov 12, 23 23:48) title
border
grestore
(Printed by ) rhead
() (Monday November 27, 2023) (50/79) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (3) 51
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(        ) p
(if) K
( i == 0:) p n
(            ) S
(print) K
(\(") p
(\\n\\n\\n\\n) str
("\)) p n
(            ) S
(print) K
(\(f") p
(Initial Training Loss => {current_train_loss:0.4f}) str
("\)) p n
() N
(        grads = tape.gradient\() N
(            current_train_loss, transformer_decoder.trainable_variables) N
(        \)) N
() N
(        adam.apply_gradients\(zip\(grads, transformer_decoder.trainable_variables\)) N
(\)) N
() N
(        current_train_loss = current_train_loss.numpy\(\)) N
() N
(        ) S
(if) K
( current_train_loss < minimum_train_loss:) p n
(            minimum_train_loss = current_train_loss) N
(            minimum_loss_step_num = i) N
(            checkpoint_manager.save\(\)) N
(        used_patience = i - minimum_loss_step_num) N
() N
(        y_train_batch_loss = np.append\(y_train_batch_loss, current_train_loss\)) N
(        x_train_loss_iterations = np.append\(x_train_loss_iterations, i\)) N
() N
(        ) S
(if) K
( i % refresh_rate == \(refresh_rate - 1\):) p n
(            current_batch_accuracy = train_batch_accuracy\(logits, labels\)) N
(            x_train_accuracy_iterations = np.append\(x_train_accuracy_iterations,) N
( i\)) N
(            y_train_accuracy = np.append\(y_train_accuracy, current_batch_accurac) N
(y\)) N
() N
(            learning_rates_left = len\(learning_rates\) - learning_rate_index) N
(            patience_left = learning_patience - used_patience) N
(            overall_description = \() N
(                f") S
(Minimum Train Loss => {minimum_train_loss:0.4f}    ) str
(") p n
(                + f") S
(Learning Rates Left => {learning_rates_left}    ) str
(") p n
(                + f") S
(Patience Left => {patience_left}    ) str
(") p n
(            \)) N
(            overall_log.set_description_str\(overall_description\)) N
(            overall_log.refresh\(\)) N
() N
(            train_description = \() N
(                f") S
(Train Batch Loss => {current_train_loss:0.4f}    ) str
(") p n
(                + f") S
(Train Accuracy => {current_batch_accuracy:0.4f}    ) str
(") p n
(            \)) N
(            train_log.set_description_str\(train_description\)) N
(            train_log.update\(refresh_rate\)) N
() N
(            bar_description = f") S
(Step => {i}) str
(") p n
(            bar.set_description\(bar_description\)) N
(            bar.refresh\(\)) N
() N
(            ) S
(# if the training loss has not improved for learning_patience) c n
(            ) p
(if) K
( \() p n
(                current_train_loss > minimum_train_loss) N
(                ) S
(and) K
( i - minimum_loss_step_num > learning_patience) p n
(            \):) N
(                ) S
(if) K
( learning_rate_index == \(len\(learning_rates\) - 1\):) p n
(                    ) S
(break) K n
(                learning_rate_index += 1) p n
(                adam.learning_rate = learning_rates[learning_rate_index]) N
(                learning_rate_change_steps = np.append\(learning_rate_change_step) N
(s, i\)) N
(                checkpoint_manager.restore_or_initialize\(\)) N
() N
(    checkpoint_manager.restore_or_initialize\(\)) N
() N
(    ) S
(# get the vocab file from) c n
(predict_who_bites_who.py) (Page 3/6) (Nov 12, 23 23:48) title
border
grestore
(Printed by ) rhead
() (51/79) (Monday November 27, 2023) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (4) 52
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(    vocab_file = transformer_decoder.get_vocab_file\(\)) p n
(    with open\(vocab_file.name, ") S
(r) str
(", encoding=") p
(utf-8) str
("\) as file:) p n
(        vocab_file_contents = file.read\(\)) N
() N
(    ) S
(# save a copy to the artifacts directory) c n
(    vocab_file_copy = Path\(") p
(artifacts/who_bites_who/model/vocab.txt) str
("\)) p n
(    with open\(vocab_file_copy, ") S
(w) str
(", encoding=") p
(utf-8) str
("\) as file:) p n
(        file.write\(vocab_file_contents\)) N
() N
(    ) S
(# delete the temporary directory) c n
(    tf.io.gfile.rmtree\(temp_dir\)) p n
() N
(    checkpoint_manager = tf.train.CheckpointManager\() N
(        checkpoint, ") S
(artifacts/who_bites_who/model) str
(", max_to_keep=1) p n
(    \)) N
(    checkpoint_manager.save\(\)) N
() N
(    batch_indices = rng.uniform\() N
(        shape=[batch_size], maxval=text.shape[0], dtype=tf.int32) N
(    \)) N
(    input_tokens_batch = tf.gather\(text, batch_indices\)) N
(    targets_batch = tf.gather\(targets, batch_indices\)) N
() N
(    fig, ax = plt.subplots\(2, 1\)) N
(    plt.subplots_adjust\(hspace=0.5\)) N
() N
(    ax[0].semilogy\(x_train_loss_iterations, y_train_batch_loss, label=") S
(Training Los) str n
(s) S
("\)) p n
(    ) S
(for) K
( learning_rate_change_step ) p
(in) K
( learning_rate_change_steps:) p n
(        ax[0].axvline\() N
(            x=learning_rate_change_step,) N
(            color=") S
(black) str
(",) p n
(            linestyle=") S
(dashed) str
(",) p n
(            label=") S
(Learning Rate Change) str
(",) p n
(        \)) N
(    ax[0].axvline\() N
(        x=minimum_loss_step_num, color=") S
(red) str
(", linestyle=") p
(dashed) str
(", label=") p
(Minimum Lo) str n
(ss) S
(") p n
(    \)) N
(    ax[0].set_xlabel\(") S
(Iterations) str
("\)) p n
(    ax[0].set_ylabel\(") S
(Loss) str
("\)) p n
() N
(    ax[1].plot\(x_train_accuracy_iterations, y_train_accuracy, label=") S
(Training Accura) str n
(cy) S
("\)) p n
(    ) S
(for) K
( learning_rate_change_step ) p
(in) K
( learning_rate_change_steps:) p n
(        ax[1].axvline\() N
(            x=learning_rate_change_step,) N
(            color=") S
(black) str
(",) p n
(            linestyle=") S
(dashed) str
(",) p n
(            label=") S
(Learning Rate Change) str
(",) p n
(        \)) N
(    ax[1].axvline\() N
(        x=minimum_loss_step_num, color=") S
(red) str
(", linestyle=") p
(dashed) str
(", label=") p
(Minimum Lo) str n
(ss) S
(") p n
(    \)) N
(    ax[1].set_xlabel\(") S
(Iterations) str
("\)) p n
(    ax[1].set_ylabel\(") S
(Accuracy) str
("\)) p n
(    ax[1].legend\(loc=") S
(lower left) str
("\)) p n
() N
(    ) S
(print) K
(\(") p
(\\n\\n\\n\\n) str
("\)) p n
() N
(    labels = targets_batch) N
(    logits = transformer_decoder\(input_tokens_batch\)) N
(    final_train_accuracy = train_batch_accuracy\(logits, labels\)) N
() N
(    ) S
(print) K
(\(f") p
(Final Training Accuracy => {final_train_accuracy:0.4f}) str
("\)) p n
(predict_who_bites_who.py) (Page 4/6) (Nov 12, 23 23:48) title
border
grestore
(Printed by ) rhead
() (Monday November 27, 2023) (52/79) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (5) 53
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(    ) p
(print) K
(\(f") p
(Stop Iteration => {i}) str
("\)) p n
() N
(    fig.suptitle\() N
(        ") S
(Predict Who Bites Who: Final Train Accuracy = ) str
(") p n
(        + f") S
({final_train_accuracy:0.4f}) str
(") p n
(    \)) N
() N
(    ) S
(# if the file already exists add a number to the end of the file name) c n
(    ) p
(# to avoid overwriting) c n
(    file_index = 0) p n
(    ) S
(while) K
( Path\() p n
(        f") S
(artifacts/who_bites_who/predict_who_bites_who_img_{file_index}.png) str
(") p n
(    \).exists\(\):) N
(        file_index += 1) N
(    fig.savefig\(f") S
(artifacts/who_bites_who/predict_who_bites_who_img_{file_index}.png) str
("\)) p n
() N
(    ) S
(# Save the config file as a yaml under the same name as the image) c n
(    config_path = Path\() p n
(        f") S
(artifacts/who_bites_who/predict_who_bites_who_img_{file_index}.yaml) str
(") p n
(    \)) N
(    config_path.write_text\(yaml.dump\(config\)\)) N
() N
(    ) S
(# save the model) c n
(    checkpoint_manager.save\(\)) p n
(    config_path = Path\(f") S
(artifacts/who_bites_who/model/model.yaml) str
("\)) p n
(    config_path.write_text\(yaml.dump\(config\)\)) N
() N
() N
(def) K
( test\(model_path: Path\):) p n
(    ) S
(if) K
( model_path ) p
(is) K
( None:) p n
(        model_path = Path\(") S
(artifacts/who_bites_who/model) str
("\)) p n
() N
(    ) S
(if) K
( ) p
(not) K
( model_path.exists\(\):) p n
(        ) S
(print) K
(\(") p
(Model does not exist, run the train script first) str
("\)) p n
(        ) S
(return) K n
() p n
(    config_path = Path\(") S
(artifacts/who_bites_who/model/model.yaml) str
("\)) p n
() N
(    config = yaml.safe_load\(config_path.read_text\(\)\)) N
(    context_length = config[") S
(data) str
("][") p
(context_length) str
("]) p n
(    num_heads = config[") S
(transformer) str
("][") p
(num_heads) str
("]) p n
(    model_dim = config[") S
(transformer) str
("][") p
(model_dim) str
("]) p n
(    ffn_dim = config[") S
(transformer) str
("][") p
(ffn_dim) str
("]) p n
(    num_blocks = config[") S
(transformer) str
("][") p
(num_blocks) str
("]) p n
() N
(    rng = tf.random.get_global_generator\(\)) N
(    rng.reset_from_seed\(0x43966E87BD57227011B5B03B58785EC1\)) N
(    tf.random.set_seed\(0x43966E87BD57227011B5B03B58785EC1\)) N
() N
(    vocab_file = Path\(") S
(artifacts/who_bites_who/model/vocab.txt) str
("\)) p n
() N
(    transformer_decoder = TransformerDecoder\() N
(        context_length,) N
(        num_heads,) N
(        model_dim,) N
(        ffn_dim,) N
(        num_blocks,) N
(        vocab_file=vocab_file,) N
(    \)) N
() N
(    checkpoint = tf.train.Checkpoint\(transformer_decoder\)) N
(    checkpoint.restore\(tf.train.latest_checkpoint\(model_path\)\)) N
() N
(    ) S
(print) K
(\(") p
(\\n\\n\\n\\nEnter 'exit' to exit) str
("\)) p n
(    ) S
(while) K
( 1:) p n
(        input_text = input\(") S
(\\n\\nEnter a sentence: ) str
("\)) p n
(predict_who_bites_who.py) (Page 5/6) (Nov 12, 23 23:48) title
border
grestore
(Printed by ) rhead
() (53/79) (Monday November 27, 2023) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (6) 54
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(        ) p
(if) K
( input_text == ") p
(exit) str
(":) p n
(            ) S
(break) K n
() p n
(        tokenized_text = transformer_decoder.predict\(input_text\)) N
(        ) S
(print) K
(\(f") p
(Bite Bot: ) str
(" + tokenized_text\)) p n
(predict_who_bites_who.py) (Page 6/6) (Nov 12, 23 23:48) title
border
grestore
(Printed by ) rhead
() (Monday November 27, 2023) (54/79) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (1) 55
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(#!/usr/bin/env python3) c n
() p n
(import) K
( argparse) p n
(import) K
( importlib) p n
(from) K
( pathlib ) p
(import) K
( Path) p n
() N
(import) K
( argcomplete) p n
() N
() N
(def) K
( main\(\):) p n
(    parser = argparse.ArgumentParser\(description=") S
(Choose an example to train:) str
("\)) p n
(    parser.add_argument\(") S
(runner) str
(", type=Path,) p n
(                        help=") S
(Path to the runner file) str
("\)) p n
(    parser.add_argument\(") S
(--model) str
(", ") p
(-m) str
(", type=Path,) p n
(                        nargs=') S
(?) str
(', help=") p
(Path to the model directory) str
("\)) p n
() N
(    argcomplete.autocomplete\(parser\)) N
(    args = parser.parse_args\(\)) N
() N
(    runner = importlib.import_module\(f") S
(runners.{args.runner.stem}) str
("\)) p n
(    runner.test\(args.model\)) N
() N
() N
(if) K
( __name__ == ") p
(__main__) str
(":) p n
(    main\(\)) N
(test.py) (Page 1/1) (Nov 04, 23 17:25) title
border
grestore
(Printed by ) rhead
() (55/79) (Monday November 27, 2023) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (1) 56
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(import) K
( pytest) p n
() N
() N
(@pytest.mark.parametrize\(") S
(augmentation_probability) str
(", [0.0, 0.5, 1.0]\)) p n
(def) K
( test_dimenionality\(augmentation_probability\):) p n
(    ) S
(import) K
( tensorflow as tf) p n
() N
(    ) S
(from) K
( helpers.augment_data ) p
(import) K
( AugmentData) p n
(    ) S
(from) K
( helpers.load_pickle_data ) p
(import) K
( load_pickle_data) p n
() N
(    rng = tf.random.get_global_generator\(\)) N
(    rng.reset_from_seed\(2384230948\)) N
() N
(    augment_data = AugmentData\(augmentation_probability\)) N
() N
(    labels, images = load_pickle_data\(") S
(data/cifar-10-batches-py/data_batch_1) str
("\)) p n
() N
(    augmented_labels, augmented_images = augment_data\(labels, images\)) N
() N
(    ) S
(# check the image dimensions) c n
(    assert \() p n
(        tf.shape\(augmented_images\)[0].numpy\(\)) N
(        == tf.shape\(images\)[0].numpy\(\)) N
(        + augmentation_probability * tf.shape\(images\)[0].numpy\(\) * 6) N
(    \)) N
() N
(    ) S
(# check the label dimensions) c n
(    assert \() p n
(        tf.shape\(augmented_labels\)[0].numpy\(\)) N
(        == tf.shape\(labels\)[0].numpy\(\)) N
(        + augmentation_probability * tf.shape\(labels\)[0].numpy\(\) * 6) N
(    \)) N
() N
() N
(if) K
( __name__ == ") p
(__main__) str
(":) p n
(    pytest.main\([__file__]\)) N
(augment_data_test.py) (Page 1/1) (Nov 04, 23 17:26) title
border
grestore
(Printed by ) rhead
() (Monday November 27, 2023) (56/79) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (1) 57
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(import) K
( pytest) p n
() N
() N
(@pytest.mark.parametrize\(") S
(kernel_size) str
(", [[2, 2], [4, 4], [8, 8]]\)) p n
(@pytest.mark.parametrize\(") S
(input_channels) str
(", [1, 3, 16]\)) p n
(@pytest.mark.parametrize\(") S
(output_channels) str
(", [1, 3, 16]\)) p n
(def) K
( test_dimensionality\(kernel_size, input_channels, output_channels\):) p n
(    ) S
(import) K
( tensorflow as tf) p n
(    ) S
(from) K
( helpers.conv_2d ) p
(import) K
( Conv2D) p n
() N
(    rng = tf.random.get_global_generator\(\)) N
(    rng.reset_from_seed\(2384230948\)) N
() N
(    conv2d = Conv2D\(input_channels, output_channels, kernel_size\)) N
() N
(    a = rng.normal\(shape=[1, 28, 28, input_channels]\)) N
(    z = conv2d\(a\)) N
() N
(    tf.assert_equal\(tf.shape\(z\)[-1], output_channels\)) N
() N
() N
(if) K
( __name__ == ") p
(__main__) str
(":) p n
(    pytest.main\([__file__]\)) N
(conv_2d_test.py) (Page 1/1) (Nov 04, 23 17:26) title
border
grestore
(Printed by ) rhead
() (57/79) (Monday November 27, 2023) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (1) 58
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(import) K
( pytest) p n
() N
() N
(def) K
( test_dimensionality\(\):) p n
(    ) S
(import) K
( tensorflow as tf) p n
(    ) S
(from) K
( helpers.group_norm ) p
(import) K
( GroupNorm) p n
() N
(    rng = tf.random.get_global_generator\(\)) N
(    rng.reset_from_seed\(2384230948\)) N
() N
(    group_norm = GroupNorm\(4, 16\)) N
() N
(    input = rng.normal\(shape=[1, 32, 32, 16]\)) N
(    output = group_norm\(input\)) N
() N
(    tf.assert_equal\(tf.shape\(output\), tf.shape\(input\)\)) N
() N
() N
(def) K
( test_mean_and_variance\(\):) p n
(    ) S
(import) K
( tensorflow as tf) p n
(    ) S
(from) K
( helpers.group_norm ) p
(import) K
( GroupNorm) p n
() N
(    rng = tf.random.get_global_generator\(\)) N
(    rng.reset_from_seed\(2384230948\)) N
() N
(    group_norm = GroupNorm\(4, 16\)) N
() N
(    input = rng.normal\(shape=[1, 32, 32, 16]\)) N
(    output = group_norm\(input\)) N
() N
(    mean, variance = tf.nn.moments\(output, axes=[1, 2, 3]\)) N
() N
(    assert mean[0].numpy\(\) == pytest.approx\(0.0, abs=1e-3\)) N
(    assert variance[0].numpy\(\) == pytest.approx\(1.0, abs=1e-3\)) N
() N
() N
(if) K
( __name__ == ") p
(__main__) str
(":) p n
(    pytest.main\([__file__]\)) N
(group_norm_test.py) (Page 1/1) (Nov 04, 23 17:26) title
border
grestore
(Printed by ) rhead
() (Monday November 27, 2023) (58/79) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (1) 59
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(import) K
( pytest) p n
() N
() N
(def) K
( test_dimensionality\(\):) p n
(    ) S
(from) K
( helpers.load_idx_data ) p
(import) K
( load_idx_data) p n
() N
(    train_images = load_idx_data\(") S
(data/train-images-idx3-ubyte) str
("\)) p n
(    train_labels = load_idx_data\(") S
(data/train-labels-idx1-ubyte) str
("\)) p n
(    test_labels = load_idx_data\(") S
(data/t10k-labels-idx1-ubyte) str
("\)) p n
(    test_images = load_idx_data\(") S
(data/t10k-images-idx3-ubyte) str
("\)) p n
() N
(    assert train_images.shape == \(60000, 28, 28, 1\)) N
(    assert train_labels.shape == \(60000, 1\)) N
(    assert test_images.shape == \(10000, 28, 28, 1\)) N
(    assert test_labels.shape == \(10000, 1\)) N
() N
() N
(if) K
( __name__ == ") p
(__main__) str
(":) p n
(    pytest.main\([__file__]\)) N
(load_idx_data_test.py) (Page 1/1) (Nov 04, 23 17:26) title
border
grestore
(Printed by ) rhead
() (59/79) (Monday November 27, 2023) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (1) 60
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(import) K
( pytest) p n
() N
() N
(def) K
( test_dimensionality\(\):) p n
(    ) S
(import) K
( tensorflow as tf) p n
() N
(    ) S
(from) K
( helpers.load_pickle_data ) p
(import) K
( load_pickle_data) p n
() N
(    train_and_val_labels, train_and_val_images = load_pickle_data\() N
(        ") S
(data/cifar-10-batches-py/data_batch_1) str
(") p n
(    \)) N
() N
(    assert tf.shape\(train_and_val_labels\)[0] == 10000) N
(    assert train_and_val_images.shape == tf.TensorShape\([10000, 32, 32, 3]\)) N
() N
(    train_and_val_labels, train_and_val_images = load_pickle_data\() N
(        ") S
(data/cifar-100-python/train) str
(", ") p
(fine_labels) str
(") p n
(    \)) N
() N
(    assert tf.shape\(train_and_val_labels\)[0] == [50000]) N
(    assert train_and_val_images.shape == tf.TensorShape\([50000, 32, 32, 3]\)) N
() N
() N
(def) K
( test_labels\(\):) p n
(    ) S
(import) K
( tensorflow as tf) p n
() N
(    ) S
(from) K
( helpers.load_pickle_data ) p
(import) K
( load_pickle_data) p n
() N
(    train_and_val_labels, _ = load_pickle_data\() N
(        ") S
(data/cifar-10-batches-py/data_batch_1) str
(") p n
(    \)) N
() N
(    assert tf.reduce_min\(train_and_val_labels\) == 0) N
(    assert tf.reduce_max\(train_and_val_labels\) == 9) N
() N
() N
(if) K
( __name__ == ") p
(__main__) str
(":) p n
(    pytest.main\([__file__]\)) N
(load_pickle_data_test.py) (Page 1/1) (Nov 04, 23 17:26) title
border
grestore
(Printed by ) rhead
() (Monday November 27, 2023) (60/79) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (1) 61
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(import) K
( pytest) p n
() N
() N
(@pytest.mark.parametrize\() N
(    ") S
(sentence, expected_tokens) str
(",) p n
(    [) N
(        \() N
(            ") S
(Woah oh wee woo Wah wi wah woo) str
(",) p n
(            [[b") S
(Woah) str
(", b") p
(oh) str
(", b") p
(wee) str
(", b") p
(woo) str
(", b") p
(Wah) str
(", b") p
(wi) str
(", b") p
(wah) str
(", b") p
(woo) str
("]],) p n
(        \),) N
(        \() N
(            ") S
(AHHHHHHH AHHHHHH AHH AHHHHHHH AHHHHHHHHHHHHHH AHH AHAHHH AHH) str n
(H AHHH AHH) S
(",) p n
(            [) N
(                [) N
(                    b") S
(AHHHHHHH) str
(",) p n
(                    b") S
(AHHHHHH) str
(",) p n
(                    b") S
(AHH) str
(",) p n
(                    b") S
(AHHHHHHH) str
(",) p n
(                    b") S
(AHHHHHHHHHHHHHH) str
(",) p n
(                    b") S
(AHH) str
(",) p n
(                    b") S
(AHAHHH) str
(",) p n
(                    b") S
(AHHH) str
(",) p n
(                ],) N
(                [) N
(                    b") S
(AHHH) str
(",) p n
(                    b") S
(AHH) str
(",) p n
(                    b") S
(<PAD>) str
(",) p n
(                    b") S
(<PAD>) str
(",) p n
(                    b") S
(<PAD>) str
(",) p n
(                    b") S
(<PAD>) str
(",) p n
(                    b") S
(<PAD>) str
(",) p n
(                    b") S
(<PAD>) str
(",) p n
(                ],) N
(            ],) N
(        \),) N
(    ],) N
(\)) N
(def) K
( test_tokenizer\(sentence, expected_tokens\):) p n
(    ) S
(import) K
( tensorflow as tf) p n
() N
(    ) S
(from) K
( helpers.tokenizer ) p
(import) K
( Tokenizer) p n
() N
(    tokenizer = Tokenizer\(8, False\)) N
() N
(    tokens = tokenizer\(sentence\)) N
() N
(    assert tf.reduce_all\(tf.equal\(tokens, tf.convert_to_tensor\(expected_tokens\)\)) N
(\)) N
() N
() N
(if) K
( __name__ == ") p
(__main__) str
(":) p n
(    pytest.main\([__file__]\)) N
(tokenizer_test.py) (Page 1/1) (Nov 13, 23 0:26) title
border
grestore
(Printed by ) rhead
() (61/79) (Monday November 27, 2023) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (1) 62
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(import) K
( pytest) p n
() N
() N
(def) K
( test_non_additivity\(\):) p n
(    ) S
(import) K
( tensorflow as tf) p n
() N
(    ) S
(from) K
( modules.basis_expansion ) p
(import) K
( BasisExpansion) p n
() N
(    rng = tf.random.get_global_generator\(\)) N
(    rng.reset_from_seed\(2384230948\)) N
() N
(    num_inputs = 10) N
(    num_outputs = 1) N
(    num_bases = 10) N
() N
(    basisExpansion = BasisExpansion\(num_bases, num_inputs, num_outputs\)) N
() N
(    a = rng.normal\(shape=[1, num_inputs]\)) N
(    b = rng.normal\(shape=[1, num_inputs]\)) N
() N
(    case1 = basisExpansion\(a + b\)) N
(    case2 = basisExpansion\(a\) + basisExpansion\(b\)) N
() N
(    tol = 2.22e-15 + 2.22e-15*tf.abs\(case2\)) N
() N
(    tf.debugging.Assert\() N
(        tf.reduce_any\() N
(            tf.greater\() N
(                tf.abs\() N
(                    case1 - case2) N
(                    \),) N
(                tol) N
(                \)) N
(            \),) N
(        [case1, case2],) N
(        summarize=2) N
(    \)) N
() N
() N
(def) K
( test_homogeneity\(\):) p n
(    ) S
(import) K
( tensorflow as tf) p n
() N
(    ) S
(from) K
( modules.basis_expansion ) p
(import) K
( BasisExpansion) p n
() N
(    rng = tf.random.get_global_generator\(\)) N
(    rng.reset_from_seed\(2384230948\)) N
() N
(    num_inputs = 10) N
(    num_outputs = 1) N
(    num_bases = 10) N
(    num_test_cases = 100) N
() N
(    basisExpansion = BasisExpansion\(num_bases, num_inputs, num_outputs\)) N
() N
(    a = rng.normal\(shape=[1, 1, num_inputs]\)) N
(    b = rng.normal\(shape=[num_test_cases, 1, 1]\)) N
() N
(    case1 = basisExpansion\(a * b\)) N
(    case2 = basisExpansion\(a\) * b) N
() N
(    tol = 2.22e-15 + 2.22e-15*tf.abs\(case2\)) N
() N
(    tf.debugging.Assert\() N
(        tf.reduce_any\() N
(            tf.greater\() N
(                tf.abs\() N
(basis_expansion_test.py) (Page 1/2) (Nov 04, 23 17:26) title
border
grestore
(Printed by ) rhead
() (Monday November 27, 2023) (62/79) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (2) 63
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(                    case1 - case2) p n
(                    \),) N
(                tol) N
(                \)) N
(            \),) N
(        [case1, case2],) N
(        summarize=2) N
(    \)) N
() N
() N
(if) K
( __name__ == ") p
(__main__) str
(":) p n
(    pytest.main\([__file__]\)) N
(basis_expansion_test.py) (Page 2/2) (Nov 04, 23 17:26) title
border
grestore
(Printed by ) rhead
() (63/79) (Monday November 27, 2023) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (1) 64
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(import) K
( pytest) p n
() N
() N
(@pytest.mark.parametrize\(") S
(layer_depths) str
(", [[10, 20], [20, 40]]\)) p n
(@pytest.mark.parametrize\(") S
(kernel_sizes) str
(", [[[2, 2], [2, 2]], [[3, 3], [3, 3]]]\)) p n
(@pytest.mark.parametrize\(") S
(num_classes) str
(", [10, 100]\)) p n
(@pytest.mark.parametrize\(") S
(resblock_size) str
(", [1, 2, 3]\)) p n
(@pytest.mark.parametrize\(") S
(group_norm_num_groups) str
(", [[2, 2], [2, 5]]\)) p n
(def) K
( test_dimensionality\() p n
(    layer_depths,) N
(    kernel_sizes,) N
(    num_classes,) N
(    resblock_size,) N
(    group_norm_num_groups,) N
(\):) N
(    ) S
(import) K
( tensorflow as tf) p n
() N
(    ) S
(from) K
( modules.classifier ) p
(import) K
( Classifier) p n
() N
(    rng = tf.random.get_global_generator\(\)) N
(    rng.reset_from_seed\(2384230948\)) N
() N
(    input_depth = 3) N
(    input_size = 32) N
(    dropout_prob = 0.5) N
(    pool_size = 2) N
() N
(    num_hidden_layers = 1) N
(    hidden_layer_width = 10) N
() N
(    classifier = Classifier\() N
(        input_depth,) N
(        layer_depths,) N
(        kernel_sizes,) N
(        num_classes,) N
(        input_size,) N
(        resblock_size,) N
(        pool_size,) N
(        dropout_prob,) N
(        group_norm_num_groups,) N
(        num_hidden_layers,) N
(        hidden_layer_width,) N
(    \)) N
() N
(    input_data = rng.normal\(shape=[1, input_size, input_size, input_depth]\)) N
(    classified_data = classifier\(input_data\)) N
() N
(    tf.assert_equal\(tf.shape\(classified_data\)[-1], num_classes\)) N
() N
() N
(if) K
( __name__ == ") p
(__main__) str
(":) p n
(    pytest.main\([__file__]\)) N
(classifier_test.py) (Page 1/1) (Nov 04, 23 17:26) title
border
grestore
(Printed by ) rhead
() (Monday November 27, 2023) (64/79) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (1) 65
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(import) K
( pytest) p n
(import) K
( tensorflow as tf) p n
() N
() N
(@pytest.mark.parametrize\() N
(    ") S
(text) str
(",) p n
(    [) N
(        tf.constant\([") S
(professor curro likes) str
(", ") p
(reading about) str
(", ") p
(apples) str
("]\),) p n
(        tf.constant\([") S
(apples are a good fruit) str
("]\),) p n
(    ],) N
(\)) N
(@pytest.mark.parametrize\(") S
(num_embedding) str
(", [100, 200, 300]\)) p n
(@pytest.mark.parametrize\(") S
(embedding_depth) str
(", [50, 100, 150]\)) p n
(@pytest.mark.parametrize\(") S
(num_word_to_tokenize) str
(", [10, 20, 30]\)) p n
(@pytest.mark.parametrize\(") S
(num_classes) str
(", [10, 20, 30]\)) p n
(def) K
( test_EmbedClassifier_call\() p n
(    text, num_embedding, embedding_depth, num_word_to_tokenize, num_classes) N
(\):) N
(    ) S
(from) K
( modules.embed_classifier ) p
(import) K
( EmbedClassifier) p n
() N
(    num_classes = 10) N
(    embed_classifier = EmbedClassifier\() N
(        num_embedding,) N
(        embedding_depth,) N
(        num_word_to_tokenize,) N
(        dropout_prob=0.5,) N
(        num_hidden_layers=3,) N
(        hidden_layer_width=30,) N
(        num_classes=num_classes,) N
(    \)) N
() N
(    embeddings = embed_classifier\(text\)) N
() N
(    assert embeddings.shape[0] == len\(text\)) N
(    assert embeddings.shape[1] == num_classes) N
() N
() N
(if) K
( __name__ == ") p
(__main__) str
(":) p n
(    pytest.main\([__file__]\)) N
(embed_classifier_test.py) (Page 1/1) (Nov 05, 23 1:59) title
border
grestore
(Printed by ) rhead
() (65/79) (Monday November 27, 2023) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (1) 66
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(import) K
( pytest) p n
() N
() N
(def) K
( test_additivity\(\):) p n
(    ) S
(import) K
( tensorflow as tf) p n
() N
(    ) S
(from) K
( modules.linear ) p
(import) K
( Linear) p n
() N
(    rng = tf.random.get_global_generator\(\)) N
(    rng.reset_from_seed\(2384230948\)) N
() N
(    num_inputs = 10) N
(    num_outputs = 1) N
() N
(    linear = Linear\(num_inputs, num_outputs\)) N
() N
(    a = rng.normal\(shape=[1, num_inputs]\)) N
(    b = rng.normal\(shape=[1, num_inputs]\)) N
() N
(    tf.debugging.assert_near\(linear\(a + b\), linear\(a\) + linear\(b\), summarize=2\)) N
() N
() N
(def) K
( test_homogeneity\(\):) p n
(    ) S
(import) K
( tensorflow as tf) p n
() N
(    ) S
(from) K
( modules.linear ) p
(import) K
( Linear) p n
() N
(    rng = tf.random.get_global_generator\(\)) N
(    rng.reset_from_seed\(2384230948\)) N
() N
(    num_inputs = 10) N
(    num_outputs = 1) N
(    num_test_cases = 100) N
() N
(    linear = Linear\(num_inputs, num_outputs\)) N
() N
(    a = rng.normal\(shape=[1, num_inputs]\)) N
(    b = rng.normal\(shape=[num_test_cases, 1]\)) N
() N
(    tf.debugging.assert_near\(linear\(a * b\), linear\(a\) * b, summarize=2\)) N
() N
() N
(@pytest.mark.parametrize\(") S
(num_outputs) str
(", [1, 16, 128]\)) p n
(def) K
( test_dimensionality\(num_outputs\):) p n
(    ) S
(import) K
( tensorflow as tf) p n
() N
(    ) S
(from) K
( modules.linear ) p
(import) K
( Linear) p n
() N
(    rng = tf.random.get_global_generator\(\)) N
(    rng.reset_from_seed\(2384230948\)) N
() N
(    num_inputs = 10) N
() N
(    linear = Linear\(num_inputs, num_outputs\)) N
() N
(    a = rng.normal\(shape=[1, num_inputs]\)) N
(    z = linear\(a\)) N
() N
(    tf.assert_equal\(tf.shape\(z\)[-1], num_outputs\)) N
() N
() N
(@pytest.mark.parametrize\(") S
(bias) str
(", [True, False]\)) p n
(def) K
( test_trainable\(bias\):) p n
(    ) S
(import) K
( tensorflow as tf) p n
() N
(    ) S
(from) K
( modules.linear ) p
(import) K
( Linear) p n
(linear_test.py) (Page 1/3) (Nov 04, 23 17:26) title
border
grestore
(Printed by ) rhead
() (Monday November 27, 2023) (66/79) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (2) 67
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
() p n
(    rng = tf.random.get_global_generator\(\)) N
(    rng.reset_from_seed\(2384230948\)) N
() N
(    num_inputs = 10) N
(    num_outputs = 1) N
() N
(    linear = Linear\(num_inputs, num_outputs, bias=bias\)) N
() N
(    a = rng.normal\(shape=[1, num_inputs]\)) N
() N
(    with tf.GradientTape\(\) as tape:) N
(        z = linear\(a\)) N
(        loss = tf.math.reduce_mean\(z**2\)) N
() N
(    grads = tape.gradient\(loss, linear.trainable_variables\)) N
() N
(    ) S
(for) K
( grad, var ) p
(in) K
( zip\(grads, linear.trainable_variables\):) p n
(        tf.debugging.check_numerics\(grad, message=f") S
({var.name}: ) str
("\)) p n
(        tf.debugging.assert_greater\(tf.math.abs\(grad\), 0.0\)) N
() N
(    assert len\(grads\) == len\(linear.trainable_variables\)) N
() N
(    ) S
(if) K
( bias:) p n
(        assert len\(grads\) == 2) N
(    ) S
(else) K
(:) p n
(        assert len\(grads\) == 1) N
() N
() N
(@pytest.mark.parametrize\() N
(    ") S
(a_shape, b_shape) str
(",) p n
(    [) N
(        \([1000, 1000], [100, 100]\),) N
(        \([1000, 100], [100, 100]\),) N
(        \([100, 1000], [100, 100]\)) N
(    ],) N
(\)) N
(def) K
( test_init_properties\(a_shape, b_shape\):) p n
(    ) S
(import) K
( tensorflow as tf) p n
() N
(    ) S
(from) K
( modules.linear ) p
(import) K
( Linear) p n
() N
(    rng = tf.random.get_global_generator\(\)) N
(    rng.reset_from_seed\(2384230948\)) N
() N
(    num_inputs_a, num_outputs_a = a_shape) N
(    num_inputs_b, num_outputs_b = b_shape) N
() N
(    linear_a = Linear\(num_inputs_a, num_outputs_a, bias=False\)) N
(    linear_b = Linear\(num_inputs_b, num_outputs_b, bias=False\)) N
() N
(    std_a = tf.math.reduce_std\(linear_a.w\)) N
(    std_b = tf.math.reduce_std\(linear_b.w\)) N
() N
(    tf.debugging.assert_less\(std_a, std_b\)) N
() N
() N
(def) K
( test_bias\(\):) p n
(    ) S
(import) K
( tensorflow as tf) p n
() N
(    ) S
(from) K
( modules.linear ) p
(import) K
( Linear) p n
() N
(    rng = tf.random.get_global_generator\(\)) N
(    rng.reset_from_seed\(2384230948\)) N
() N
(    linear_with_bias = Linear\(1, 1, bias=True\)) N
(linear_test.py) (Page 2/3) (Nov 04, 23 17:26) title
border
grestore
(Printed by ) rhead
() (67/79) (Monday November 27, 2023) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (3) 68
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(    assert hasattr\(linear_with_bias, ") p
(b) str
("\)) p n
() N
(    linear_with_bias = Linear\(1, 1, bias=False\)) N
(    assert ) S
(not) K
( hasattr\(linear_with_bias, ") p
(b) str
("\)) p n
() N
() N
(if) K
( __name__ == ") p
(__main__) str
(":) p n
(    pytest.main\([__file__]\)) N
(linear_test.py) (Page 3/3) (Nov 04, 23 17:26) title
border
grestore
(Printed by ) rhead
() (Monday November 27, 2023) (68/79) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (1) 69
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(import) K
( pytest) p n
() N
() N
(def) K
( test_non_additivity\(\):) p n
(    ) S
(import) K
( tensorflow as tf) p n
() N
(    ) S
(from) K
( modules.mlp ) p
(import) K
( MLP) p n
() N
(    rng = tf.random.get_global_generator\(\)) N
(    rng.reset_from_seed\(2384230948\)) N
() N
(    num_inputs = 10) N
(    num_outputs = 1) N
(    num_hidden_layers = 10) N
(    hidden_layer_width = 10) N
(    relu = tf.nn.relu) N
(    sigmoid = tf.nn.sigmoid) N
() N
(    mlp = MLP\() N
(        num_inputs, num_outputs, num_hidden_layers, hidden_layer_width, relu, si) N
(gmoid) N
(    \)) N
() N
(    a = rng.normal\(shape=[1, num_inputs]\)) N
(    b = rng.normal\(shape=[1, num_inputs]\)) N
() N
(    case1 = mlp\(a + b\)) N
(    case2 = mlp\(a\) + mlp\(b\)) N
() N
(    tol = 2.22e-15 + 2.22e-15 * tf.abs\(case2\)) N
() N
(    tf.debugging.Assert\() N
(        tf.reduce_any\(tf.greater\(tf.abs\(case1 - case2\), tol\)\),) N
(        [case1, case2],) N
(        summarize=2,) N
(    \)) N
() N
() N
(def) K
( test_non_homogeneity\(\):) p n
(    ) S
(import) K
( tensorflow as tf) p n
() N
(    ) S
(from) K
( modules.mlp ) p
(import) K
( MLP) p n
() N
(    rng = tf.random.get_global_generator\(\)) N
(    rng.reset_from_seed\(2384230948\)) N
() N
(    num_inputs = 10) N
(    num_outputs = 1) N
(    num_test_cases = 100) N
(    num_hidden_layers = 10) N
(    hidden_layer_width = 10) N
(    relu = tf.nn.relu) N
(    sigmoid = tf.nn.sigmoid) N
() N
(    mlp = MLP\() N
(        num_inputs, num_outputs, num_hidden_layers, hidden_layer_width, relu, si) N
(gmoid) N
(    \)) N
() N
(    a = rng.normal\(shape=[1, 1, num_inputs]\)) N
(    b = rng.normal\(shape=[num_test_cases, 1, 1]\)) N
() N
(    case1 = mlp\(a * b\)) N
(    case2 = mlp\(a\) * b) N
() N
(    tol = 2.22e-15 + 2.22e-15 * tf.abs\(case2\)) N
(mlp_test.py) (Page 1/4) (Nov 05, 23 2:42) title
border
grestore
(Printed by ) rhead
() (69/79) (Monday November 27, 2023) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (2) 70
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
() p n
(    tf.debugging.Assert\() N
(        tf.reduce_any\(tf.greater\(tf.abs\(case1 - case2\), tol\)\),) N
(        [case1, case2],) N
(        summarize=2,) N
(    \)) N
() N
() N
(def) K
( test_additivity\(\):) p n
(    ) S
(import) K
( tensorflow as tf) p n
() N
(    ) S
(from) K
( modules.mlp ) p
(import) K
( MLP) p n
() N
(    rng = tf.random.get_global_generator\(\)) N
(    rng.reset_from_seed\(2384230948\)) N
() N
(    num_inputs = 10) N
(    num_outputs = 1) N
(    num_hidden_layers = 10) N
(    hidden_layer_width = 10) N
() N
(    mlp = MLP\(num_inputs, num_outputs, num_hidden_layers, hidden_layer_width\)) N
() N
(    a = rng.normal\(shape=[1, num_inputs]\)) N
(    b = rng.normal\(shape=[1, num_inputs]\)) N
() N
(    tf.debugging.assert_near\(mlp\(a + b\), mlp\(a\) + mlp\(b\), summarize=2\)) N
() N
() N
(def) K
( test_homogeneity\(\):) p n
(    ) S
(import) K
( tensorflow as tf) p n
() N
(    ) S
(from) K
( modules.mlp ) p
(import) K
( MLP) p n
() N
(    rng = tf.random.get_global_generator\(\)) N
(    rng.reset_from_seed\(2384230948\)) N
() N
(    num_inputs = 10) N
(    num_outputs = 1) N
(    num_test_cases = 100) N
(    num_hidden_layers = 10) N
(    hidden_layer_width = 10) N
() N
(    mlp = MLP\(num_inputs, num_outputs, num_hidden_layers, hidden_layer_width\)) N
() N
(    a = rng.normal\(shape=[1, num_inputs]\)) N
(    b = rng.normal\(shape=[num_test_cases, 1]\)) N
() N
(    tf.debugging.assert_near\(mlp\(a * b\), mlp\(a\) * b, summarize=2\)) N
() N
() N
(def) K
( test_dimensionality\(\):) p n
(    ) S
(import) K
( tensorflow as tf) p n
() N
(    ) S
(from) K
( modules.mlp ) p
(import) K
( MLP) p n
() N
(    rng = tf.random.get_global_generator\(\)) N
(    rng.reset_from_seed\(2384230948\)) N
() N
(    num_inputs = 10) N
(    num_outputs = 1) N
(    num_hidden_layers = 10) N
(    hidden_layer_width = 10) N
() N
(    mlp = MLP\(num_inputs, num_outputs, num_hidden_layers, hidden_layer_width\)) N
() N
(mlp_test.py) (Page 2/4) (Nov 05, 23 2:42) title
border
grestore
(Printed by ) rhead
() (Monday November 27, 2023) (70/79) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (3) 71
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(    a = rng.normal\(shape=[1, num_inputs]\)) p n
(    z = mlp\(a\)) N
() N
(    tf.assert_equal\(tf.shape\(z\)[-1], num_outputs\)) N
() N
() N
(def) K
( test_trainable\(\):) p n
(    ) S
(import) K
( tensorflow as tf) p n
() N
(    ) S
(from) K
( modules.mlp ) p
(import) K
( MLP) p n
() N
(    rng = tf.random.get_global_generator\(\)) N
(    rng.reset_from_seed\(2384230948\)) N
() N
(    num_inputs = 10) N
(    num_outputs = 1) N
(    num_hidden_layers = 10) N
(    hidden_layer_width = 10) N
() N
(    mlp = MLP\(num_inputs, num_outputs, num_hidden_layers, hidden_layer_width\)) N
() N
(    a = rng.normal\(shape=[1, num_inputs]\)) N
() N
(    with tf.GradientTape\(\) as tape:) N
(        z = mlp\(a\)) N
(        loss = tf.reduce_mean\(z**2\)) N
() N
(    grads = tape.gradient\(loss, mlp.trainable_variables\)) N
() N
(    ) S
(for) K
( grad, var ) p
(in) K
( zip\(grads, mlp.trainable_variables\):) p n
(        tf.debugging.check_numerics\(grad, message=f") S
({var.name}: ) str
("\)) p n
(        tf.debugging.assert_greater\(tf.math.abs\(grad\), 0.0\)) N
() N
(    assert len\(grads\) == len\(mlp.trainable_variables\)) N
() N
() N
(def) K
( test_no_hidden_layers\(\):) p n
(    ) S
(import) K
( tensorflow as tf) p n
() N
(    ) S
(from) K
( modules.mlp ) p
(import) K
( MLP) p n
() N
(    rng = tf.random.get_global_generator\(\)) N
(    rng.reset_from_seed\(2384230948\)) N
() N
(    num_inputs = 10) N
(    num_outputs = 1) N
(    relu = tf.nn.relu) N
(    sigmoid = tf.nn.sigmoid) N
() N
(    mlp = MLP\() N
(        num_inputs, num_outputs, hidden_activation=relu, output_activation=sigmo) N
(id) N
(    \)) N
() N
(    a = rng.normal\(shape=[1, num_inputs]\)) N
(    b = rng.normal\(shape=[1, num_inputs]\)) N
() N
(    case1 = mlp\(a + b\)) N
(    case2 = mlp\(a\) + mlp\(b\)) N
() N
(    tol = 2.22e-15 + 2.22e-15 * tf.abs\(case2\)) N
() N
(    tf.debugging.Assert\() N
(        tf.reduce_any\(tf.greater\(tf.abs\(case1 - case2\), tol\)\),) N
(        [case1, case2],) N
(        summarize=2,) N
(mlp_test.py) (Page 3/4) (Nov 05, 23 2:42) title
border
grestore
(Printed by ) rhead
() (71/79) (Monday November 27, 2023) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (4) 72
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(    \)) p n
() N
() N
(if) K
( __name__ == ") p
(__main__) str
(":) p n
(    pytest.main\([__file__]\)) N
(mlp_test.py) (Page 4/4) (Nov 05, 23 2:42) title
border
grestore
(Printed by ) rhead
() (Monday November 27, 2023) (72/79) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (1) 73
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(import) K
( pytest) p n
() N
() N
(def) K
( test_causal_mask\(\):) p n
(    ) S
(import) K
( tensorflow as tf) p n
() N
(    ) S
(from) K
( modules.multi_head_attention ) p
(import) K
( MultiHeadAttention) p n
() N
(    rng = tf.random.get_global_generator\(\)) N
(    rng.reset_from_seed\(0x43966E87BD57227011B5B03B58785EC1\)) N
(    tf.random.set_seed\(0x43966E87BD57227011B5B03B58785EC1\)) N
() N
(    context_length = 5) N
(    num_heads = 1) N
(    model_dim = 3) N
(    batch_size = 1) N
() N
(    queries = rng.normal\(shape=[batch_size, context_length, model_dim]\)) N
(    keys = rng.normal\(shape=[batch_size, context_length, model_dim]\)) N
(    values = rng.normal\(shape=[batch_size, context_length, model_dim]\)) N
() N
(    mask = tf.linalg.band_part\(tf.ones\(\(context_length, context_length\)\), 0, -1\)) N
(    ) S
(# make the main diagonal 0) c n
(    mask = mask - tf.eye\(context_length\)) p n
() N
(    ) S
(# stack causal mask for each batch resulting in shape \(B, seq_len, seq_len\)) c n
(    mask = tf.stack\([mask ) p
(for) K
( _ ) p
(in) K
( range\(batch_size\)]\)) p n
() N
(    mha = MultiHeadAttention\(num_heads, model_dim\)) N
() N
(    with tf.GradientTape\(\) as tape:) N
(        tape.watch\([queries, keys, values]\)) N
(        output = mha\(queries, keys, values, mask\)) N
() N
(    dy_dx = tape.gradient\(output, [queries, keys, values]\)) N
() N
(    ) S
(# ensure that the derivative is zero for future tokens with respect to previ) c n
(ous tokens) N
(    assert tf.reduce_all\(dy_dx[0][:, 0, 1:] == 0\)) p n
() N
(    ) S
(# ensure that the derivative is not zero for future tokens with respect to p) c n
(revious tokens) N
(    assert tf.reduce_all\([dy_dx[0][:, i] != 0 ) p
(for) K
( i ) p
(in) K
( range\(1, context_length\)]) p n
(\)) N
() N
() N
(@pytest.mark.parametrize\() N
(    ") S
(batch_size, context_length, num_heads, model_dim) str
(",) p n
(    [) N
(        \(1, 5, 1, 3\),) N
(        \(5, 10, 3, 9\),) N
(        \(10, 20, 9, 27\),) N
(    ],) N
(\)) N
(def) K
( test_dimensionality\(batch_size, context_length, num_heads, model_dim\):) p n
(    ) S
(import) K
( tensorflow as tf) p n
() N
(    ) S
(from) K
( modules.multi_head_attention ) p
(import) K
( MultiHeadAttention) p n
() N
(    rng = tf.random.get_global_generator\(\)) N
(    rng.reset_from_seed\(0x43966E87BD57227011B5B03B58785EC1\)) N
(    tf.random.set_seed\(0x43966E87BD57227011B5B03B58785EC1\)) N
() N
(    queries = rng.normal\(shape=[batch_size, context_length, model_dim]\)) N
(    keys = rng.normal\(shape=[batch_size, context_length, model_dim]\)) N
(    values = rng.normal\(shape=[batch_size, context_length, model_dim]\)) N
(multi_head_attention_test.py) (Page 1/2) (Nov 13, 23 14:25) title
border
grestore
(Printed by ) rhead
() (73/79) (Monday November 27, 2023) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (2) 74
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
() p n
(    mask = tf.linalg.band_part\(tf.ones\(\(context_length, context_length\)\), 0, -1\)) N
(    ) S
(# make the main diagonal 0) c n
(    mask = mask - tf.eye\(context_length\)) p n
() N
(    ) S
(# stack causal mask for each batch resulting in shape \(B, seq_len, seq_len\)) c n
(    mask = tf.stack\([mask ) p
(for) K
( _ ) p
(in) K
( range\(batch_size\)]\)) p n
() N
(    mha = MultiHeadAttention\(num_heads, model_dim\)) N
() N
(    output = mha\(queries, keys, values, mask\)) N
() N
(    assert output.shape == \(batch_size, context_length, model_dim\)) N
() N
() N
(if) K
( __name__ == ") p
(__main__) str
(":) p n
(    pytest.main\([__file__]\)) N
(multi_head_attention_test.py) (Page 2/2) (Nov 13, 23 14:25) title
border
grestore
(Printed by ) rhead
() (Monday November 27, 2023) (74/79) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (1) 75
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(import) K
( pytest) p n
() N
() N
(@pytest.mark.parametrize\(") S
(input_depth) str
(", [3, 6]\)) p n
(@pytest.mark.parametrize\(") S
(output_depth) str
(", [3, 6]\)) p n
(@pytest.mark.parametrize\(") S
(kernel_size) str
(", [[2, 2], [4, 4], [8, 8]]\)) p n
(@pytest.mark.parametrize\(") S
(group_norm_num_groups) str
(", [1, 3]\)) p n
(@pytest.mark.parametrize\(") S
(resblock_size) str
(", [1, 2, 3]\)) p n
(def) K
( test_dimensionality\() p n
(    input_depth, output_depth, kernel_size, group_norm_num_groups, resblock_size) N
(\):) N
(    ) S
(import) K
( tensorflow as tf) p n
() N
(    ) S
(from) K
( modules.residual_block ) p
(import) K
( ResidualBlock) p n
() N
(    rng = tf.random.get_global_generator\(\)) N
(    rng.reset_from_seed\(2384230948\)) N
() N
(    residual_block = ResidualBlock\() N
(        input_depth, output_depth, kernel_size, group_norm_num_groups, resblock_) N
(size) N
(    \)) N
() N
(    input_tensor = rng.normal\(shape=[1, 32, 32, input_depth]\)) N
(    output_tensor = residual_block\(input_tensor\)) N
() N
(    tf.assert_equal\(tf.shape\(output_tensor\)[-1], output_depth\)) N
(    tf.assert_equal\(tf.shape\(output_tensor\)[0:3], tf.shape\(input_tensor\)[0:3]\)) N
() N
() N
(if) K
( __name__ == ") p
(__main__) str
(":) p n
(    pytest.main\([__file__]\)) N
(residual_block_test.py) (Page 1/1) (Nov 04, 23 17:26) title
border
grestore
(Printed by ) rhead
() (75/79) (Monday November 27, 2023) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (1) 76
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(import) K
( pytest) p n
() N
() N
(@pytest.mark.parametrize\() N
(    ") S
(batch_size, seq_len, model_dim, num_heads) str
(",) p n
(    [) N
(        \(1, 6, 12, 3\),) N
(        \(5, 12, 36, 9\),) N
(        \(10, 27, 108, 27\),) N
(    ],) N
(\)) N
(def) K
( test_dimensionality\(batch_size, seq_len, model_dim, num_heads\):) p n
(    ) S
(import) K
( tensorflow as tf) p n
() N
(    ) S
(from) K
( modules.transformer_decoder_block ) p
(import) K
( TransformerDecoderBlock) p n
() N
(    rng = tf.random.get_global_generator\(\)) N
(    rng.reset_from_seed\(0x43966E87BD57227011B5B03B58785EC1\)) N
(    tf.random.set_seed\(0x43966E87BD57227011B5B03B58785EC1\)) N
() N
(    ffn_dim = 2048) N
() N
(    decoder_block = TransformerDecoderBlock\(num_heads, model_dim, ffn_dim\)) N
() N
(    input_embeddings = tf.Variable\(rng.normal\(shape=[batch_size, seq_len, model_) N
(dim]\)\)) N
(    embeddings = decoder_block\(input_embeddings\)) N
() N
(    assert embeddings.shape == \(batch_size, seq_len, model_dim\)) N
() N
() N
(if) K
( __name__ == ") p
(__main__) str
(":) p n
(    pytest.main\([__file__]\)) N
(transformer_decoder_block_test.py) (Page 1/1) (Nov 13, 23 14:49) title
border
grestore
(Printed by ) rhead
() (Monday November 27, 2023) (76/79) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (1) 77
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(import) K
( pytest) p n
() N
() N
(def) K
( test_autoregressive\(\):) p n
(    ) S
(import) K
( tensorflow as tf) p n
() N
(    ) S
(from) K
( helpers.adam ) p
(import) K
( Adam) p n
(    ) S
(from) K
( modules.transformer_decoder ) p
(import) K
( TransformerDecoder) p n
() N
(    rng = tf.random.get_global_generator\(\)) N
(    rng.reset_from_seed\(0x43966E87BD57227011B5B03B58785EC1\)) N
(    tf.random.set_seed\(0x43966E87BD57227011B5B03B58785EC1\)) N
() N
(    batch_size = 100) N
(    context_length = 6) N
(    num_heads = 8) N
(    model_dim = 512) N
(    ffn_dim = 2048) N
(    num_blocks = 6) N
() N
(    input_text = ") S
(<SOS> Florida man bites dog. <EOS> Dog bites professor curro. <EOS>) str
(") p n
() N
(    transformer_decoder = TransformerDecoder\() N
(        context_length,) N
(        num_heads,) N
(        model_dim,) N
(        ffn_dim,) N
(        num_blocks,) N
(        input_text,) N
(    \)) N
(    learning_rate = 0.0001) N
(    adam = Adam\(learning_rate\)) N
() N
(    text, targets = transformer_decoder.get_tokens_and_targets\(\)) N
() N
(    ) S
(for) K
( _ ) p
(in) K
( range\(20\):) p n
(        batch_indices = rng.uniform\() N
(            shape=[batch_size], maxval=text.shape[0], dtype=tf.int32) N
(        \)) N
() N
(        with tf.GradientTape\(\) as tape:) N
(            input_tokens_batch = tf.gather\(text, batch_indices\)) N
(            targets_batch = tf.gather\(targets, batch_indices\)) N
() N
(            labels = targets_batch) N
(            logits = transformer_decoder\(input_tokens_batch\)) N
(            current_train_loss = tf.reduce_mean\() N
(                tf.nn.sparse_softmax_cross_entropy_with_logits\() N
(                    labels=labels,) N
(                    logits=logits,) N
(                \)) N
(            \)) N
() N
(        grads = tape.gradient\() N
(            current_train_loss, transformer_decoder.trainable_variables) N
(        \)) N
() N
(        adam.apply_gradients\(zip\(grads, transformer_decoder.trainable_variables\)) N
(\)) N
() N
(    accuracy = tf.reduce_mean\() N
(        tf.cast\() N
(            tf.equal\() N
(                logits.numpy\(\).argmax\(axis=2\).reshape\(-1\),) N
(                labels.numpy\(\).reshape\(-1\),) N
(            \),) N
(transformer_decoder_test.py) (Page 1/2) (Nov 13, 23 18:30) title
border
grestore
(Printed by ) rhead
() (77/79) (Monday November 27, 2023) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (2) 78
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(            tf.float32,) p n
(        \)) N
(    \)) N
() N
(    assert accuracy == 1.0) N
(    assert transformer_decoder.predict\(") S
(<SOS> Florida) str
("\) == ") p
( man bites dog.) str
(") p n
(    assert transformer_decoder.predict\(") S
(Dog) str
("\) == ") p
( bites professor curro.) str
(") p n
() N
() N
(def) K
( test_exploding_gradients\(\):) p n
(    ) S
(import) K
( tensorflow as tf) p n
() N
(    ) S
(from) K
( helpers.adam ) p
(import) K
( Adam) p n
(    ) S
(from) K
( modules.transformer_decoder ) p
(import) K
( TransformerDecoder) p n
() N
(    rng = tf.random.get_global_generator\(\)) N
(    rng.reset_from_seed\(0x43966E87BD57227011B5B03B58785EC1\)) N
(    tf.random.set_seed\(0x43966E87BD57227011B5B03B58785EC1\)) N
() N
(    context_length = 6) N
(    num_heads = 8) N
(    model_dim = 512) N
(    ffn_dim = 2048) N
(    num_blocks = 6) N
() N
(    input_text = ") S
(<SOS> Florida man bites dog. <EOS> Dog bites professor curro. <EOS>) str
(") p n
() N
(    transformer_decoder = TransformerDecoder\() N
(        context_length,) N
(        num_heads,) N
(        model_dim,) N
(        ffn_dim,) N
(        num_blocks,) N
(        input_text,) N
(    \)) N
(    learning_rate = 0.0001) N
(    adam = Adam\(learning_rate\)) N
() N
(    text, targets = transformer_decoder.get_tokens_and_targets\(\)) N
() N
(    with tf.GradientTape\(\) as tape:) N
(        labels = targets) N
(        logits = transformer_decoder\(text\)) N
(        loss = tf.reduce_mean\() N
(            tf.nn.sparse_softmax_cross_entropy_with_logits\() N
(                labels=labels,) N
(                logits=logits,) N
(            \)) N
(        \)) N
() N
(    grads = tape.gradient\(loss, transformer_decoder.trainable_variables\)) N
() N
(    adam.apply_gradients\(zip\(grads, transformer_decoder.trainable_variables\)\)) N
() N
(    ) S
(for) K
( grad, var ) p
(in) K
( zip\(grads, transformer_decoder.trainable_variables\):) p n
(        tf.debugging.check_numerics\(grad, message=f") S
({var.name}: ) str
("\)) p n
() N
(    assert len\(grads\) == len\(transformer_decoder.trainable_variables\)) N
() N
() N
(if) K
( __name__ == ") p
(__main__) str
(":) p n
(    pytest.main\([__file__]\)) N
(transformer_decoder_test.py) (Page 2/2) (Nov 13, 23 18:30) title
border
grestore
(Printed by ) rhead
() (Monday November 27, 2023) (78/79) footer
end % of iso1dict
pagesave restore
showpage
%%Page: (1) 79
%%BeginPageSetup
/pagesave save def
%%EndPageSetup
iso1dict begin
gsave
llx lly 12 add translate
/v 0 store
/x0 x v get 4.703931 add sx cw mul add store
/y0 y v get bfs th add sub store
x0 y0 moveto
(#!/usr/bin/env python3) c n
() p n
(import) K
( argparse) p n
(import) K
( importlib) p n
(from) K
( pathlib ) p
(import) K
( Path) p n
() N
(import) K
( argcomplete) p n
() N
() N
(def) K
( main\(\):) p n
(    parser = argparse.ArgumentParser\(description=") S
(Choose an example to train:) str
("\)) p n
(    parser.add_argument\(") S
(runner) str
(", type=Path,) p n
(                        help=") S
(Path to the runner file) str
("\)) p n
(    parser.add_argument\(") S
(--config) str
(", ") p
(-c) str
(", type=Path,) p n
(                        nargs=') S
(?) str
(', help=") p
(Path to the config file) str
("\)) p n
(    parser.add_argument\(") S
(--restore_from_checkpoint) str
(", ") p
(-r) str
(", action=") p
(store_true) str
(",) p n
(                        help=") S
(Whether or not to use the last checkpoint) str
("\)) p n
() N
(    argcomplete.autocomplete\(parser\)) N
(    args = parser.parse_args\(\)) N
() N
(    runner = importlib.import_module\(f") S
(runners.{args.runner.stem}) str
("\)) p n
(    runner.train\(args.config, args.restore_from_checkpoint\)) N
() N
() N
(if) K
( __name__ == ") p
(__main__) str
(":) p n
(    main\(\)) N
(train.py) (Page 1/1) (Nov 04, 23 17:25) title
border
grestore
(Printed by ) rhead
() (79/79) (Monday November 27, 2023) footer
end % of iso1dict
pagesave restore
showpage

%%Trailer
end
%%EOF
