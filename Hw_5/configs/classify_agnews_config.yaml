display:
  refresh_rate: 5
learning:
  batch_size: 500
  dropout_prob: 0.2
  learning_patience: 200
  learning_rates:
  - 0.0005
  - 0.0001
  - 0.0005
  - 0.001
  - 0.0005
  - 0.0001
  - 0.00005
  - 0.00001
  num_iters: 100000
  weight_decay: 0.2
  num_embeddings: 50
  embedding_depth: 1000
mlp:
  hidden_layer_width: 1000
  num_hidden_layers: 4
data:
  num_words_to_tokenize: 50
